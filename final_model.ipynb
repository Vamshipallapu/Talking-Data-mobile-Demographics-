{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yPWj_gkM0D9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from sklearn.preprocessing import LabelEncoder,StandardScaler, OneHotEncoder\n",
        "from scipy.sparse import csr_matrix, hstack\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.feature_extraction.text import TfidfTransformer,TfidfVectorizer,CountVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4BTTHn1M0EA",
        "outputId": "5dc24939-14bd-4cee-b329-78920a10bc4b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation,BatchNormalization\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import np_utils\n",
        "from keras.optimizers import SGD,Adagrad\n",
        "from keras.layers.advanced_activations import PReLU\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import EarlyStopping,TensorBoard\n",
        "from statistics import mean"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrOgHRCIM0EC"
      },
      "source": [
        "# LOADING THE DATA"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1apXM1eNrrj",
        "outputId": "7ead1b8d-df7a-4387-b040-f1a64541dbba"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0U0psIyM0EF"
      },
      "outputs": [],
      "source": [
        "feat_gat_tr = pd.read_csv(\"/content/drive/MyDrive/talkingdata-mobile-user-demographics/gender_age_train.csv\",index_col='device_id')\n",
        "feat_gat_test = pd.read_csv(\"/content/drive/MyDrive/talkingdata-mobile-user-demographics/gender_age_test.csv\",index_col='device_id')\n",
        "feat_ph=pd.read_csv(\"/content/drive/MyDrive/talkingdata-mobile-user-demographics/phone_brand_device_model.csv\")\n",
        "feat_app_lab=pd.read_csv('/content/drive/MyDrive/talkingdata-mobile-user-demographics/app_labels.csv')\n",
        "feat_lab_cat=pd.read_csv(\"/content/drive/MyDrive/talkingdata-mobile-user-demographics/label_categories.csv\")\n",
        "feat_ap_eve=pd.read_csv(\"/content/drive/MyDrive/talkingdata-mobile-user-demographics/app_events.csv\", dtype={'is_active':bool})\n",
        "feat_eve = pd.read_csv('/content/drive/MyDrive/talkingdata-mobile-user-demographics/events.csv',  parse_dates=['timestamp'],index_col='event_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fRW1JpaM0EG"
      },
      "outputs": [],
      "source": [
        "#removing duplicate device id's\n",
        "feat_ph = feat_ph.drop_duplicates('device_id',keep='first').set_index('device_id') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_pcD6fEM0EH",
        "outputId": "472befad-aaa2-4f75-cfb7-7949c1e25634"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(74645, 3)\n",
            "(112071, 0)\n",
            "(186716, 2)\n",
            "(459943, 2)\n",
            "(930, 2)\n",
            "(32473067, 4)\n",
            "(3252950, 4)\n"
          ]
        }
      ],
      "source": [
        "print(feat_gat_tr.shape)\n",
        "print(feat_gat_test.shape)\n",
        "print(feat_ph.shape)\n",
        "print(feat_app_lab.shape)\n",
        "print(feat_lab_cat.shape)\n",
        "print(feat_ap_eve.shape)\n",
        "print(feat_eve.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6LbsWmvM0EI"
      },
      "source": [
        "# SPLITTING THE DATA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BF5DU0GCM0EI"
      },
      "source": [
        "SOME DEVICES HAVE EVENTS INFORMATION AND SOME DEVICES DOES NOT HAVE EVENT INFORMTION.\n",
        "1. SO WE DIVIDE THE DATA INTO TRAIN AND TEST IN BOTH EVENTS AND NO EVENTS DATA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTm5V258M0EJ"
      },
      "outputs": [],
      "source": [
        "#https://docs.scipy.org/doc/numpy/reference/generated/numpy.in1d.html\n",
        "feat_mas=np.in1d(feat_gat_tr.index,feat_eve[\"device_id\"].values)\n",
        "feat_gatr_eve= feat_gat_tr[feat_mas]\n",
        "\n",
        "feat_mas=np.in1d(feat_gat_test.index,feat_eve[\"device_id\"].values)\n",
        "feat_gate_eve= feat_gat_test[feat_mas]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9lqO96RM0EK"
      },
      "outputs": [],
      "source": [
        "#https://docs.scipy.org/doc/numpy/reference/generated/numpy.in1d.html\n",
        "feat_mas=np.in1d(feat_gat_tr.index,feat_eve[\"device_id\"].values,invert=True)\n",
        "feat_gatr_noeve= feat_gat_tr[feat_mas]\n",
        "\n",
        "feat_mas=np.in1d(feat_gat_test.index,feat_eve[\"device_id\"].values,invert=True)\n",
        "feat_gate_noeve= feat_gat_test[feat_mas]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OiqKh-xZM0EL"
      },
      "outputs": [],
      "source": [
        "#Each row of is given by a unique integer as an identifier\n",
        "\n",
        "feat_gat_tr['trainrow'] = np.arange(feat_gat_tr.shape[0])\n",
        "feat_gat_test['testrow'] = np.arange(feat_gat_test.shape[0])\n",
        "\n",
        "feat_gatr_eve['trainrow']=np.arange(feat_gatr_eve.shape[0])\n",
        "feat_gate_eve['testrow']=np.arange(feat_gate_eve.shape[0])\n",
        "\n",
        "feat_gatr_noeve['trainrow']=np.arange(feat_gatr_noeve.shape[0])\n",
        "feat_gate_noeve['testrow']=np.arange(feat_gate_noeve.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JREHBf6_M0EM",
        "outputId": "65ad8fa2-5d56-4f9e-a33b-c87b067053f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train data with events information: (23309, 4)\n",
            "train data without events information: (51336, 4)\n",
            "test data with events information: (35194, 1)\n",
            "test data without events information: (76877, 1)\n"
          ]
        }
      ],
      "source": [
        "print(\"train data with events information:\",feat_gatr_eve.shape)\n",
        "print(\"train data without events information:\",feat_gatr_noeve.shape)\n",
        "print(\"test data with events information:\",feat_gate_eve.shape)\n",
        "print(\"test data without events information:\",feat_gate_noeve.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONRsIWDwM0EN"
      },
      "source": [
        "# VECTORIZING PHONE BRAND"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5Jc1rpxM0EN"
      },
      "outputs": [],
      "source": [
        "feat_br_encoder = LabelEncoder().fit(feat_ph.phone_brand)\n",
        "feat_ph['brand'] = feat_br_encoder.transform(feat_ph['phone_brand'])\n",
        "nbrand=len(feat_br_encoder.classes_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwJXa1PSM0EO"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('brandencoder','wb') as fp:\n",
        "    pickle.dump(feat_br_encoder,fp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1sMtYfhM0EO"
      },
      "source": [
        "# VECTORIZING PHONE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pn5POW9CM0EO"
      },
      "outputs": [],
      "source": [
        "m = feat_ph.phone_brand.str.cat(feat_ph.device_model)\n",
        "#m=feat_ph['phone_brand'].str.cat(feat_ph['device_model'])\n",
        "feat_mod_encodr = LabelEncoder().fit(m)\n",
        "feat_ph['model'] = feat_mod_encodr.transform(m)\n",
        "nmodel=len(feat_mod_encodr.classes_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZchnRHaYM0EP"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('feat_mod_encodr','wb') as fp:\n",
        "    pickle.dump(feat_mod_encodr,fp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3tR9pKbM0EP"
      },
      "source": [
        "# FEATURES USING APP ID'S"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkkeO7YBM0EP",
        "outputId": "e1da74bc-eef4-4230-e515-169304e45202"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>device_id</th>\n",
              "      <th>app</th>\n",
              "      <th>size</th>\n",
              "      <th>trainrow</th>\n",
              "      <th>testrow</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-9222956879900151005</td>\n",
              "      <td>548</td>\n",
              "      <td>18</td>\n",
              "      <td>5145.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-9222956879900151005</td>\n",
              "      <td>1096</td>\n",
              "      <td>18</td>\n",
              "      <td>5145.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-9222956879900151005</td>\n",
              "      <td>1248</td>\n",
              "      <td>26</td>\n",
              "      <td>5145.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-9222956879900151005</td>\n",
              "      <td>1545</td>\n",
              "      <td>12</td>\n",
              "      <td>5145.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-9222956879900151005</td>\n",
              "      <td>1664</td>\n",
              "      <td>18</td>\n",
              "      <td>5145.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             device_id   app  size  trainrow  testrow\n",
              "0 -9222956879900151005   548    18    5145.0      NaN\n",
              "1 -9222956879900151005  1096    18    5145.0      NaN\n",
              "2 -9222956879900151005  1248    26    5145.0      NaN\n",
              "3 -9222956879900151005  1545    12    5145.0      NaN\n",
              "4 -9222956879900151005  1664    18    5145.0      NaN"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#https://www.kaggle.com/dvasyukova/a-linear-model-on-apps-and-labels\n",
        "#number of times app used in a device id's\n",
        "feat_app_encodr = LabelEncoder().fit(feat_ap_eve['app_id'])\n",
        "feat_ap_eve['app'] = feat_app_encodr.transform(feat_ap_eve['app_id'])\n",
        "\n",
        "\n",
        "napps = len(feat_app_encodr.classes_)\n",
        "\n",
        "feat_devic_aps = (feat_ap_eve.merge(feat_eve[['device_id']], how='left',left_on='event_id',right_index=True)\n",
        "                       .groupby(['device_id','app'])['app'].agg(['size'])# grouping by device id and app and finding size of app\n",
        "                       .merge(feat_gatr_eve[['trainrow']], how='left', left_index=True, right_index=True)#finding trainrow\n",
        "                       .merge(feat_gate_eve[['testrow']], how='left', left_index=True, right_index=True)#finding testrow\n",
        "                       .reset_index())\n",
        "feat_devic_aps.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cB29sFeaM0EQ",
        "outputId": "5599be5d-2063-4706-cf70-9fd5d53f69db"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2369025, 5)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feat_devic_aps.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBwnXQNXM0EQ"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('feat_app_encodr','wb') as fp:\n",
        "    pickle.dump(feat_app_encodr,fp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnRDDYyMM0EQ"
      },
      "source": [
        "# FEATURES USING APP LABELS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDeYkNtSM0ER"
      },
      "outputs": [],
      "source": [
        "feat_app_lab = feat_app_lab.loc[feat_app_lab.app_id.isin(feat_ap_eve.app_id.unique())]\n",
        "feat_app_lab['app'] = feat_app_encodr.transform(feat_app_lab.app_id)\n",
        "feat_lab_encodr = LabelEncoder().fit(feat_app_lab.label_id)\n",
        "feat_app_lab['label'] = feat_lab_encodr.transform(feat_app_lab.label_id)\n",
        "nlabels = len(feat_lab_encodr.classes_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzUMrH8hM0ER"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('feat_lab_encodr','wb') as fp:\n",
        "    pickle.dump(feat_lab_encodr,fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zm0WDjFQM0ER",
        "outputId": "455e2d5a-1080-47b7-c19e-679262fbf0ce"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>device_id</th>\n",
              "      <th>label</th>\n",
              "      <th>size</th>\n",
              "      <th>trainrow</th>\n",
              "      <th>testrow</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-9222956879900151005</td>\n",
              "      <td>117</td>\n",
              "      <td>1</td>\n",
              "      <td>5145.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-9222956879900151005</td>\n",
              "      <td>120</td>\n",
              "      <td>1</td>\n",
              "      <td>5145.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-9222956879900151005</td>\n",
              "      <td>126</td>\n",
              "      <td>1</td>\n",
              "      <td>5145.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-9222956879900151005</td>\n",
              "      <td>138</td>\n",
              "      <td>2</td>\n",
              "      <td>5145.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-9222956879900151005</td>\n",
              "      <td>147</td>\n",
              "      <td>2</td>\n",
              "      <td>5145.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             device_id  label  size  trainrow  testrow\n",
              "0 -9222956879900151005    117     1    5145.0      NaN\n",
              "1 -9222956879900151005    120     1    5145.0      NaN\n",
              "2 -9222956879900151005    126     1    5145.0      NaN\n",
              "3 -9222956879900151005    138     2    5145.0      NaN\n",
              "4 -9222956879900151005    147     2    5145.0      NaN"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feat_devic_lab = (feat_devic_aps[['device_id','app']]\n",
        "                .merge(feat_app_lab[['app','label']])\n",
        "                .groupby(['device_id','label'])['app'].agg(['size'])\n",
        "                .merge(feat_gatr_eve[['trainrow']], how='left', left_index=True, right_index=True)\n",
        "                .merge(feat_gate_eve[['testrow']], how='left', left_index=True, right_index=True)\n",
        "                .reset_index())\n",
        "feat_devic_lab.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZLFgDZsM0ES",
        "outputId": "46bf35d0-aaa0-4093-fb38-f4d471deaff1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4244113, 5)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feat_devic_lab.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFU2eBdSM0ES"
      },
      "source": [
        "# FEATURES USING TIME FEATURE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPqcXbayM0ES"
      },
      "outputs": [],
      "source": [
        "#we are processing timestamp feature to get hour and day and dividing into 4 bins\n",
        "feat_eve['hour'] = feat_eve['timestamp'].map(lambda x:pd.to_datetime(x).hour)\n",
        "feat_eve['hourbin'] = [1 if ((x>=1)&(x<=6)) else 2 if ((x>=7)&(x<=12)) else 3 if ((x>=13)&(x<=18)) else 4 for x in feat_eve['hour']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dp3AhZT5M0ES"
      },
      "outputs": [],
      "source": [
        "feat_eve.hour=feat_eve.hour.astype(str)\n",
        "feat_eve.hourbin=feat_eve.hourbin.astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyNkaIGSM0ES"
      },
      "outputs": [],
      "source": [
        "feat_hr_join = feat_eve.groupby(\"device_id\")[\"hour\"].apply(lambda x: \" \".join('0'+str(s) for s in x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3dFalizFM0ET"
      },
      "outputs": [],
      "source": [
        "feat_hr_bin_join=feat_eve.groupby(\"device_id\")[\"hourbin\"].apply(lambda x: \" \".join('0'+str(s) for s in x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRrmaTAgM0ET"
      },
      "outputs": [],
      "source": [
        "feat_days_join=feat_eve['timestamp'].dt.day_name()\n",
        "feat_eve['day']=feat_days_join.map({'Sunday':0,'Monday':1,'Tuesday':2,'Wednesday':3,'Thursday':4,'Friday':5,'Saturday':6})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlLYZl--M0ET"
      },
      "outputs": [],
      "source": [
        "feat_days_join = feat_eve.groupby(\"device_id\")[\"day\"].apply(lambda x: \" \".join(\"0\"+str(s) for s in x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1R_SP2BM0ET"
      },
      "source": [
        "# FEATURES USING LATITUDE AND LONGITUDE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMCXiZz2M0ET"
      },
      "outputs": [],
      "source": [
        "feat_med_lat = feat_eve.groupby(\"device_id\")[\"latitude\"].agg('median')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRG7P0-0M0EU"
      },
      "outputs": [],
      "source": [
        "feat_med_lon=feat_eve.groupby(\"device_id\")[\"longitude\"].agg('median')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_smpwpfvM0EU"
      },
      "source": [
        "WE ARE CLUSTERING MEDIAN LATITUDES AND LONGITUDES IN TO 10 CLUSTERS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSCDpAutM0EU"
      },
      "outputs": [],
      "source": [
        "feat_com=pd.concat([feat_med_lat, feat_med_lon], axis=1)\n",
        "kmeans = KMeans(n_clusters=10, random_state=0).fit(feat_com)\n",
        "feat_clustrd_geo_featrs=pd.Series(kmeans.labels_)\n",
        "feat_clustrd_geo_featrs.index=feat_med_lon.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIMBveyAM0EU",
        "outputId": "e892f78c-b8b8-47e1-9ba8-eac6e7d2e19e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([5, 1, 1, ..., 1, 4, 1])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "kmeans.labels_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kbNtJcPM0EU"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('kmeans_labels','wb') as fp:\n",
        "    pickle.dump(kmeans.labels_,fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmDhEpsfM0EV",
        "outputId": "260f7430-42a0-4b17-eca5-0cb9067e04ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Int64Index([-9222956879900151005, -9222661944218806987, -9222399302879214035,\n",
            "            -9221825537663503111, -9221767098072603291, -9221079146476055829,\n",
            "            -9221026417907250887, -9220830859283101130, -9220452176650064280,\n",
            "            -9220329415676028483,\n",
            "            ...\n",
            "             9219164468944552013,  9219842210460037807,  9219937375310355234,\n",
            "             9220562120895859549,  9220814716773471568,  9220914901466458680,\n",
            "             9221586026451102237,  9222110179000857683,  9222355582733155698,\n",
            "             9222539910510672930],\n",
            "           dtype='int64', name='device_id', length=60865)\n"
          ]
        }
      ],
      "source": [
        "feat_clustrd_geo_featrs.index=feat_med_lon.index\n",
        "print(feat_clustrd_geo_featrs.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZ99p0-BM0EV"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgIm0yh1M0EV"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('n_clusters','wb') as fp:\n",
        "    pickle.dump(kmeans,fp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsNYIIzJM0EV"
      },
      "source": [
        "# FEATURES BASED ON ACTIVE APPS AND APP COUNT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJPOxBEXM0EV"
      },
      "outputs": [],
      "source": [
        "feat_aps = feat_ap_eve.groupby(\"event_id\")[\"is_active\"].apply(lambda x: \" \".join(str(s) for s in x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NL-PfRw1M0EW",
        "outputId": "64af8a28-81e4-4b47-b00a-70e500f14926"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1488096,)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feat_aps.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MetOmvsoM0EW"
      },
      "outputs": [],
      "source": [
        "feat_eve[\"apps_active\"] = feat_eve.index.map(apps)\n",
        "feat_actv_aps_eve = feat_eve.groupby(\"device_id\")[\"apps_active\"].apply(lambda x: \" \".join(str(s) for s in x if str(s)!='nan'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wlz6ZiheM0EW"
      },
      "source": [
        "\n",
        "# MODELLING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-ceZU0GM0EW"
      },
      "source": [
        "# ONE HOT ENCODING OF PHONE BRAND"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iE47DB-DM0EW"
      },
      "outputs": [],
      "source": [
        "feat_gat_tr['brand'] = feat_ph['brand']\n",
        "feat_gat_test['brand'] = feat_ph['brand']\n",
        "\n",
        "feat_Xtr_br = csr_matrix((np.ones(feat_gat_tr.shape[0]), \n",
        "                       (feat_gat_tr.trainrow, feat_gat_tr.brand)))\n",
        "feat_Xte_br = csr_matrix((np.ones(feat_gat_test.shape[0]), \n",
        "                       (feat_gat_test.testrow, feat_gat_test.brand)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAWxLhWcM0EW",
        "outputId": "e0b8d16e-5e6c-4e4d-9f36-959786d3474b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(74645, 5)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feat_gat_tr.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jj_0UTq5M0EX",
        "outputId": "4c705d7c-e835-4023-9e2f-b81bbbc503c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(74645, 77)\n",
            "(112071, 77)\n"
          ]
        }
      ],
      "source": [
        "feat_gat_tr['brand'] = feat_ph['brand']\n",
        "feat_gat_test['brand'] = feat_ph['brand']\n",
        "\n",
        "feat_gat_tr['brand'] = str(feat_gat_tr['brand'])\n",
        "feat_gat_test['brand'] = str(feat_gat_test['brand'])\n",
        "\n",
        "feat_vectorzr = CountVectorizer(lowercase = True)\n",
        "feat_vectorzr.fit(feat_gat_tr['brand'])\n",
        "feat_tr_br_onehot = feat_vectorzr.transform(feat_gat_tr['brand'].values)\n",
        "feat_te_br_onehot = feat_vectorzr.transform(feat_gat_test['brand'].values)\n",
        "print(feat_tr_br_onehot.shape)\n",
        "print(feat_te_br_onehot.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAznww_sM0EX"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('brand_onehot','wb') as fp:\n",
        "    pickle.dump(feat_vectorzr,fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwWw8ckKM0EX",
        "outputId": "d83a0846-4c4f-4d8e-d740-816c67b99719"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(74645, 131)\n",
            "(112071, 131)\n"
          ]
        }
      ],
      "source": [
        "print(feat_Xtr_br.shape)\n",
        "print(feat_Xte_br.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sVA_08yM0EX"
      },
      "source": [
        "# ONE HOT ENCODING OF PHONE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zf6llWNZM0EX",
        "outputId": "dd6e0d08-c130-461d-9823-59e34172f2ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(74645, 1667)\n",
            "(112071, 1667)\n"
          ]
        }
      ],
      "source": [
        "feat_gat_tr['model'] = feat_ph['model']\n",
        "feat_gat_test['model'] = feat_ph['model']\n",
        "\n",
        "feat_Xtr_mod = csr_matrix((np.ones(feat_gat_tr.shape[0]), \n",
        "                       (feat_gat_tr.trainrow, feat_gat_tr.model)))\n",
        "feat_Xte_mod = csr_matrix((np.ones(feat_gat_test.shape[0]), \n",
        "                       (feat_gat_test.testrow, feat_gat_test.model)))\n",
        "print(feat_Xtr_mod.shape)\n",
        "print(feat_Xte_mod.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wb0uIY6oM0EY",
        "outputId": "771cd8ac-ede3-40f3-ef5f-8a3eda907669"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(74645, 98)\n",
            "(112071, 98)\n"
          ]
        }
      ],
      "source": [
        "feat_gat_tr['model'] = feat_ph['model']\n",
        "feat_gat_test['model'] = feat_ph['model']\n",
        "\n",
        "feat_gat_tr['model'] = str(feat_gat_tr['model'])\n",
        "feat_gat_test['model'] = str(feat_gat_test['model'])\n",
        "\n",
        "feat_vectorzr = CountVectorizer(lowercase = True)\n",
        "feat_vectorzr.fit(feat_gat_tr['model'])\n",
        "feat_tr_mod_onehot = feat_vectorzr.transform(feat_gat_tr['model'].values)\n",
        "feat_te_mod_onehot = feat_vectorzr.transform(feat_gat_test['model'].values)\n",
        "print(feat_tr_mod_onehot.shape)\n",
        "print(feat_te_mod_onehot.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpV6bYKYM0EY"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('model_onehot','wb') as fp:\n",
        "    pickle.dump(feat_vectorzr,fp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anCPP8bHM0EY"
      },
      "source": [
        "# ONE HOT ENCODING OF DEVICE APPS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "syJgUSQpM0EY",
        "outputId": "09f547d3-653a-43d3-80aa-4da454d2a78d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(74645, 19237)\n",
            "(112071, 19237)\n"
          ]
        }
      ],
      "source": [
        "d = feat_devic_aps.dropna(subset=['trainrow'])\n",
        "feat_Xtr_ap = csr_matrix((np.ones(d.shape[0]), (d.trainrow, d.app)), \n",
        "                      shape=(feat_gat_tr.shape[0],napps))\n",
        "d = feat_devic_aps.dropna(subset=['testrow'])\n",
        "feat_Xte_ap = csr_matrix((np.ones(d.shape[0]), (d.testrow, d.app)), \n",
        "                      shape=(feat_gat_test.shape[0],napps))\n",
        "\n",
        "print(feat_Xtr_ap.shape)\n",
        "print(feat_Xte_ap.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ALWAsDhM0EZ"
      },
      "source": [
        "# ONE HOT ENCODING OF APP CATEGORY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pokn-zFuM0EZ",
        "outputId": "fc059db2-5bc5-48df-f735-570f0647048c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(74645, 492)\n",
            "(112071, 492)\n"
          ]
        }
      ],
      "source": [
        "d = feat_devic_lab.dropna(subset=['trainrow'])\n",
        "feat_Xtr_lab = csr_matrix((np.ones(d.shape[0]), (d.trainrow, d.label)), \n",
        "                      shape=(feat_gat_tr.shape[0],nlabels))\n",
        "d = feat_devic_lab.dropna(subset=['testrow'])\n",
        "feat_Xte_lab = csr_matrix((np.ones(d.shape[0]), (d.testrow, d.label)), \n",
        "                      shape=(feat_gat_test.shape[0],nlabels))\n",
        "\n",
        "print(feat_Xtr_lab.shape)\n",
        "print(feat_Xte_lab.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ztx9Iy-VM0EZ",
        "outputId": "03c6fe34-60fc-49ac-d319-ded3f2b93c9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train data shape: (74645, 21527)\n",
            "Test data shape: (112071, 21527)\n"
          ]
        }
      ],
      "source": [
        "#hstacking all the features\n",
        "feat_Xtr = hstack((feat_Xtr_br, feat_Xtr_mod, feat_Xtr_ap, feat_Xtr_lab), format='csr')\n",
        "feat_Xte =  hstack((feat_Xte_br, feat_Xte_mod, feat_Xte_ap, feat_Xte_lab), format='csr')\n",
        "print('Train data shape:',feat_Xtr.shape)\n",
        "print('Test data shape:',feat_Xte.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucyL_uupM0EZ"
      },
      "outputs": [],
      "source": [
        "#applying applying label encoding on target variable\n",
        "feat_targt_encod = LabelEncoder().fit(feat_gat_tr.group)\n",
        "feat_y = feat_targt_encod.transform(feat_gat_tr.group)\n",
        "nclasses = len(feat_targt_encod.classes_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSKvPlfbM0EZ"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('classlabel','wb') as fp:\n",
        "    pickle.dump(feat_y,fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nN1jhWJ2M0Ea",
        "outputId": "39cb1a83-b06a-4cb7-d7f3-35fbe3908305"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(63448, 21527) (63448,)\n",
            "(11197, 21527) (11197,)\n"
          ]
        }
      ],
      "source": [
        "#splitting data into train and validation\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "xtr, xcv, ytr, ycv = train_test_split(feat_Xtr, y,stratify=feat_y,test_size=0.15)\n",
        "print(xtr.shape,ytr.shape)\n",
        "print(xcv.shape,ycv.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdqTna-fM0Ea"
      },
      "source": [
        "# LOGISTIC REGRESSION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDENnDStM0Ea",
        "outputId": "c8ae1cd1-15a7-4e5c-e7d9-02b379255ab8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for c =  1e-05\n",
            "for c =  1e-05 the log loss is : 2.4240490121671416\n",
            "for c =  0.0001\n",
            "for c =  0.0001 the log loss is : 2.4239127140248673\n",
            "for c =  0.001\n",
            "for c =  0.001 the log loss is : 2.421898251247192\n",
            "for c =  0.01\n",
            "for c =  0.01 the log loss is : 2.4034478389221365\n",
            "for c =  0.1\n",
            "for c =  0.1 the log loss is : 2.408299979523952\n",
            "for c =  1\n",
            "for c =  1 the log loss is : 2.4181286899702306\n",
            "for c =  10\n",
            "for c =  10 the log loss is : 2.42395984079844\n",
            "for c =  100\n",
            "for c =  100 the log loss is : 2.4254481618915733\n",
            "for c =  1000\n",
            "for c =  1000 the log loss is : 2.425641919967717\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "feat_alph = [0.00001,0.0001,0.001,0.01,0.1,1,10,100,1000]\n",
        "feat_cv_log_er = []\n",
        "for i in feat_alph:\n",
        "    print('for c = ',i)\n",
        "    feat_SGD  = LogisticRegression(class_weight = 'balanced',penalty = 'l2',C = i)\n",
        "    feat_clf =  feat_SGD.fit(xtr,ytr)\n",
        "    feat_sgd_clib = CalibratedClassifierCV(feat_clf,method = 'sigmoid') \n",
        "    feat_sgd_clib.fit(xtr,ytr)\n",
        "    feat_y_cv_pred = feat_sgd_clib.predict_proba(xcv)\n",
        "    #feat_cv_log_er.append(log_loss(y_cv,feat_y_cv_pred))\n",
        "    print('for c = ',i ,'the log loss is :',log_loss(ycv,feat_y_cv_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7P-hnjBwM0Ea"
      },
      "source": [
        "WE CHOSE OUR BEST C TO BE 0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cp8COFi4M0Ea",
        "outputId": "cd50f58a-dcd5-4da4-9e26-d6b3f3a410cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The train log loss for best C is: 2.4145317866106\n",
            "The validation log loss for best C is: 2.354060651561517\n"
          ]
        }
      ],
      "source": [
        "feat_clf = LogisticRegression(C=0.01, class_weight='balanced', multi_class='multinomial', solver='lbfgs')\n",
        "feat_clf.fit(xtr, ytr)\n",
        "feat_sig_clf = CalibratedClassifierCV(feat_clf, method=\"sigmoid\")\n",
        "feat_sig_clf.fit(xcv, ycv)\n",
        "\n",
        "feat_pred_y = feat_sig_clf.predict_proba(xtr)\n",
        "feat_loss=log_loss(ytr, feat_pred_y)\n",
        "print(\"The train log loss for best C is:\",feat_loss)\n",
        "feat_pred_y = feat_sig_clf.predict_proba(xcv)\n",
        "feat_loss=log_loss(ycv, feat_pred_y)\n",
        "print(\"The validation log loss for best C is:\",feat_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbiPwHwNM0Ea"
      },
      "source": [
        "# MODELLING USING DEVICES WITHOUT EVENTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_a4QONEM0Eb"
      },
      "outputs": [],
      "source": [
        "feat_Xtr_whol = hstack((feat_Xtr_br, feat_Xtr_mod), format='csr')\n",
        "\n",
        "feat_targt_encod = LabelEncoder().fit(feat_gat_tr.group)\n",
        "feat_y = feat_targt_encod.transform(feat_gat_tr.group)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-juHl-OhM0Eb"
      },
      "outputs": [],
      "source": [
        "feat_gate_noeve['model']=feat_ph['model']\n",
        "feat_gate_noeve['brand']=feat_ph['brand']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyiEUJ0sM0Eb",
        "outputId": "ae67f2ae-636d-4b59-e0bb-ad1e2b6c699c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(76877, 3)"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtyk2HpYM0Eb"
      },
      "outputs": [],
      "source": [
        "feat_gate_noeve_mod = csr_matrix((np.ones(feat_gate_noeve.shape[0]), \n",
        "                       (feat_gate_noeve.testrow, feat_gate_noeve.model)))\n",
        "\n",
        "feat_gate_noeve_br= csr_matrix((np.ones(feat_gate_noeve.shape[0]), \n",
        "                       (feat_gate_noeve.testrow, feat_gate_noeve.brand)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1ARq26oM0Eb"
      },
      "outputs": [],
      "source": [
        "feat_Xte_no_eve=hstack((feat_gate_noeve_br, feat_gate_noeve_mod), format='csr')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "noSXkqnEM0Eb"
      },
      "outputs": [],
      "source": [
        "feat_xte_no_eve_1=hstack((feat_gate_noeve_br, feat_gate_noeve_mod), format='csr')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MB6dUaPyM0Ec",
        "outputId": "8299acd3-4943-42a1-f709-3de3d46dc2be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(76877, 1667)\n"
          ]
        }
      ],
      "source": [
        "print(feat_gate_noeve_mod.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omlFlpr5M0Ec"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('model_onehot','rb') as fp:\n",
        "  model_onehot = pickle.load(fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29REEIMZM0Ec"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('brand_onehot','rb') as fp:\n",
        "  brand_onehot = pickle.load(fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFS754aTM0Ec",
        "outputId": "aa28f83a-6438-4458-f972-00b464b661d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(76877, 77)\n",
            "(76877, 98)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "feat_gate_noeve['model'] = feat_ph['model']\n",
        "feat_gate_noeve['brand'] = feat_ph['brand']\n",
        "\n",
        "feat_gate_noeve['model'] = str(feat_gate_noeve['model'])\n",
        "feat_gate_noeve['brand'] = str(feat_gate_noeve['brand'])\n",
        "\n",
        "feat_noeve_test_br_onehot = brand_onehot.transform(feat_gate_noeve['brand'])\n",
        "feat_noeve_test_mod_onehot = model_onehot.transform(feat_gate_noeve['model'])\n",
        "print(feat_noeve_test_br_onehot.shape)\n",
        "print(feat_noeve_test_mod_onehot.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtOnEIt4M0Ec"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R07NBBmdM0Ec",
        "outputId": "2c68f1bf-31c0-4557-bff6-98c5a4c75c58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(74645, 175)\n",
            "(76877, 175)\n"
          ]
        }
      ],
      "source": [
        "feat_Xtr = hstack((feat_tr_mod_onehot,feat_tr_br_onehot)).tocsr()\n",
        "feat_xte_no_eve_onehot = hstack((feat_noeve_test_mod_onehot,feat_noeve_test_br_onehot)).tocsr()\n",
        "print(feat_Xtr.shape)\n",
        "print(feat_Xte.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4HfBdFMM0Ed",
        "outputId": "9b6fbfa1-6b9e-4d4b-ae8b-db7d5aebe780"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "xtrain shape: (74645, 1798)\n",
            "ytrain shape: (74645,)\n",
            "xtest shape: (76877, 1798)\n"
          ]
        }
      ],
      "source": [
        "print(\"xtrain shape:\",feat_Xtr_wh.shape)\n",
        "print(\"ytrain shape:\",feat_y.shape)\n",
        "\n",
        "print(\"xtest shape:\",feat_Xte_no_eve.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2eHlC9VM0Ed"
      },
      "outputs": [],
      "source": [
        "xtr, xcv, ytr, ycv = train_test_split(feat_Xtr_wh, y,stratify=feat_y,test_size=0.15,random_state=18)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilPdqjx5M0Ed"
      },
      "outputs": [],
      "source": [
        "xtr, xcv, ytr, ycv = train_test_split(feat_xtr, y,stratify=feat_y,test_size=0.15,random_state=18)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bk68j07CM0Ed",
        "outputId": "57a0ba49-6820-4bdd-8099-dd256291b335"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(63448, 175) (63448,)\n",
            "(11197, 175) (11197,)\n"
          ]
        }
      ],
      "source": [
        "print(xtr.shape,ytr.shape)\n",
        "print(xcv.shape,ycv.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oQmQfTqM0Ed"
      },
      "source": [
        "# LOGISTIC REGRESSION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INKxzi-5M0Ed",
        "outputId": "1474b845-2bec-4915-d983-0c4ff9584f4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For values of C =  0.001 The validation log loss is: 2.4030020103020036\n",
            "For values of C =  0.01 The validation log loss is: 2.39641152579951\n",
            "For values of C =  0.02 The validation log loss is: 2.3940695248817785\n",
            "For values of C =  0.1 The validation log loss is: 2.3896730084069544\n",
            "For values of C =  0.15 The validation log loss is: 2.3891201368497037\n",
            "For values of C =  1 The validation log loss is: 2.39105667945638\n",
            "For values of C =  10 The validation log loss is: 2.398847882073424\n"
          ]
        }
      ],
      "source": [
        "feat_alph = [0.001,0.01,0.02,0.1,0.15,1,10]\n",
        "\n",
        "\n",
        "for i in feat_alph:\n",
        "    feat_clf = LogisticRegression(C=i, class_weight='balanced', multi_class='multinomial',solver='lbfgs')\n",
        "    feat_clf.fit(xtr, ytr)\n",
        "    #Using Model Calibration\n",
        "    feat_sig_clf = CalibratedClassifierCV(feat_clf, method=\"sigmoid\")\n",
        "    feat_sig_clf.fit(xtr, ytr)\n",
        "    feat_pred_y = feat_sig_clf.predict_proba(xcv)\n",
        "    print('For values of C = ', i, \"The validation log loss is:\",log_loss(ycv, feat_pred_y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8-Me1yyM0Ee"
      },
      "source": [
        "WE CHOSE OUR BEST C TO BE 0.15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmgaDZgRM0Ee",
        "outputId": "6bf4368c-8615-4e15-a4b1-ee5610fbfe75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The train log loss for best C is: 2.362802878894095\n",
            "The validation log loss for best C is: 2.3891201368497037\n"
          ]
        }
      ],
      "source": [
        "feat_clf = LogisticRegression(C=0.15, class_weight='balanced', multi_class='multinomial', solver='lbfgs')\n",
        "feat_clf.fit(xtr, ytr)\n",
        "feat_sig_clf = CalibratedClassifierCV(feat_clf, method=\"sigmoid\")\n",
        "feat_sig_clf.fit(xtr, ytr)\n",
        "\n",
        "feat_pred_y = feat_sig_clf.predict_proba(xtr)\n",
        "feat_loss=log_loss(ytr, feat_pred_y)\n",
        "print(\"The train log loss for best C is:\",feat_loss)\n",
        "feat_pred_y = feat_sig_clf.predict_proba(xcv)\n",
        "feat_loss=log_loss(ycv, feat_pred_y)\n",
        "print(\"The validation log loss for best C is:\",feat_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySA2NnmAM0Ee"
      },
      "outputs": [],
      "source": [
        "#predicting for test data\n",
        "feat_noeve_pred_lr=feat_sig_clf.predict_proba(feat_Xte_no_eve)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAyLVVmEM0Ee"
      },
      "outputs": [],
      "source": [
        "#saving the model\n",
        "from sklearn.externals import joblib as jobl\n",
        "from joblib import dump\n",
        "np.save('lr_noevents',feat_noeve_pred_lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fauzj9eBM0Ee"
      },
      "source": [
        "# OBSERVATIONS:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3zT8Us3M0Ef"
      },
      "source": [
        "FOR LOGISTIC REGRESSION MODEL TRAIN LOGLOSS IS 2.3628 AND VALIDATION LOSS IS 2.3891"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxBS2J7tM0Ef"
      },
      "source": [
        "# NEURAL NETWORKS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpSkHCdJM0Ef"
      },
      "outputs": [],
      "source": [
        "#https://www.kaggle.com/c/talkingdata-mobile-user-demographics/discussion/23424\n",
        "def feat_noeve_nn_mod_1(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(256, input_dim=input_shape))\n",
        "    model.add(PReLU())\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(64))\n",
        "    model.add(PReLU())\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(12))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAjcBYFTM0Ef",
        "outputId": "a43f4eae-cfd8-4eba-8cf1-bbd6a52624d0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0418 13:02:32.574199 32244 deprecation_wrapper.py:119] From c:\\users\\navee\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0418 13:02:32.589181 32244 deprecation_wrapper.py:119] From c:\\users\\navee\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0418 13:02:32.591156 32244 deprecation_wrapper.py:119] From c:\\users\\navee\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0418 13:02:32.648003 32244 deprecation_wrapper.py:119] From c:\\users\\navee\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0418 13:02:32.663927 32244 deprecation.py:506] From c:\\users\\navee\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0418 13:02:32.768647 32244 deprecation_wrapper.py:119] From c:\\users\\navee\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0418 13:02:32.782643 32244 deprecation_wrapper.py:119] From c:\\users\\navee\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 256)               45056     \n",
            "_________________________________________________________________\n",
            "p_re_lu_1 (PReLU)            (None, 256)               256       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "p_re_lu_2 (PReLU)            (None, 64)                64        \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 12)                780       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 12)                0         \n",
            "=================================================================\n",
            "Total params: 63,884\n",
            "Trainable params: 63,244\n",
            "Non-trainable params: 640\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "feat_modsum=feat_noeve_nn_mod_1(xtr.shape[1])\n",
        "feat_modsum.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bayG_cMNM0Ef"
      },
      "outputs": [],
      "source": [
        "feat_early_stop=EarlyStopping(monitor='val_loss',patience=5,restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYZSfvYjM0Ef"
      },
      "outputs": [],
      "source": [
        "def feat_noeve_avg_nn_1(state):\n",
        "    \"\"\"\n",
        "    Takes a list of Random Seeds, splits the data into Train and CV based on Seed, trains model and takes average of \n",
        "    predictions while testing  \n",
        "    \"\"\"\n",
        "    feat_mod_list=[]\n",
        "    feat_loss_list=[]\n",
        "    feat_avg_cv_los=0\n",
        "    for i in range(len(state)):\n",
        "        xtr, xcv, ytr, ycv = train_test_split(feat_Xtr_whol, y,stratify=y,test_size=0.15,random_state=state[i])\n",
        "        ytr=np_utils.to_categorical(ytr)\n",
        "        ycv=np_utils.to_categorical(ycv)\n",
        "        model=feat_noeve_nn_mod_1(xtr.shape[1])\n",
        "        model.fit(xtr, ytr, batch_size=256, epochs=20, verbose=1, validation_data=(xcv, ycv),callbacks=[early_stop])\n",
        "        model.save('saved_models/no_events/nn '+str(i+1))\n",
        "        feat_pred=model.predict_proba(xcv)\n",
        "        feat_cv_los=log_loss(ycv, feat_pred)\n",
        "        print(\"Validation Log Loss of  Model in Current Run: \",feat_cv_los)\n",
        "        feat_mod_list.append(model)\n",
        "        feat_loss_list.append(feat_cv_los)\n",
        "    feat_avg_cv_los=mean(feat_loss_list)\n",
        "    print(\"Average CV Loss of \"+str(len(state))+\" Runs :\",feat_avg_cv_los)\n",
        "    return(feat_mod_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1uJf8PZM0Eg",
        "outputId": "dd5cfd0f-e65a-48cb-adea-c6903f7b054c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0408 12:30:10.290519 11128 deprecation.py:323] From c:\\users\\navee\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 63448 samples, validate on 11197 samples\n",
            "Epoch 1/20\n",
            "63448/63448 [==============================] - 5s 74us/step - loss: 2.8828 - acc: 0.1041 - val_loss: 2.4166 - val_acc: 0.1458\n",
            "Epoch 2/20\n",
            "63448/63448 [==============================] - 4s 57us/step - loss: 2.4785 - acc: 0.1316 - val_loss: 2.3994 - val_acc: 0.1516\n",
            "Epoch 3/20\n",
            "63448/63448 [==============================] - 4s 56us/step - loss: 2.4185 - acc: 0.1435 - val_loss: 2.3957 - val_acc: 0.1517\n",
            "Epoch 4/20\n",
            "63448/63448 [==============================] - 4s 57us/step - loss: 2.3978 - acc: 0.1521 - val_loss: 2.3947 - val_acc: 0.1516\n",
            "Epoch 5/20\n",
            "63448/63448 [==============================] - 4s 57us/step - loss: 2.3890 - acc: 0.1560 - val_loss: 2.3926 - val_acc: 0.1566\n",
            "Epoch 6/20\n",
            "63448/63448 [==============================] - 4s 57us/step - loss: 2.3829 - acc: 0.1593 - val_loss: 2.3907 - val_acc: 0.1553\n",
            "Epoch 7/20\n",
            "63448/63448 [==============================] - 4s 58us/step - loss: 2.3777 - acc: 0.1592 - val_loss: 2.3904 - val_acc: 0.1561\n",
            "Epoch 8/20\n",
            "63448/63448 [==============================] - 4s 57us/step - loss: 2.3719 - acc: 0.1642 - val_loss: 2.3926 - val_acc: 0.1551\n",
            "Epoch 9/20\n",
            "63448/63448 [==============================] - 5s 77us/step - loss: 2.3668 - acc: 0.1660 - val_loss: 2.3933 - val_acc: 0.1521\n",
            "Epoch 10/20\n",
            "63448/63448 [==============================] - 4s 58us/step - loss: 2.3624 - acc: 0.1693 - val_loss: 2.3940 - val_acc: 0.1537\n",
            "Epoch 11/20\n",
            "63448/63448 [==============================] - 4s 57us/step - loss: 2.3596 - acc: 0.1686 - val_loss: 2.3960 - val_acc: 0.1566\n",
            "Epoch 12/20\n",
            "63448/63448 [==============================] - 4s 58us/step - loss: 2.3553 - acc: 0.1709 - val_loss: 2.3966 - val_acc: 0.1561\n",
            "Validation Log Loss of  Model in Current Run:  2.3904335856160874\n",
            "Train on 63448 samples, validate on 11197 samples\n",
            "Epoch 1/20\n",
            "63448/63448 [==============================] - 4s 68us/step - loss: 2.8901 - acc: 0.1050 - val_loss: 2.4086 - val_acc: 0.1483\n",
            "Epoch 2/20\n",
            "63448/63448 [==============================] - 4s 58us/step - loss: 2.4851 - acc: 0.1304 - val_loss: 2.3965 - val_acc: 0.1503\n",
            "Epoch 3/20\n",
            "63448/63448 [==============================] - 4s 58us/step - loss: 2.4164 - acc: 0.1452 - val_loss: 2.3923 - val_acc: 0.1521\n",
            "Epoch 4/20\n",
            "63448/63448 [==============================] - 4s 58us/step - loss: 2.3988 - acc: 0.1511 - val_loss: 2.3910 - val_acc: 0.1545\n",
            "Epoch 5/20\n",
            "63448/63448 [==============================] - 4s 57us/step - loss: 2.3909 - acc: 0.1551 - val_loss: 2.3895 - val_acc: 0.1581\n",
            "Epoch 6/20\n",
            "63448/63448 [==============================] - 7s 111us/step - loss: 2.3839 - acc: 0.1602 - val_loss: 2.3875 - val_acc: 0.1590\n",
            "Epoch 7/20\n",
            "63448/63448 [==============================] - 14s 220us/step - loss: 2.3763 - acc: 0.1614 - val_loss: 2.3882 - val_acc: 0.1587\n",
            "Epoch 8/20\n",
            "63448/63448 [==============================] - 11s 173us/step - loss: 2.3712 - acc: 0.1650 - val_loss: 2.3906 - val_acc: 0.1540\n",
            "Epoch 9/20\n",
            "63448/63448 [==============================] - 13s 205us/step - loss: 2.3678 - acc: 0.1648 - val_loss: 2.3915 - val_acc: 0.1565\n",
            "Epoch 10/20\n",
            "63448/63448 [==============================] - 8s 119us/step - loss: 2.3617 - acc: 0.1676 - val_loss: 2.3943 - val_acc: 0.1588\n",
            "Epoch 11/20\n",
            "63448/63448 [==============================] - 4s 70us/step - loss: 2.3578 - acc: 0.1698 - val_loss: 2.3937 - val_acc: 0.1561\n",
            "Validation Log Loss of  Model in Current Run:  2.387496891607927\n",
            "Train on 63448 samples, validate on 11197 samples\n",
            "Epoch 1/20\n",
            "63448/63448 [==============================] - 5s 75us/step - loss: 2.9050 - acc: 0.1012 - val_loss: 2.4104 - val_acc: 0.1475\n",
            "Epoch 2/20\n",
            "63448/63448 [==============================] - 5s 74us/step - loss: 2.4828 - acc: 0.1306 - val_loss: 2.3929 - val_acc: 0.1573\n",
            "Epoch 3/20\n",
            "63448/63448 [==============================] - 5s 72us/step - loss: 2.4167 - acc: 0.1447 - val_loss: 2.3902 - val_acc: 0.1551\n",
            "Epoch 4/20\n",
            "63448/63448 [==============================] - 4s 64us/step - loss: 2.3989 - acc: 0.1521 - val_loss: 2.3881 - val_acc: 0.1549\n",
            "Epoch 5/20\n",
            "63448/63448 [==============================] - 4s 61us/step - loss: 2.3903 - acc: 0.1558 - val_loss: 2.3872 - val_acc: 0.1529\n",
            "Epoch 6/20\n",
            "63448/63448 [==============================] - 4s 66us/step - loss: 2.3836 - acc: 0.1597 - val_loss: 2.3859 - val_acc: 0.1531\n",
            "Epoch 7/20\n",
            "63448/63448 [==============================] - 4s 64us/step - loss: 2.3769 - acc: 0.1631 - val_loss: 2.3872 - val_acc: 0.1536\n",
            "Epoch 8/20\n",
            "63448/63448 [==============================] - 4s 61us/step - loss: 2.3725 - acc: 0.1632 - val_loss: 2.3876 - val_acc: 0.1551\n",
            "Epoch 9/20\n",
            "63448/63448 [==============================] - 4s 61us/step - loss: 2.3677 - acc: 0.1644 - val_loss: 2.3884 - val_acc: 0.1557\n",
            "Epoch 10/20\n",
            "63448/63448 [==============================] - 4s 61us/step - loss: 2.3629 - acc: 0.1673 - val_loss: 2.3891 - val_acc: 0.1536\n",
            "Epoch 11/20\n",
            "63448/63448 [==============================] - 4s 61us/step - loss: 2.3584 - acc: 0.1707 - val_loss: 2.3897 - val_acc: 0.1515\n",
            "Validation Log Loss of  Model in Current Run:  2.385876258398855\n",
            "Train on 63448 samples, validate on 11197 samples\n",
            "Epoch 1/20\n",
            "63448/63448 [==============================] - 5s 77us/step - loss: 2.9246 - acc: 0.1037 - val_loss: 2.4114 - val_acc: 0.1472\n",
            "Epoch 2/20\n",
            "63448/63448 [==============================] - 4s 60us/step - loss: 2.4911 - acc: 0.1277 - val_loss: 2.3947 - val_acc: 0.1546\n",
            "Epoch 3/20\n",
            "63448/63448 [==============================] - 4s 61us/step - loss: 2.4185 - acc: 0.1449 - val_loss: 2.3922 - val_acc: 0.1599\n",
            "Epoch 4/20\n",
            "63448/63448 [==============================] - 4s 61us/step - loss: 2.3997 - acc: 0.1498 - val_loss: 2.3902 - val_acc: 0.1589\n",
            "Epoch 5/20\n",
            "63448/63448 [==============================] - 4s 61us/step - loss: 2.3904 - acc: 0.1559 - val_loss: 2.3872 - val_acc: 0.1592\n",
            "Epoch 6/20\n",
            "63448/63448 [==============================] - 4s 61us/step - loss: 2.3835 - acc: 0.1580 - val_loss: 2.3859 - val_acc: 0.1575\n",
            "Epoch 7/20\n",
            "63448/63448 [==============================] - 4s 60us/step - loss: 2.3770 - acc: 0.1630 - val_loss: 2.3859 - val_acc: 0.1604\n",
            "Epoch 8/20\n",
            "63448/63448 [==============================] - 4s 62us/step - loss: 2.3712 - acc: 0.1643 - val_loss: 2.3878 - val_acc: 0.1576\n",
            "Epoch 9/20\n",
            "63448/63448 [==============================] - 4s 61us/step - loss: 2.3672 - acc: 0.1657 - val_loss: 2.3892 - val_acc: 0.1540\n",
            "Epoch 10/20\n",
            "63448/63448 [==============================] - 4s 61us/step - loss: 2.3621 - acc: 0.1685 - val_loss: 2.3910 - val_acc: 0.1550\n",
            "Epoch 11/20\n",
            "63448/63448 [==============================] - 4s 60us/step - loss: 2.3561 - acc: 0.1702 - val_loss: 2.3938 - val_acc: 0.1551\n",
            "Epoch 12/20\n",
            "63448/63448 [==============================] - 4s 61us/step - loss: 2.3556 - acc: 0.1705 - val_loss: 2.3955 - val_acc: 0.1526\n",
            "Validation Log Loss of  Model in Current Run:  2.3858903664887627\n",
            "Train on 63448 samples, validate on 11197 samples\n",
            "Epoch 1/20\n",
            "63448/63448 [==============================] - 5s 74us/step - loss: 2.8879 - acc: 0.1052 - val_loss: 2.4110 - val_acc: 0.1477\n",
            "Epoch 2/20\n",
            "63448/63448 [==============================] - 4s 64us/step - loss: 2.4786 - acc: 0.1328 - val_loss: 2.3959 - val_acc: 0.1496\n",
            "Epoch 3/20\n",
            "63448/63448 [==============================] - 4s 61us/step - loss: 2.4162 - acc: 0.1452 - val_loss: 2.3928 - val_acc: 0.1547\n",
            "Epoch 4/20\n",
            "63448/63448 [==============================] - 4s 62us/step - loss: 2.3994 - acc: 0.1505 - val_loss: 2.3921 - val_acc: 0.1572\n",
            "Epoch 5/20\n",
            "63448/63448 [==============================] - 4s 61us/step - loss: 2.3888 - acc: 0.1569 - val_loss: 2.3900 - val_acc: 0.1582\n",
            "Epoch 6/20\n",
            "63448/63448 [==============================] - 4s 60us/step - loss: 2.3838 - acc: 0.1582 - val_loss: 2.3888 - val_acc: 0.1557\n",
            "Epoch 7/20\n",
            "63448/63448 [==============================] - 4s 64us/step - loss: 2.3790 - acc: 0.1607 - val_loss: 2.3890 - val_acc: 0.1558\n",
            "Epoch 8/20\n",
            "63448/63448 [==============================] - 4s 64us/step - loss: 2.3711 - acc: 0.1645 - val_loss: 2.3896 - val_acc: 0.1553\n",
            "Epoch 9/20\n",
            "63448/63448 [==============================] - 4s 60us/step - loss: 2.3689 - acc: 0.1646 - val_loss: 2.3901 - val_acc: 0.1586\n",
            "Epoch 10/20\n",
            "63448/63448 [==============================] - 4s 62us/step - loss: 2.3624 - acc: 0.1682 - val_loss: 2.3915 - val_acc: 0.1549\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11/20\n",
            "63448/63448 [==============================] - 4s 58us/step - loss: 2.3586 - acc: 0.1698 - val_loss: 2.3907 - val_acc: 0.1541\n",
            "Validation Log Loss of  Model in Current Run:  2.3887528186292855\n",
            "Average CV Loss of 5 Runs : 2.3876899841481833\n"
          ]
        }
      ],
      "source": [
        "random_seeds=[9,18,42,86,103]\n",
        "model_list_1= feat_noeve_avg_nn_1(random_seeds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4iQCG57MM0Eg",
        "outputId": "ac9face5-48f5-4268-b658-b0eb7f189f93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Average Log-Loss:  2.3528577585587853\n"
          ]
        }
      ],
      "source": [
        "feat_avg_pred=np.zeros((xtr.shape[0],12))\n",
        "for i in range(len(model_list_1)):\n",
        "    feat_tr_pred=model_list_1[i].predict_proba(xtr)\n",
        "    feat_avg_pred+=feat_tr_pred\n",
        "feat_avg_pred/=len(model_list_1)\n",
        "print(\"Train Average Log-Loss: \",log_loss(ytr, feat_avg_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddOPMuuhM0Eg",
        "outputId": "540bc834-c732-4312-f187-57137767bee8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Average Log-Loss:  2.3577544682106013\n"
          ]
        }
      ],
      "source": [
        "feat_avg_pred=np.zeros((xcv.shape[0],12))\n",
        "for i in range(len(model_list_1)):\n",
        "    feat_cv_pred=model_list_1[i].predict_proba(xcv)\n",
        "    feat_avg_pred+=feat_cv_pred\n",
        "feat_avg_pred/=len(model_list_1)\n",
        "print(\"Validation Average Log-Loss: \",log_loss(ycv, feat_avg_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LGM3Il7M0Eh"
      },
      "outputs": [],
      "source": [
        "feat_avg_pred=np.zeros((xtest_noevents.shape[0],12))\n",
        "for i in range(len(model_list_1)):\n",
        "    feat_te_pred=model_list_1[i].predict_proba(feat_Xte_no_eve)\n",
        "    feat_avg_pred+=feat_te_pred\n",
        "feat_avg_pred/=len(model_list_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQRZHtBxM0Eh"
      },
      "outputs": [],
      "source": [
        "#saving the model\n",
        "np.save('nn1_noevents_1',feat_avg_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wB9Kzs7sM0Eh"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVKEm6mOM0Eh"
      },
      "outputs": [],
      "source": [
        "def feat_noeve_avg_nn_1(state):\n",
        "    \"\"\"\n",
        "    Takes a list of Random Seeds, splits the data into Train and CV based on Seed, trains model and takes average of \n",
        "    predictions while testing  \n",
        "    \"\"\"\n",
        "    feat_mod_list=[]\n",
        "    feat_mod_list=[]\n",
        "    feat_avg_cv_los=0\n",
        "    for i in range(len(state)):\n",
        "        xtr, xcv, ytr, ycv = train_test_split(xtrain, y,stratify=y,test_size=0.15,random_state=state[i])\n",
        "        ytr=np_utils.to_categorical(ytr)\n",
        "        ycv=np_utils.to_categorical(ycv)\n",
        "        model=noevents_nn_model1(xtr.shape[1])\n",
        "        model.fit(xtr, ytr, batch_size=256, epochs=20, verbose=1, validation_data=(xcv, ycv),callbacks=[early_stop])\n",
        "        model.save('saved_models/no_events/nn_onehot '+str(i+1))\n",
        "        pred=model.predict_proba(xcv)\n",
        "        feat_cv_los=log_loss(ycv, pred)\n",
        "        print(\"Validation Log Loss of  Model in Current Run: \",feat_cv_los)\n",
        "        feat_mod_list.append(model)\n",
        "        feat_mod_list.append(feat_cv_los)\n",
        "    feat_avg_cv_los=mean(feat_mod_list)\n",
        "    print(\"Average CV Loss of \"+str(len(state))+\" Runs :\",feat_avg_cv_los)\n",
        "    return(feat_mod_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SS8rZvOnM0Eh",
        "outputId": "faa3d018-2532-45bb-8029-327dd105302f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(63448, 175)"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xtr.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJN06qNmM0Eh",
        "outputId": "19ddeeab-fe8e-4a1f-d3cb-3481efffa09c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 63448 samples, validate on 11197 samples\n",
            "Epoch 1/20\n",
            "63448/63448 [==============================] - 3s 52us/step - loss: 2.4447 - acc: 0.1201 - val_loss: 15.2127 - val_acc: 0.0562\n",
            "Epoch 2/20\n",
            "63448/63448 [==============================] - 2s 28us/step - loss: 2.4319 - acc: 0.1288 - val_loss: 15.4444 - val_acc: 0.0418\n",
            "Epoch 3/20\n",
            "63448/63448 [==============================] - 2s 27us/step - loss: 2.4305 - acc: 0.1281 - val_loss: 15.4444 - val_acc: 0.0418\n",
            "Epoch 4/20\n",
            "63448/63448 [==============================] - 2s 27us/step - loss: 2.4302 - acc: 0.1267 - val_loss: 15.4444 - val_acc: 0.0418\n",
            "Epoch 5/20\n",
            "63448/63448 [==============================] - 2s 27us/step - loss: 2.4310 - acc: 0.1272 - val_loss: 15.4444 - val_acc: 0.0418\n",
            "Epoch 6/20\n",
            "63448/63448 [==============================] - 2s 27us/step - loss: 2.4299 - acc: 0.1279 - val_loss: 14.5404 - val_acc: 0.0979\n",
            "Epoch 7/20\n",
            "63448/63448 [==============================] - 2s 27us/step - loss: 2.4297 - acc: 0.1280 - val_loss: 15.4444 - val_acc: 0.0418\n",
            "Epoch 8/20\n",
            "63448/63448 [==============================] - 2s 28us/step - loss: 2.4295 - acc: 0.1279 - val_loss: 15.4444 - val_acc: 0.0418\n",
            "Epoch 9/20\n",
            "63448/63448 [==============================] - 2s 28us/step - loss: 2.4297 - acc: 0.1279 - val_loss: 14.5404 - val_acc: 0.0979\n",
            "Epoch 10/20\n",
            "63448/63448 [==============================] - 2s 28us/step - loss: 2.4293 - acc: 0.1266 - val_loss: 14.5404 - val_acc: 0.0979\n",
            "Epoch 11/20\n",
            "63448/63448 [==============================] - 2s 28us/step - loss: 2.4290 - acc: 0.1274 - val_loss: 14.5015 - val_acc: 0.1003\n",
            "Epoch 12/20\n",
            "63448/63448 [==============================] - 2s 28us/step - loss: 2.4294 - acc: 0.1283 - val_loss: 15.4444 - val_acc: 0.0418\n",
            "Epoch 13/20\n",
            "63448/63448 [==============================] - 2s 28us/step - loss: 2.4290 - acc: 0.1285 - val_loss: 14.5404 - val_acc: 0.0979\n",
            "Epoch 14/20\n",
            "63448/63448 [==============================] - 2s 28us/step - loss: 2.4292 - acc: 0.1287 - val_loss: 15.4444 - val_acc: 0.0418\n",
            "Epoch 15/20\n",
            "63448/63448 [==============================] - 2s 28us/step - loss: 2.4289 - acc: 0.1283 - val_loss: 15.2127 - val_acc: 0.0562\n",
            "Epoch 16/20\n",
            "63448/63448 [==============================] - 2s 28us/step - loss: 2.4294 - acc: 0.1278 - val_loss: 15.4444 - val_acc: 0.0418\n",
            "Validation Log Loss of  Model in Current Run:  31.074719427568184\n",
            "Train on 63448 samples, validate on 11197 samples\n",
            "Epoch 1/20\n",
            "63448/63448 [==============================] - 3s 53us/step - loss: 2.4467 - acc: 0.1190 - val_loss: 14.2655 - val_acc: 0.1149\n",
            "Epoch 2/20\n",
            "63448/63448 [==============================] - 2s 28us/step - loss: 2.4319 - acc: 0.1270 - val_loss: 14.2655 - val_acc: 0.1149\n",
            "Epoch 3/20\n",
            "63448/63448 [==============================] - 2s 27us/step - loss: 2.4313 - acc: 0.1282 - val_loss: 14.9420 - val_acc: 0.0730\n",
            "Epoch 4/20\n",
            "63448/63448 [==============================] - 2s 28us/step - loss: 2.4305 - acc: 0.1255 - val_loss: 15.4444 - val_acc: 0.0418\n",
            "Epoch 5/20\n",
            "63448/63448 [==============================] - 2s 28us/step - loss: 2.4306 - acc: 0.1283 - val_loss: 15.0270 - val_acc: 0.0677\n",
            "Epoch 6/20\n",
            "63448/63448 [==============================] - 2s 27us/step - loss: 2.4299 - acc: 0.1260 - val_loss: 15.4444 - val_acc: 0.0418\n",
            "Validation Log Loss of  Model in Current Run:  30.568837554814444\n",
            "Train on 63448 samples, validate on 11197 samples\n",
            "Epoch 1/20\n",
            "63448/63448 [==============================] - 4s 55us/step - loss: 2.4442 - acc: 0.1196 - val_loss: 14.0726 - val_acc: 0.1269\n",
            "Epoch 2/20\n",
            "63448/63448 [==============================] - 2s 29us/step - loss: 2.4319 - acc: 0.1280 - val_loss: 15.2127 - val_acc: 0.0562\n",
            "Epoch 3/20\n",
            "63448/63448 [==============================] - 3s 47us/step - loss: 2.4309 - acc: 0.1253 - val_loss: 14.2655 - val_acc: 0.1149\n",
            "Epoch 4/20\n",
            "63448/63448 [==============================] - 2s 29us/step - loss: 2.4295 - acc: 0.1274 - val_loss: 14.0726 - val_acc: 0.1269\n",
            "Epoch 5/20\n",
            "63448/63448 [==============================] - 2s 28us/step - loss: 2.4302 - acc: 0.1277 - val_loss: 14.0726 - val_acc: 0.1269\n",
            "Epoch 6/20\n",
            "63448/63448 [==============================] - 2s 29us/step - loss: 2.4293 - acc: 0.1288 - val_loss: 13.0137 - val_acc: 0.0562\n",
            "Epoch 7/20\n",
            "63448/63448 [==============================] - 2s 30us/step - loss: 2.4291 - acc: 0.1280 - val_loss: 14.0726 - val_acc: 0.1269\n",
            "Epoch 8/20\n",
            "63448/63448 [==============================] - 2s 30us/step - loss: 2.4291 - acc: 0.1278 - val_loss: 14.2655 - val_acc: 0.1149\n",
            "Epoch 9/20\n",
            "63448/63448 [==============================] - 2s 30us/step - loss: 2.4288 - acc: 0.1276 - val_loss: 15.1191 - val_acc: 0.0620\n",
            "Epoch 10/20\n",
            "63448/63448 [==============================] - 2s 30us/step - loss: 2.4311 - acc: 0.1284 - val_loss: 14.0726 - val_acc: 0.1269\n",
            "Epoch 11/20\n",
            "63448/63448 [==============================] - 2s 30us/step - loss: 2.4295 - acc: 0.1271 - val_loss: 14.0726 - val_acc: 0.1269\n",
            "Validation Log Loss of  Model in Current Run:  26.150270795052865\n",
            "Train on 63448 samples, validate on 11197 samples\n",
            "Epoch 1/20\n",
            "63448/63448 [==============================] - 4s 60us/step - loss: 2.4443 - acc: 0.1197 - val_loss: 13.3802 - val_acc: 0.1269\n",
            "Epoch 2/20\n",
            "63448/63448 [==============================] - 2s 31us/step - loss: 2.4308 - acc: 0.1267 - val_loss: 14.9420 - val_acc: 0.0730\n",
            "Epoch 3/20\n",
            "63448/63448 [==============================] - 2s 31us/step - loss: 2.4302 - acc: 0.1271 - val_loss: 14.5404 - val_acc: 0.0979\n",
            "Epoch 4/20\n",
            "63448/63448 [==============================] - 2s 31us/step - loss: 2.4302 - acc: 0.1276 - val_loss: 14.5404 - val_acc: 0.0979\n",
            "Epoch 5/20\n",
            "63448/63448 [==============================] - 2s 31us/step - loss: 2.4298 - acc: 0.1280 - val_loss: 14.5404 - val_acc: 0.0979\n",
            "Epoch 6/20\n",
            "63448/63448 [==============================] - 2s 30us/step - loss: 2.4295 - acc: 0.1279 - val_loss: 15.2127 - val_acc: 0.0562\n",
            "Validation Log Loss of  Model in Current Run:  27.09232210426058\n",
            "Train on 63448 samples, validate on 11197 samples\n",
            "Epoch 1/20\n",
            "63448/63448 [==============================] - 4s 62us/step - loss: 2.4452 - acc: 0.1202 - val_loss: 15.4444 - val_acc: 0.0418\n",
            "Epoch 2/20\n",
            "63448/63448 [==============================] - 2s 32us/step - loss: 2.4321 - acc: 0.1263 - val_loss: 15.2127 - val_acc: 0.0562\n",
            "Epoch 3/20\n",
            "63448/63448 [==============================] - 2s 32us/step - loss: 2.4309 - acc: 0.1278 - val_loss: 14.0438 - val_acc: 0.1287\n",
            "Epoch 4/20\n",
            "63448/63448 [==============================] - 2s 32us/step - loss: 2.4312 - acc: 0.1284 - val_loss: 14.5404 - val_acc: 0.0979\n",
            "Epoch 5/20\n",
            "63448/63448 [==============================] - 2s 31us/step - loss: 2.4308 - acc: 0.1261 - val_loss: 15.1191 - val_acc: 0.0620\n",
            "Epoch 6/20\n",
            "63448/63448 [==============================] - 2s 32us/step - loss: 2.4297 - acc: 0.1282 - val_loss: 15.1191 - val_acc: 0.0620\n",
            "Epoch 7/20\n",
            "63448/63448 [==============================] - 2s 32us/step - loss: 2.4293 - acc: 0.1274 - val_loss: 14.0726 - val_acc: 0.1269\n",
            "Epoch 8/20\n",
            "63448/63448 [==============================] - 2s 32us/step - loss: 2.4291 - acc: 0.1275 - val_loss: 14.2655 - val_acc: 0.1149\n",
            "Validation Log Loss of  Model in Current Run:  29.772345952842027\n",
            "Average CV Loss of 5 Runs : 28.93169916690762\n"
          ]
        }
      ],
      "source": [
        "random_seeds=[9,18,42,86,103]\n",
        "model_list_2= feat_noeve_avg_nn_1(random_seeds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCXiw8rPM0Ei",
        "outputId": "a9d77dcd-2c54-47da-e494-212c24b37db8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Average Log-Loss:  14.917648857027595\n"
          ]
        }
      ],
      "source": [
        "feat_avg_pred=np.zeros((xtr.shape[0],12))\n",
        "for i in range(len(model_list_2)):\n",
        "    feat_tr_pred=model_list_2[i].predict_proba(xtr)\n",
        "    feat_avg_pred+=feat_tr_pred\n",
        "feat_avg_pred/=len(model_list_2)\n",
        "print(\"Train Average Log-Loss: \",log_loss(ytr, feat_avg_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYxvVfm4M0Ei",
        "outputId": "422d70d0-34de-45a7-88ea-b84ea777f50e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Average Log-Loss:  14.920084094153626\n"
          ]
        }
      ],
      "source": [
        "feat_avg_pred=np.zeros((xcv.shape[0],12))\n",
        "for i in range(len(model_list_2)):\n",
        "    feat_cv_pred=model_list_2[i].predict_proba(xcv)\n",
        "    feat_avg_pred+=feat_cv_pred\n",
        "feat_avg_pred/=len(model_list_2)\n",
        "print(\"Validation Average Log-Loss: \",log_loss(ycv, feat_avg_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jMcWM6TM0Ei",
        "outputId": "fbf4ff0d-4d06-4e34-ce87-5bb8c8a4d8d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(76877, 175)"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feat_xte_no_eve_onehot.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jW-anmtyM0Ei"
      },
      "outputs": [],
      "source": [
        "feat_avg_pred=np.zeros((xtest_noevents_onehot.shape[0],12))\n",
        "for i in range(len(model_list_2)):\n",
        "    feat_te_pred=model_list_2[i].predict_proba(feat_xte_no_eve_onehot)\n",
        "    feat_avg_pred+=feat_te_pred\n",
        "feat_avg_pred/=len(model_list_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68_kIgyJM0Ei"
      },
      "source": [
        "OBSERVATIONS:\n",
        "USING NEURAL NETWORK WE GOT TRAIN LOSS OF 2.3528 AND TEST LOSS OF 2.3577"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eMp1ZkwM0Ej"
      },
      "source": [
        "# MODEL 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMZQ7iBsM0Ej"
      },
      "outputs": [],
      "source": [
        "#https://www.kaggle.com/c/talkingdata-mobile-user-demographics/discussion/23424\n",
        "def feat_noeve_nn_mod_2(input_dim,output_dim, learRate=0.0025):\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(Dense(500, input_shape=(input_dim,), init='uniform'))\n",
        "    model.add(PReLU(init='zero'))\n",
        "    model.add(Dropout(0.82))\n",
        "    model.add(Dense(output_dim, init='uniform'))\n",
        "    model.add(Activation('softmax'))\n",
        "    opt = Adagrad(lr=learRate, epsilon=1e-08)\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=opt,\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEzfGXPTM0Ej",
        "outputId": "6aab2c1b-6708-429d-d248-0877dc252810"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0408 12:35:07.644370 11128 nn_ops.py:4224] Large dropout rate: 0.82 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_19 (Dense)             (None, 500)               899500    \n",
            "_________________________________________________________________\n",
            "p_re_lu_13 (PReLU)           (None, 500)               500       \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 12)                6012      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 12)                0         \n",
            "=================================================================\n",
            "Total params: 906,012\n",
            "Trainable params: 906,012\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_sum=feat_noeve_nn_mod_2(xtr.shape[1],12)\n",
        "model_sum.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKSSKr8RM0Ej"
      },
      "outputs": [],
      "source": [
        "early_stop=EarlyStopping(monitor='val_loss',patience=5,restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvVoGMPsM0Ej"
      },
      "outputs": [],
      "source": [
        "def feat_noeve_avg_nn_2(state):\n",
        "    \"\"\"\n",
        "    Takes a list of Random Seeds, splits the data into Train and CV based on Seed, trains model and takes average of \n",
        "    predictions while testing  \n",
        "    \"\"\"\n",
        "    feat_mod_list=[]\n",
        "    feat_los_list=[]\n",
        "    feat_avg_cv_los=0\n",
        "    for i in range(len(state)):\n",
        "        xtr, xcv, ytr, ycv = train_test_split(Xtrain_whole, y,stratify=y,test_size=0.15,random_state=state[i])\n",
        "        ytr=np_utils.to_categorical(ytr)\n",
        "        ycv=np_utils.to_categorical(ycv)\n",
        "        model=noevents_nn_model2(xtr.shape[1],12)\n",
        "        #logdir = os.path.join(\"logs\",\"noevents_nn1.\"+str(i+1))\n",
        "        #t_callback=TensorBoard(log_dir=logdir)\n",
        "        model.fit(xtr, ytr, batch_size=256, epochs=30, verbose=1, validation_data=(xcv, ycv),callbacks=[early_stop])\n",
        "        feat_pred=model.predict_proba(xcv)\n",
        "        feat_cv_los=log_loss(ycv, feat_pred)\n",
        "        print(\"Validation Log Loss of  Model in Current Run: \",feat_cv_los)\n",
        "        feat_mod_list.append(model)\n",
        "        feat_los_list.append(feat_cv_los)\n",
        "    feat_avg_cv_los=mean(feat_los_list)\n",
        "    print(\"Average CV Loss of \"+str(len(state))+\" Runs :\",feat_avg_cv_los)\n",
        "    return(feat_mod_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJtM-uMDM0Ek",
        "outputId": "c980b675-acc9-43c8-f6fa-f620258b7148"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0408 12:35:07.760055 11128 nn_ops.py:4224] Large dropout rate: 0.82 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 63448 samples, validate on 11197 samples\n",
            "Epoch 1/30\n",
            "63448/63448 [==============================] - 5s 75us/step - loss: 2.4315 - acc: 0.1345 - val_loss: 2.4168 - val_acc: 0.1427\n",
            "Epoch 2/30\n",
            "63448/63448 [==============================] - 4s 67us/step - loss: 2.4143 - acc: 0.1416 - val_loss: 2.4114 - val_acc: 0.1440\n",
            "Epoch 3/30\n",
            "63448/63448 [==============================] - 4s 65us/step - loss: 2.4089 - acc: 0.1452 - val_loss: 2.4081 - val_acc: 0.1444\n",
            "Epoch 4/30\n",
            "63448/63448 [==============================] - 4s 65us/step - loss: 2.4047 - acc: 0.1462 - val_loss: 2.4059 - val_acc: 0.1466\n",
            "Epoch 5/30\n",
            "63448/63448 [==============================] - 4s 65us/step - loss: 2.4024 - acc: 0.1482 - val_loss: 2.4042 - val_acc: 0.1478\n",
            "Epoch 6/30\n",
            "63448/63448 [==============================] - 4s 65us/step - loss: 2.4006 - acc: 0.1497 - val_loss: 2.4030 - val_acc: 0.1485\n",
            "Epoch 7/30\n",
            "63448/63448 [==============================] - 4s 66us/step - loss: 2.3989 - acc: 0.1504 - val_loss: 2.4020 - val_acc: 0.1499\n",
            "Epoch 8/30\n",
            "63448/63448 [==============================] - 4s 70us/step - loss: 2.3977 - acc: 0.1518 - val_loss: 2.4011 - val_acc: 0.1501\n",
            "Epoch 9/30\n",
            "63448/63448 [==============================] - 4s 70us/step - loss: 2.3956 - acc: 0.1528 - val_loss: 2.4004 - val_acc: 0.1501\n",
            "Epoch 10/30\n",
            "63448/63448 [==============================] - 4s 68us/step - loss: 2.3954 - acc: 0.1534 - val_loss: 2.3998 - val_acc: 0.1496\n",
            "Epoch 11/30\n",
            "63448/63448 [==============================] - 4s 64us/step - loss: 2.3932 - acc: 0.1557 - val_loss: 2.3993 - val_acc: 0.1508\n",
            "Epoch 12/30\n",
            "63448/63448 [==============================] - 4s 64us/step - loss: 2.3928 - acc: 0.1564 - val_loss: 2.3988 - val_acc: 0.1516\n",
            "Epoch 13/30\n",
            "63448/63448 [==============================] - 4s 63us/step - loss: 2.3921 - acc: 0.1562 - val_loss: 2.3984 - val_acc: 0.1527\n",
            "Epoch 14/30\n",
            "63448/63448 [==============================] - 4s 63us/step - loss: 2.3909 - acc: 0.1576 - val_loss: 2.3980 - val_acc: 0.1525\n",
            "Epoch 15/30\n",
            "63448/63448 [==============================] - 4s 64us/step - loss: 2.3898 - acc: 0.1600 - val_loss: 2.3976 - val_acc: 0.1522\n",
            "Epoch 16/30\n",
            "63448/63448 [==============================] - 4s 67us/step - loss: 2.3885 - acc: 0.1568 - val_loss: 2.3972 - val_acc: 0.1523\n",
            "Epoch 17/30\n",
            "63448/63448 [==============================] - 4s 69us/step - loss: 2.3881 - acc: 0.1580 - val_loss: 2.3969 - val_acc: 0.1525\n",
            "Epoch 18/30\n",
            "63448/63448 [==============================] - 4s 71us/step - loss: 2.3882 - acc: 0.1584 - val_loss: 2.3966 - val_acc: 0.1522\n",
            "Epoch 19/30\n",
            "63448/63448 [==============================] - 4s 68us/step - loss: 2.3876 - acc: 0.1594 - val_loss: 2.3963 - val_acc: 0.1520\n",
            "Epoch 20/30\n",
            "63448/63448 [==============================] - 4s 67us/step - loss: 2.3863 - acc: 0.1595 - val_loss: 2.3961 - val_acc: 0.1520\n",
            "Epoch 21/30\n",
            "63448/63448 [==============================] - 4s 68us/step - loss: 2.3856 - acc: 0.1593 - val_loss: 2.3958 - val_acc: 0.1523\n",
            "Epoch 22/30\n",
            "63448/63448 [==============================] - 4s 70us/step - loss: 2.3851 - acc: 0.1607 - val_loss: 2.3955 - val_acc: 0.1541\n",
            "Epoch 23/30\n",
            "63448/63448 [==============================] - 4s 68us/step - loss: 2.3848 - acc: 0.1607 - val_loss: 2.3953 - val_acc: 0.1546\n",
            "Epoch 24/30\n",
            "63448/63448 [==============================] - 4s 68us/step - loss: 2.3851 - acc: 0.1634 - val_loss: 2.3951 - val_acc: 0.1545\n",
            "Epoch 25/30\n",
            "63448/63448 [==============================] - 4s 69us/step - loss: 2.3834 - acc: 0.1618 - val_loss: 2.3949 - val_acc: 0.1544\n",
            "Epoch 26/30\n",
            "63448/63448 [==============================] - 4s 69us/step - loss: 2.3830 - acc: 0.1630 - val_loss: 2.3947 - val_acc: 0.1545\n",
            "Epoch 27/30\n",
            "63448/63448 [==============================] - 4s 69us/step - loss: 2.3818 - acc: 0.1638 - val_loss: 2.3945 - val_acc: 0.1545\n",
            "Epoch 28/30\n",
            "63448/63448 [==============================] - 4s 69us/step - loss: 2.3822 - acc: 0.1633 - val_loss: 2.3943 - val_acc: 0.1537\n",
            "Epoch 29/30\n",
            "63448/63448 [==============================] - 4s 69us/step - loss: 2.3822 - acc: 0.1627 - val_loss: 2.3941 - val_acc: 0.1533\n",
            "Epoch 30/30\n",
            "63448/63448 [==============================] - 4s 70us/step - loss: 2.3809 - acc: 0.1627 - val_loss: 2.3939 - val_acc: 0.1535\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0408 12:37:17.340040 11128 nn_ops.py:4224] Large dropout rate: 0.82 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Log Loss of  Model in Current Run:  2.393906689524874\n",
            "Train on 63448 samples, validate on 11197 samples\n",
            "Epoch 1/30\n",
            "63448/63448 [==============================] - 5s 77us/step - loss: 2.4322 - acc: 0.1355 - val_loss: 2.4170 - val_acc: 0.1474\n",
            "Epoch 2/30\n",
            "63448/63448 [==============================] - 4s 67us/step - loss: 2.4155 - acc: 0.1423 - val_loss: 2.4108 - val_acc: 0.1508\n",
            "Epoch 3/30\n",
            "63448/63448 [==============================] - 4s 71us/step - loss: 2.4097 - acc: 0.1463 - val_loss: 2.4070 - val_acc: 0.1512\n",
            "Epoch 4/30\n",
            "63448/63448 [==============================] - 4s 70us/step - loss: 2.4068 - acc: 0.1459 - val_loss: 2.4043 - val_acc: 0.1525\n",
            "Epoch 5/30\n",
            "63448/63448 [==============================] - 4s 66us/step - loss: 2.4044 - acc: 0.1461 - val_loss: 2.4023 - val_acc: 0.1523\n",
            "Epoch 6/30\n",
            "63448/63448 [==============================] - 5s 73us/step - loss: 2.4014 - acc: 0.1494 - val_loss: 2.4007 - val_acc: 0.1519\n",
            "Epoch 7/30\n",
            "63448/63448 [==============================] - 4s 69us/step - loss: 2.3996 - acc: 0.1514 - val_loss: 2.3995 - val_acc: 0.1533\n",
            "Epoch 8/30\n",
            "63448/63448 [==============================] - 4s 64us/step - loss: 2.3984 - acc: 0.1524 - val_loss: 2.3984 - val_acc: 0.1539\n",
            "Epoch 9/30\n",
            "63448/63448 [==============================] - 4s 66us/step - loss: 2.3969 - acc: 0.1536 - val_loss: 2.3975 - val_acc: 0.1550\n",
            "Epoch 10/30\n",
            "63448/63448 [==============================] - 4s 66us/step - loss: 2.3961 - acc: 0.1511 - val_loss: 2.3968 - val_acc: 0.1567\n",
            "Epoch 11/30\n",
            "63448/63448 [==============================] - 4s 66us/step - loss: 2.3939 - acc: 0.1546 - val_loss: 2.3962 - val_acc: 0.1563\n",
            "Epoch 12/30\n",
            "63448/63448 [==============================] - 4s 66us/step - loss: 2.3929 - acc: 0.1534 - val_loss: 2.3956 - val_acc: 0.1554\n",
            "Epoch 13/30\n",
            "63448/63448 [==============================] - 4s 66us/step - loss: 2.3924 - acc: 0.1554 - val_loss: 2.3951 - val_acc: 0.1560\n",
            "Epoch 14/30\n",
            "63448/63448 [==============================] - 4s 65us/step - loss: 2.3922 - acc: 0.1543 - val_loss: 2.3946 - val_acc: 0.1568\n",
            "Epoch 15/30\n",
            "63448/63448 [==============================] - 4s 66us/step - loss: 2.3905 - acc: 0.1583 - val_loss: 2.3942 - val_acc: 0.1560\n",
            "Epoch 16/30\n",
            "63448/63448 [==============================] - 4s 66us/step - loss: 2.3901 - acc: 0.1568 - val_loss: 2.3938 - val_acc: 0.1558\n",
            "Epoch 17/30\n",
            "63448/63448 [==============================] - 4s 66us/step - loss: 2.3892 - acc: 0.1580 - val_loss: 2.3935 - val_acc: 0.1567\n",
            "Epoch 18/30\n",
            "63448/63448 [==============================] - 4s 66us/step - loss: 2.3884 - acc: 0.1583 - val_loss: 2.3931 - val_acc: 0.1566\n",
            "Epoch 19/30\n",
            "63448/63448 [==============================] - 4s 66us/step - loss: 2.3877 - acc: 0.1578 - val_loss: 2.3928 - val_acc: 0.1570\n",
            "Epoch 20/30\n",
            "63448/63448 [==============================] - 4s 65us/step - loss: 2.3873 - acc: 0.1599 - val_loss: 2.3926 - val_acc: 0.1569\n",
            "Epoch 21/30\n",
            "63448/63448 [==============================] - 4s 65us/step - loss: 2.3859 - acc: 0.1611 - val_loss: 2.3923 - val_acc: 0.1565\n",
            "Epoch 22/30\n",
            "63448/63448 [==============================] - 4s 66us/step - loss: 2.3873 - acc: 0.1582 - val_loss: 2.3920 - val_acc: 0.1565\n",
            "Epoch 23/30\n",
            "63448/63448 [==============================] - 4s 65us/step - loss: 2.3864 - acc: 0.1599 - val_loss: 2.3918 - val_acc: 0.1566\n",
            "Epoch 24/30\n",
            "63448/63448 [==============================] - 4s 65us/step - loss: 2.3846 - acc: 0.1597 - val_loss: 2.3916 - val_acc: 0.1572\n",
            "Epoch 25/30\n",
            "63448/63448 [==============================] - 4s 66us/step - loss: 2.3843 - acc: 0.1605 - val_loss: 2.3914 - val_acc: 0.1581\n",
            "Epoch 26/30\n",
            "63448/63448 [==============================] - 4s 65us/step - loss: 2.3839 - acc: 0.1634 - val_loss: 2.3912 - val_acc: 0.1582\n",
            "Epoch 27/30\n",
            "63448/63448 [==============================] - 4s 66us/step - loss: 2.3829 - acc: 0.1626 - val_loss: 2.3910 - val_acc: 0.1579\n",
            "Epoch 28/30\n",
            "63448/63448 [==============================] - 4s 66us/step - loss: 2.3831 - acc: 0.1630 - val_loss: 2.3908 - val_acc: 0.1576\n",
            "Epoch 29/30\n",
            "63448/63448 [==============================] - 4s 66us/step - loss: 2.3822 - acc: 0.1622 - val_loss: 2.3906 - val_acc: 0.1583\n",
            "Epoch 30/30\n",
            "63448/63448 [==============================] - 4s 66us/step - loss: 2.3822 - acc: 0.1615 - val_loss: 2.3904 - val_acc: 0.1580\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0408 12:39:25.408527 11128 nn_ops.py:4224] Large dropout rate: 0.82 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Log Loss of  Model in Current Run:  2.390445421803921\n",
            "Train on 63448 samples, validate on 11197 samples\n",
            "Epoch 1/30\n",
            "63448/63448 [==============================] - 5s 79us/step - loss: 2.4323 - acc: 0.1345 - val_loss: 2.4160 - val_acc: 0.1410\n",
            "Epoch 2/30\n",
            "63448/63448 [==============================] - 4s 66us/step - loss: 2.4156 - acc: 0.1418 - val_loss: 2.4098 - val_acc: 0.1418\n",
            "Epoch 3/30\n",
            "63448/63448 [==============================] - 4s 67us/step - loss: 2.4095 - acc: 0.1459 - val_loss: 2.4060 - val_acc: 0.1454\n",
            "Epoch 4/30\n",
            "63448/63448 [==============================] - 4s 64us/step - loss: 2.4062 - acc: 0.1464 - val_loss: 2.4033 - val_acc: 0.1460\n",
            "Epoch 5/30\n",
            "63448/63448 [==============================] - 4s 65us/step - loss: 2.4031 - acc: 0.1479 - val_loss: 2.4013 - val_acc: 0.1468\n",
            "Epoch 6/30\n",
            "63448/63448 [==============================] - 4s 65us/step - loss: 2.4017 - acc: 0.1489 - val_loss: 2.3997 - val_acc: 0.1474\n",
            "Epoch 7/30\n",
            "63448/63448 [==============================] - 4s 66us/step - loss: 2.4003 - acc: 0.1505 - val_loss: 2.3984 - val_acc: 0.1482\n",
            "Epoch 8/30\n",
            "63448/63448 [==============================] - 4s 65us/step - loss: 2.3980 - acc: 0.1534 - val_loss: 2.3973 - val_acc: 0.1498\n",
            "Epoch 9/30\n",
            "63448/63448 [==============================] - 4s 66us/step - loss: 2.3969 - acc: 0.1518 - val_loss: 2.3963 - val_acc: 0.1509\n",
            "Epoch 10/30\n",
            "63448/63448 [==============================] - 4s 66us/step - loss: 2.3955 - acc: 0.1547 - val_loss: 2.3955 - val_acc: 0.1514\n",
            "Epoch 11/30\n",
            "63448/63448 [==============================] - 4s 70us/step - loss: 2.3948 - acc: 0.1541 - val_loss: 2.3948 - val_acc: 0.1516s: 2.3950 - acc: 0.\n",
            "Epoch 12/30\n",
            "63448/63448 [==============================] - 4s 67us/step - loss: 2.3936 - acc: 0.1543 - val_loss: 2.3942 - val_acc: 0.1518\n",
            "Epoch 13/30\n",
            "63448/63448 [==============================] - 4s 66us/step - loss: 2.3925 - acc: 0.1568 - val_loss: 2.3936 - val_acc: 0.1534\n",
            "Epoch 14/30\n",
            "63448/63448 [==============================] - 4s 67us/step - loss: 2.3918 - acc: 0.1557 - val_loss: 2.3930 - val_acc: 0.1522\n",
            "Epoch 15/30\n",
            "63448/63448 [==============================] - 4s 69us/step - loss: 2.3915 - acc: 0.1572 - val_loss: 2.3926 - val_acc: 0.1528\n",
            "Epoch 16/30\n",
            "63448/63448 [==============================] - 4s 68us/step - loss: 2.3897 - acc: 0.1594 - val_loss: 2.3921 - val_acc: 0.1540\n",
            "Epoch 17/30\n",
            "63448/63448 [==============================] - 4s 68us/step - loss: 2.3894 - acc: 0.1590 - val_loss: 2.3917 - val_acc: 0.1548\n",
            "Epoch 18/30\n",
            "63448/63448 [==============================] - 4s 65us/step - loss: 2.3887 - acc: 0.1588 - val_loss: 2.3914 - val_acc: 0.1552\n",
            "Epoch 19/30\n",
            "63448/63448 [==============================] - 4s 65us/step - loss: 2.3883 - acc: 0.1582 - val_loss: 2.3910 - val_acc: 0.1558\n",
            "Epoch 20/30\n",
            "63448/63448 [==============================] - 4s 65us/step - loss: 2.3873 - acc: 0.1610 - val_loss: 2.3906 - val_acc: 0.1564\n",
            "Epoch 21/30\n",
            "63448/63448 [==============================] - 4s 68us/step - loss: 2.3872 - acc: 0.1605 - val_loss: 2.3903 - val_acc: 0.1565\n",
            "Epoch 22/30\n",
            "63448/63448 [==============================] - 4s 68us/step - loss: 2.3861 - acc: 0.1602 - val_loss: 2.3900 - val_acc: 0.1562\n",
            "Epoch 23/30\n",
            "63448/63448 [==============================] - 4s 68us/step - loss: 2.3858 - acc: 0.1587 - val_loss: 2.3898 - val_acc: 0.1563\n",
            "Epoch 24/30\n",
            "63448/63448 [==============================] - 4s 69us/step - loss: 2.3856 - acc: 0.1604 - val_loss: 2.3895 - val_acc: 0.1570\n",
            "Epoch 25/30\n",
            "63448/63448 [==============================] - 4s 68us/step - loss: 2.3845 - acc: 0.1617 - val_loss: 2.3893 - val_acc: 0.1571\n",
            "Epoch 26/30\n",
            "63448/63448 [==============================] - 4s 68us/step - loss: 2.3846 - acc: 0.1613 - val_loss: 2.3890 - val_acc: 0.1575\n",
            "Epoch 27/30\n",
            "63448/63448 [==============================] - 4s 67us/step - loss: 2.3841 - acc: 0.1627 - val_loss: 2.3888 - val_acc: 0.1587\n",
            "Epoch 28/30\n",
            "63448/63448 [==============================] - 4s 66us/step - loss: 2.3824 - acc: 0.1614 - val_loss: 2.3886 - val_acc: 0.1587\n",
            "Epoch 29/30\n",
            "63448/63448 [==============================] - 4s 66us/step - loss: 2.3823 - acc: 0.1623 - val_loss: 2.3884 - val_acc: 0.1588\n",
            "Epoch 30/30\n",
            "63448/63448 [==============================] - 4s 65us/step - loss: 2.3826 - acc: 0.1621 - val_loss: 2.3882 - val_acc: 0.1591\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0408 12:41:34.231742 11128 nn_ops.py:4224] Large dropout rate: 0.82 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Log Loss of  Model in Current Run:  2.3882187361524307\n",
            "Train on 63448 samples, validate on 11197 samples\n",
            "Epoch 1/30\n",
            "63448/63448 [==============================] - 5s 81us/step - loss: 2.4325 - acc: 0.1353 - val_loss: 2.4162 - val_acc: 0.1448\n",
            "Epoch 2/30\n",
            "63448/63448 [==============================] - 4s 70us/step - loss: 2.4151 - acc: 0.1429 - val_loss: 2.4099 - val_acc: 0.1463\n",
            "Epoch 3/30\n",
            "63448/63448 [==============================] - 4s 65us/step - loss: 2.4093 - acc: 0.1448 - val_loss: 2.4060 - val_acc: 0.1465\n",
            "Epoch 4/30\n",
            "63448/63448 [==============================] - 4s 66us/step - loss: 2.4068 - acc: 0.1465 - val_loss: 2.4033 - val_acc: 0.1468\n",
            "Epoch 5/30\n",
            "63448/63448 [==============================] - 4s 66us/step - loss: 2.4035 - acc: 0.1489 - val_loss: 2.4012 - val_acc: 0.1498\n",
            "Epoch 6/30\n",
            "63448/63448 [==============================] - 4s 66us/step - loss: 2.4012 - acc: 0.1497 - val_loss: 2.3996 - val_acc: 0.1523\n",
            "Epoch 7/30\n",
            "63448/63448 [==============================] - 4s 66us/step - loss: 2.3992 - acc: 0.1519 - val_loss: 2.3983 - val_acc: 0.1525\n",
            "Epoch 8/30\n",
            "63448/63448 [==============================] - 4s 66us/step - loss: 2.3977 - acc: 0.1509 - val_loss: 2.3973 - val_acc: 0.1539\n",
            "Epoch 9/30\n",
            "63448/63448 [==============================] - 4s 65us/step - loss: 2.3959 - acc: 0.1526 - val_loss: 2.3964 - val_acc: 0.1549\n",
            "Epoch 10/30\n",
            "63448/63448 [==============================] - 4s 65us/step - loss: 2.3949 - acc: 0.1536 - val_loss: 2.3956 - val_acc: 0.1552\n",
            "Epoch 11/30\n",
            "63448/63448 [==============================] - 4s 66us/step - loss: 2.3938 - acc: 0.1560 - val_loss: 2.3950 - val_acc: 0.1560\n",
            "Epoch 12/30\n",
            "63448/63448 [==============================] - 4s 66us/step - loss: 2.3935 - acc: 0.1548 - val_loss: 2.3944 - val_acc: 0.1553\n",
            "Epoch 13/30\n",
            "63448/63448 [==============================] - 4s 66us/step - loss: 2.3930 - acc: 0.1545 - val_loss: 2.3939 - val_acc: 0.1563\n",
            "Epoch 14/30\n",
            "63448/63448 [==============================] - 4s 66us/step - loss: 2.3908 - acc: 0.1554 - val_loss: 2.3934 - val_acc: 0.1558\n",
            "Epoch 15/30\n",
            "63448/63448 [==============================] - 4s 65us/step - loss: 2.3902 - acc: 0.1581 - val_loss: 2.3930 - val_acc: 0.1560\n",
            "Epoch 16/30\n",
            "63448/63448 [==============================] - 4s 66us/step - loss: 2.3907 - acc: 0.1572 - val_loss: 2.3926 - val_acc: 0.1565\n",
            "Epoch 17/30\n",
            "63448/63448 [==============================] - 4s 66us/step - loss: 2.3891 - acc: 0.1579 - val_loss: 2.3923 - val_acc: 0.1558\n",
            "Epoch 18/30\n",
            "63448/63448 [==============================] - 4s 69us/step - loss: 2.3891 - acc: 0.1571 - val_loss: 2.3920 - val_acc: 0.1569\n",
            "Epoch 19/30\n",
            "63448/63448 [==============================] - 4s 67us/step - loss: 2.3878 - acc: 0.1584 - val_loss: 2.3917 - val_acc: 0.1570\n",
            "Epoch 20/30\n",
            "63448/63448 [==============================] - 4s 67us/step - loss: 2.3874 - acc: 0.1569 - val_loss: 2.3914 - val_acc: 0.1567\n",
            "Epoch 21/30\n",
            "63448/63448 [==============================] - 4s 68us/step - loss: 2.3863 - acc: 0.1608 - val_loss: 2.3911 - val_acc: 0.1574\n",
            "Epoch 22/30\n",
            "63448/63448 [==============================] - 4s 68us/step - loss: 2.3853 - acc: 0.1600 - val_loss: 2.3909 - val_acc: 0.1583\n",
            "Epoch 23/30\n",
            "63448/63448 [==============================] - 4s 68us/step - loss: 2.3855 - acc: 0.1595 - val_loss: 2.3907 - val_acc: 0.1596\n",
            "Epoch 24/30\n",
            "63448/63448 [==============================] - 4s 65us/step - loss: 2.3846 - acc: 0.1606 - val_loss: 2.3904 - val_acc: 0.1591\n",
            "Epoch 25/30\n",
            "63448/63448 [==============================] - 4s 69us/step - loss: 2.3842 - acc: 0.1606 - val_loss: 2.3902 - val_acc: 0.1595\n",
            "Epoch 26/30\n",
            "63448/63448 [==============================] - 4s 66us/step - loss: 2.3839 - acc: 0.1598 - val_loss: 2.3900 - val_acc: 0.1597\n",
            "Epoch 27/30\n",
            "63448/63448 [==============================] - 4s 65us/step - loss: 2.3826 - acc: 0.1624 - val_loss: 2.3898 - val_acc: 0.1591\n",
            "Epoch 28/30\n",
            "63448/63448 [==============================] - 4s 65us/step - loss: 2.3833 - acc: 0.1607 - val_loss: 2.3897 - val_acc: 0.1592 loss\n",
            "Epoch 29/30\n",
            "63448/63448 [==============================] - 4s 68us/step - loss: 2.3827 - acc: 0.1615 - val_loss: 2.3895 - val_acc: 0.1592\n",
            "Epoch 30/30\n",
            "63448/63448 [==============================] - 4s 70us/step - loss: 2.3817 - acc: 0.1615 - val_loss: 2.3893 - val_acc: 0.1595\n",
            "Validation Log Loss of  Model in Current Run:  2.389341872515844\n",
            "Train on 63448 samples, validate on 11197 samples\n",
            "Epoch 1/30\n",
            "63448/63448 [==============================] - 5s 82us/step - loss: 2.4303 - acc: 0.1354 - val_loss: 2.4152 - val_acc: 0.1402\n",
            "Epoch 2/30\n",
            "63448/63448 [==============================] - 5s 75us/step - loss: 2.4133 - acc: 0.1441 - val_loss: 2.4097 - val_acc: 0.1409\n",
            "Epoch 3/30\n",
            "63448/63448 [==============================] - 4s 66us/step - loss: 2.4086 - acc: 0.1448 - val_loss: 2.4065 - val_acc: 0.1443\n",
            "Epoch 4/30\n",
            "63448/63448 [==============================] - 4s 66us/step - loss: 2.4052 - acc: 0.1470 - val_loss: 2.4043 - val_acc: 0.1445\n",
            "Epoch 5/30\n",
            "63448/63448 [==============================] - 4s 65us/step - loss: 2.4020 - acc: 0.1481 - val_loss: 2.4025 - val_acc: 0.1454\n",
            "Epoch 6/30\n",
            "63448/63448 [==============================] - 4s 65us/step - loss: 2.4000 - acc: 0.1482 - val_loss: 2.4012 - val_acc: 0.1457\n",
            "Epoch 7/30\n",
            "63448/63448 [==============================] - 4s 66us/step - loss: 2.3986 - acc: 0.1515 - val_loss: 2.4002 - val_acc: 0.1467\n",
            "Epoch 8/30\n",
            "63448/63448 [==============================] - 4s 65us/step - loss: 2.3976 - acc: 0.1530 - val_loss: 2.3993 - val_acc: 0.1483\n",
            "Epoch 9/30\n",
            "63448/63448 [==============================] - 4s 66us/step - loss: 2.3965 - acc: 0.1520 - val_loss: 2.3985 - val_acc: 0.1502\n",
            "Epoch 10/30\n",
            "63448/63448 [==============================] - 5s 74us/step - loss: 2.3947 - acc: 0.1554 - val_loss: 2.3979 - val_acc: 0.1521\n",
            "Epoch 11/30\n",
            "63448/63448 [==============================] - 5s 75us/step - loss: 2.3938 - acc: 0.1554 - val_loss: 2.3973 - val_acc: 0.1528\n",
            "Epoch 12/30\n",
            "63448/63448 [==============================] - 5s 72us/step - loss: 2.3927 - acc: 0.1571 - val_loss: 2.3967 - val_acc: 0.1532\n",
            "Epoch 13/30\n",
            "63448/63448 [==============================] - 5s 75us/step - loss: 2.3918 - acc: 0.1566 - val_loss: 2.3963 - val_acc: 0.1536\n",
            "Epoch 14/30\n",
            "63448/63448 [==============================] - 5s 77us/step - loss: 2.3916 - acc: 0.1557 - val_loss: 2.3958 - val_acc: 0.1540\n",
            "Epoch 15/30\n",
            "63448/63448 [==============================] - 5s 73us/step - loss: 2.3899 - acc: 0.1583 - val_loss: 2.3954 - val_acc: 0.1534\n",
            "Epoch 16/30\n",
            "63448/63448 [==============================] - 5s 74us/step - loss: 2.3889 - acc: 0.1577 - val_loss: 2.3950 - val_acc: 0.1541\n",
            "Epoch 17/30\n",
            "63448/63448 [==============================] - 5s 76us/step - loss: 2.3883 - acc: 0.1594 - val_loss: 2.3946 - val_acc: 0.1545\n",
            "Epoch 18/30\n",
            "63448/63448 [==============================] - 5s 74us/step - loss: 2.3878 - acc: 0.1599 - val_loss: 2.3943 - val_acc: 0.1541\n",
            "Epoch 19/30\n",
            "63448/63448 [==============================] - 5s 80us/step - loss: 2.3873 - acc: 0.1597 - val_loss: 2.3940 - val_acc: 0.1550\n",
            "Epoch 20/30\n",
            "63448/63448 [==============================] - 5s 75us/step - loss: 2.3867 - acc: 0.1590 - val_loss: 2.3937 - val_acc: 0.1548\n",
            "Epoch 21/30\n",
            "63448/63448 [==============================] - 5s 73us/step - loss: 2.3863 - acc: 0.1595 - val_loss: 2.3934 - val_acc: 0.1543\n",
            "Epoch 22/30\n",
            "63448/63448 [==============================] - 5s 74us/step - loss: 2.3854 - acc: 0.1615 - val_loss: 2.3931 - val_acc: 0.1544\n",
            "Epoch 23/30\n",
            "63448/63448 [==============================] - 5s 74us/step - loss: 2.3850 - acc: 0.1609 - val_loss: 2.3929 - val_acc: 0.1545\n",
            "Epoch 24/30\n",
            "63448/63448 [==============================] - 5s 74us/step - loss: 2.3843 - acc: 0.1603 - val_loss: 2.3926 - val_acc: 0.1546\n",
            "Epoch 25/30\n",
            "63448/63448 [==============================] - 5s 75us/step - loss: 2.3838 - acc: 0.1611 - val_loss: 2.3924 - val_acc: 0.1550\n",
            "Epoch 26/30\n",
            "63448/63448 [==============================] - 5s 76us/step - loss: 2.3832 - acc: 0.1623 - val_loss: 2.3922 - val_acc: 0.1547\n",
            "Epoch 27/30\n",
            "63448/63448 [==============================] - 5s 74us/step - loss: 2.3831 - acc: 0.1622 - val_loss: 2.3919 - val_acc: 0.1559\n",
            "Epoch 28/30\n",
            "63448/63448 [==============================] - 5s 73us/step - loss: 2.3824 - acc: 0.1615 - val_loss: 2.3917 - val_acc: 0.1575\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29/30\n",
            "63448/63448 [==============================] - 5s 71us/step - loss: 2.3817 - acc: 0.1609 - val_loss: 2.3915 - val_acc: 0.1576\n",
            "Epoch 30/30\n",
            "63448/63448 [==============================] - 5s 75us/step - loss: 2.3814 - acc: 0.1625 - val_loss: 2.3913 - val_acc: 0.1578\n",
            "Validation Log Loss of  Model in Current Run:  2.391342581548126\n",
            "Average CV Loss of 5 Runs : 2.390651060309039\n"
          ]
        }
      ],
      "source": [
        "random_seeds=[9,18,42,86,103]\n",
        "model_list_2= noevents_average_nn_2(random_seeds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvcqKpwcM0Ek",
        "outputId": "2506e380-a792-44ca-bc81-50f0c00f6d3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Average Log-Loss:  2.3770776429186817\n"
          ]
        }
      ],
      "source": [
        "feat_avg_pred=np.zeros((xtr.shape[0],12))\n",
        "for i in range(len(model_list_2)):\n",
        "    feat_tr_pred=model_list_2[i].predict_proba(xtr)\n",
        "    feat_avg_pred+=feat_tr_pred\n",
        "feat_avg_pred/=len(model_list_2)\n",
        "print(\"Train Average Log-Loss: \",log_loss(ytr, feat_avg_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBkENHE7M0Ek",
        "outputId": "e256edcf-2ee8-479d-fada-671a8e220ad5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Average Log-Loss:  2.3788470152956647\n"
          ]
        }
      ],
      "source": [
        "feat_avg_pred=np.zeros((xcv.shape[0],12))\n",
        "for i in range(len(model_list_2)):\n",
        "    feat_cv_pred=model_list_2[i].predict_proba(xcv)\n",
        "    feat_avg_pred+=feat_cv_pred\n",
        "feat_avg_pred/=len(model_list_2)\n",
        "print(\"Validation Average Log-Loss: \",log_loss(ycv, feat_avg_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbbC347oM0Ek"
      },
      "outputs": [],
      "source": [
        "feat_avg_pred=np.zeros((xtest_noevents.shape[0],12))\n",
        "for i in range(len(model_list_2)):\n",
        "    test_pred=model_list_2[i].predict_proba(feat_Xte_no_eve)\n",
        "    feat_avg_pred+=test_pred\n",
        "feat_avg_pred/=len(model_list_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4W-brIWM0Ek"
      },
      "outputs": [],
      "source": [
        "#saving the model\n",
        "np.save('nn2_noevents_1',feat_avg_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiwOXS_SM0El"
      },
      "source": [
        "OBSERVATIONS:\n",
        "1.THE TRAIN AND VALIDATION LOSS FOR THE MODEL ARE 2.377 AND 2.378 RESPEECTIVELY."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRgcA0ycM0El"
      },
      "source": [
        "# XGBOOST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJ9gXnxBM0El",
        "outputId": "f1d6f2a1-d3ed-4f2e-a904-358ad45f4595"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Log Loss : 2.3718148085004658\n",
            "Validation Log Loss : 2.3929110310146204\n"
          ]
        }
      ],
      "source": [
        "#https://www.kaggle.com/c/talkingdata-mobile-user-demographics/discussion/23424\n",
        "feat_xgb = XGBClassifier(n_estimators=350, n_jobs=-1,learning_rate=0.05, colsample_bytree=0.7, max_depth=5,subsample=0.7,objective='multi:softprob',num_class=12,eval_metric='mlogloss')\n",
        "feat_xgb.fit(xtr, ytr)\n",
        "#Using Model Calibration\n",
        "feat_clf = CalibratedClassifierCV(feat_xgb, method=\"sigmoid\")\n",
        "feat_clf.fit(xtr, ytr)\n",
        "\n",
        "feat_pred_y=feat_clf.predict_proba(xtr)\n",
        "print(\"Train Log Loss :\",log_loss(ytr, feat_pred_y))\n",
        "\n",
        "\n",
        "feat_pred_y=feat_clf.predict_proba(xcv)\n",
        "print(\"Validation Log Loss :\",log_loss(ycv, feat_pred_y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnwHxZhIM0El"
      },
      "outputs": [],
      "source": [
        "feat_no_eve_pred_lr=feat_clf.predict_proba(feat_Xte_no_eve)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9RjZo57M0El"
      },
      "outputs": [],
      "source": [
        "#saving the model\n",
        "np.save('xgb_noevents_1.npy',feat_no_eve_pred_lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIUs5Bk7M0El"
      },
      "source": [
        "OBSERVATIONS:\n",
        "THE TRAIN AND VALIDATION LOSS ARE 2.3718 AND 2.3929 RESPECTIVELY.\n",
        "THESE ARE NOT AS GOOD AS THE NEURAL NETWORK MODEL."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3ih6OE3M0Em"
      },
      "source": [
        "# MODELLING USING DEVICES WITH EVENTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-h-wgIeM0Em"
      },
      "source": [
        "# ONE HOT ENCODING OF PHONE BRAND"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggx_jFZLM0Em",
        "outputId": "402e1c0f-9142-4781-bc23-ecdfd5a6941d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Brand One-hot Shape:  (23309, 131)\n",
            "Test Brand One-hot Shape:  (35194, 131)\n"
          ]
        }
      ],
      "source": [
        "feat_gatr_eve['brand']=feat_ph['brand']\n",
        "feat_gate_eve['brand']=feat_ph['brand']\n",
        "\n",
        "\n",
        "#https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html\n",
        "feat_Xtr_eve_br = csr_matrix((np.ones(feat_gatr_eve.shape[0]), # Number of Rows/Devices\n",
        "                       (feat_gatr_eve.trainrow, feat_gatr_eve.brand)),shape=(feat_gatr_eve.shape[0],nbrand))\n",
        "feat_Xte_eve_br = csr_matrix((np.ones(feat_gate_eve.shape[0]), # Number of Rows/Devices\n",
        "                       (feat_gate_eve.testrow, feat_gate_eve.brand)),shape=(feat_gate_eve.shape[0],nbrand))\n",
        "\n",
        "print(\"Train Brand One-hot Shape: \",feat_Xtr_eve_br.shape)\n",
        "print(\"Test Brand One-hot Shape: \",feat_Xtr_eve_br.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpb4MjAxM0Em"
      },
      "source": [
        "#  ONE HOT ENCODING OF PHONE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAjd3rZYM0Em",
        "outputId": "9cda3563-8f43-483a-ae32-96d1f9bc1d21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Brand One-hot Shape:  (23309, 1667)\n",
            "Test Brand One-hot Shape:  (35194, 1667)\n"
          ]
        }
      ],
      "source": [
        "feat_gatr_eve['model']=feat_ph['model']\n",
        "feat_gate_eve['model']=feat_ph['model']\n",
        "\n",
        "feat_Xtr_eve_mod = csr_matrix((np.ones(feat_gatr_eve.shape[0]), \n",
        "                       (feat_gatr_eve.trainrow, feat_gatr_eve.model)),shape=(feat_gatr_eve.shape[0],nmodel))\n",
        "\n",
        "feat_Xte_eve_mod = csr_matrix((np.ones(feat_gate_eve.shape[0]), \n",
        "                       (feat_gate_eve.testrow, feat_gate_eve.model)),shape=(feat_gate_eve.shape[0],nmodel))\n",
        "print(\"Train Brand One-hot Shape: \",feat_Xtr_eve_mod.shape)\n",
        "print(\"Test Brand One-hot Shape: \",feat_Xte_eve_mod.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZ4QGug0M0En"
      },
      "source": [
        "# ONE HOT ENCODING OF DEVICE APPS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-469YFNM0En",
        "outputId": "2721dfcd-58c0-465f-f56d-f48255412102"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Event Apps One-hot Shape:  (23309, 19237)\n",
            "Test Event Apps One-hot Shape:  (35194, 19237)\n"
          ]
        }
      ],
      "source": [
        "#Since the Deviceapps has both train and test columns merged to create Train Apps One-Hot we will Drop all Nan of Train Row\n",
        "#Once we remove Nan in Train Rows we will get the Apps in Train Data and we create CSR Matrix for those rows\n",
        "d = feat_devic_aps.dropna(subset=['trainrow'])\n",
        "feat_Xtr_eve_app = csr_matrix((np.ones(d.shape[0]), (d.trainrow, d.app)), \n",
        "                      shape=(feat_gatr_eve.shape[0],napps))\n",
        "\n",
        "#Since the Deviceapps has both train and test columns merged to create Test Apps One-Hot we will Drop all Nan of Test Row\n",
        "#Once we remove Nan in Test Rows we will get the Apps in Test Data and we create CSR Matrix for those rows\n",
        "d = feat_devic_aps.dropna(subset=['testrow'])\n",
        "feat_Xte_eve_app = csr_matrix((np.ones(d.shape[0]), (d.testrow, d.app)), \n",
        "                      shape=(feat_gate_eve.shape[0],napps))\n",
        "print(\"Train Event Apps One-hot Shape: \",feat_Xtr_eve_app.shape)\n",
        "print(\"Test Event Apps One-hot Shape: \",feat_Xte_eve_app.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bt-sOHRtM0En"
      },
      "source": [
        "# ONE HOT ENCODING OF DEVICE LABELS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJMR1U9OM0En",
        "outputId": "0001e8d3-6df6-4da4-d102-0c7ba52714bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Event Labels One-hot Shape:  (23309, 492)\n",
            "Test Event Labels One-hot Shape:  (35194, 492)\n"
          ]
        }
      ],
      "source": [
        "#Since the Devicelabels has both train and test columns merged to create Train Labels One-Hot we will Drop all Nan of Train Row\n",
        "#Once we remove Nan in Train Rows we will get the Labels in Train Data and we create CSR Matrix for those rows\n",
        "d = feat_devic_lab.dropna(subset=['trainrow'])\n",
        "feat_Xtr_eve_lab = csr_matrix((np.ones(d.shape[0]), (d.trainrow, d.label)), \n",
        "                      shape=(feat_gatr_eve.shape[0],nlabels))\n",
        "#Since the Devicelabels has both train and test columns merged to create Test Labels One-Hot we will Drop all Nan of Test Row\n",
        "#Once we remove Nan in Test Rows we will get the Labels in Test Data and we create CSR Matrix for those rows\n",
        "d = feat_devic_lab.dropna(subset=['testrow'])\n",
        "feat_Xte_eve_lab = csr_matrix((np.ones(d.shape[0]), (d.testrow, d.label)), \n",
        "                      shape=(feat_gate_eve.shape[0],nlabels))\n",
        "print(\"Train Event Labels One-hot Shape: \",feat_Xtr_eve_lab.shape)\n",
        "print(\"Test Event Labels One-hot Shape: \",feat_Xte_eve_lab.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nG8YZvgtM0Eo"
      },
      "source": [
        "# TFIDF  FEATURES FOR HOURS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oLYtKStM0Eo",
        "outputId": "f0bd891f-6d4c-4799-ab99-08e41161840b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Event Hours TF-IDF Shape:  (23309, 24)\n",
            "Test Event Hours TF-IDF Shape:  (35194, 24)\n"
          ]
        }
      ],
      "source": [
        "feat_gatr_eve[\"hourjoin\"]=feat_gatr_eve.index.map(hourjoin)\n",
        "feat_gate_eve[\"hourjoin\"]=feat_gate_eve.index.map(hourjoin)\n",
        "\n",
        "feat_vectorzr=TfidfVectorizer()\n",
        "feat_vectorzr.fit(feat_gatr_eve['hourjoin'].values)\n",
        "\n",
        "feat_Xtr_horjoin_tfidf = feat_vectorzr.transform(feat_gatr_eve['hourjoin'].values)\n",
        "feat_Xte_horjoin_tfidf = feat_vectorzr.transform(feat_gate_eve['hourjoin'].values)\n",
        "\n",
        "print(\"Train Event Hours TF-IDF Shape: \",feat_Xtr_horjoin_tfidf.shape)\n",
        "print(\"Test Event Hours TF-IDF Shape: \",feat_Xtr_horjoin_tfidf.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFUcJeVhM0Eo"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('hour_tfidf','wb') as fp:\n",
        "    pickle.dump(feat_vectorzr,fp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehg3DneJM0Eo"
      },
      "source": [
        "#  BOW FOR HOURS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHFfWmJAM0Eo",
        "outputId": "24ba3106-222c-4117-82bb-c87b1dd47446"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After vectorizations\n",
            "Train Event Hours One-hot Shape:  (23309, 24)\n",
            "Test Event Hours One-hot Shape:  (35194, 24)\n"
          ]
        }
      ],
      "source": [
        "feat_gatr_eve[\"hourjoin\"]=feat_gatr_eve.index.map(hourjoin)\n",
        "feat_gate_eve[\"hourjoin\"]=feat_gate_eve.index.map(hourjoin)\n",
        "\n",
        "feat_vectorzr=CountVectorizer()\n",
        "feat_vectorzr.fit(feat_gatr_eve['hourjoin'].values)\n",
        "\n",
        "feat_X_tr_hrjoin_onehot = feat_vectorzr.transform(feat_gatr_eve['hourjoin'].values)\n",
        "feat_X_te_hrjoin_onehot = feat_vectorzr.transform(feat_gate_eve['hourjoin'].values)\n",
        "print(\"After vectorizations\")\n",
        "print(\"Train Event Hours One-hot Shape: \",feat_X_tr_hrjoin_onehot.shape)\n",
        "print(\"Test Event Hours One-hot Shape: \",feat_X_te_hrjoin_onehot.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZFQHgj8M0Eo"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('hour_bow','wb') as fp:\n",
        "    pickle.dump(feat_vectorzr,fp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaWbooR6M0Ep"
      },
      "source": [
        "# ONE HOT ENCODING OF HOUR BIN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQ_qDAsYM0Ep",
        "outputId": "83d29d17-d6a5-41cb-a960-b6c2cc0e5b8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Event Hours One-hot Shape:  (23309, 4)\n",
            "Test Event Hours One-hot Shape:  (35194, 4)\n"
          ]
        }
      ],
      "source": [
        "feat_gatr_eve[\"hourbinjoin\"]=feat_gatr_eve.index.map(hourbinjoin)\n",
        "feat_gate_eve[\"hourbinjoin\"]=feat_gate_eve.index.map(hourbinjoin)\n",
        "\n",
        "feat_vectorzr=CountVectorizer(binary=True)\n",
        "feat_vectorzr.fit(feat_gatr_eve['hourbinjoin'].values)\n",
        "\n",
        "feat_X_tr_hrbinjoin_onehot = feat_vectorzr.transform(feat_gatr_eve['hourbinjoin'].values)\n",
        "feat_X_te_hrbinjoin_onehot = feat_vectorzr.transform(feat_gate_eve['hourbinjoin'].values)\n",
        "\n",
        "print(\"Train Event Hours One-hot Shape: \",feat_X_tr_hrbinjoin_onehot.shape)\n",
        "print(\"Test Event Hours One-hot Shape: \",feat_X_te_hrbinjoin_onehot.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jdB1oIhM0Ep"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('hour_bin_bow','wb') as fp:\n",
        "    pickle.dump(feat_vectorzr,fp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkN3msXvM0Ep"
      },
      "source": [
        "# TFIDF FEATURES FOR DAY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQidM53UM0Ep",
        "outputId": "af446ee4-bbdd-4c65-91b9-a1591f3cf3de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After vectorizations\n",
            "Train Event days TF-IDF Shape:  (23309, 7)\n",
            "Test Event days TF-IDF Shape:  (35194, 7)\n"
          ]
        }
      ],
      "source": [
        "feat_gatr_eve[\"daysjoin\"]=feat_gatr_eve.index.map(daysjoin)\n",
        "feat_gate_eve[\"daysjoin\"]=feat_gate_eve.index.map(daysjoin)\n",
        "\n",
        "feat_vectorzr=TfidfVectorizer()\n",
        "feat_vectorzr.fit(feat_gatr_eve['daysjoin'].values)\n",
        "\n",
        "feat_X_tr_daysjoin_tfidf = feat_vectorzr.transform(feat_gatr_eve['daysjoin'].values)\n",
        "feat_X_te_daysjoin_tfidf = feat_vectorzr.transform(feat_gate_eve['daysjoin'].values)\n",
        "print(\"After vectorizations\")\n",
        "print(\"Train Event days TF-IDF Shape: \",feat_X_tr_daysjoin_tfidf.shape)\n",
        "print(\"Test Event days TF-IDF Shape: \",feat_X_te_daysjoin_tfidf.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evtxfx5oM0Eq"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('day_tfidf','wb') as fp:\n",
        "    pickle.dump(feat_vectorzr,fp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9u58_qVM0Eq"
      },
      "source": [
        "# STANDARDIZING LATITUDE AND LONGITUDE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbdrS49OM0Eq",
        "outputId": "1f4d293a-0f87-4963-b2de-0b4898498d08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Event Latitude Standardized Shape:  (23309, 1)\n",
            "Test Event Latitude Standardized  Shape:  (35194, 1)\n"
          ]
        }
      ],
      "source": [
        "feat_gatr_eve[\"latitude\"]=feat_gatr_eve.index.map(median_lat)\n",
        "feat_gate_eve[\"latitude\"]=feat_gate_eve.index.map(median_lat)\n",
        "\n",
        "feat_scalr=StandardScaler()\n",
        "feat_scalr.fit(feat_gatr_eve['latitude'].values.reshape(-1,1))\n",
        "\n",
        "feat_Xtr_eve_lat = feat_scalr.transform(feat_gatr_eve['latitude'].values.reshape(-1,1))\n",
        "feat_Xte_eve_lat = feat_scalr.transform(feat_gate_eve['latitude'].values.reshape(-1,1))\n",
        "\n",
        "print(\"Train Event Latitude Standardized Shape: \",feat_Xtr_eve_lat.shape)\n",
        "print(\"Test Event Latitude Standardized  Shape: \",feat_Xte_eve_lat.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVNWCezlM0Eq"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('lat_scaler','wb') as fp:\n",
        "    pickle.dump(feat_scalr,fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-ROP5-dM0Eq",
        "outputId": "98a92977-485c-4f68-bad1-85f68cf34d47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Event longitude Standardized Shape:  (23309, 1)\n",
            "Test Event longitude Standardized  Shape:  (35194, 1)\n"
          ]
        }
      ],
      "source": [
        "feat_gatr_eve[\"longitude\"]=feat_gatr_eve.index.map(feat_med_lon)\n",
        "feat_gate_eve[\"longitude\"]=feat_gate_eve.index.map(feat_med_lon)\n",
        "\n",
        "feat_scalr=StandardScaler()\n",
        "feat_scalr.fit(feat_gatr_eve['longitude'].values.reshape(-1,1))\n",
        "\n",
        "feat_Xtr_eve_lon = feat_scalr.transform(feat_gatr_eve['longitude'].values.reshape(-1,1))\n",
        "feat_Xte_eve_lon = feat_scalr.transform(feat_gate_eve['longitude'].values.reshape(-1,1))\n",
        "\n",
        "print(\"Train Event longitude Standardized Shape: \",feat_Xtr_eve_lon.shape)\n",
        "print(\"Test Event longitude Standardized  Shape: \",feat_Xtr_eve_lon.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9XST-MYM0Er"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('lon_scaler','wb') as fp:\n",
        "    pickle.dump(feat_scalr,fp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8eCvdq1M0Er"
      },
      "source": [
        "# ONE HOT ENCODING OF CLUSTERED FEATURES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STTIpy2yM0Er",
        "outputId": "bd97c6e5-2f82-4369-c507-818f0a8610c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Event locationbin Shape:  (23309, 10)\n",
            "Test Event locationbin Shape:  (35194, 10)\n"
          ]
        }
      ],
      "source": [
        "feat_gatr_eve[\"locationbin\"]=feat_gatr_eve.index.map(clustered_geo_features)\n",
        "feat_gate_eve[\"locationbin\"]=feat_gate_eve.index.map(clustered_geo_features)\n",
        "\n",
        "#feat_gatr_eve.locationbin=feat_gatr_eve.locationbin.astype(str)\n",
        "#feat_gate_eve.locationbin=feat_gate_eve.locationbin.astype(str)\n",
        "\n",
        "feat_vectorzr= OneHotEncoder()\n",
        "feat_vectorzr.fit(feat_gatr_eve['locationbin'].values.reshape(-1,1))\n",
        "\n",
        "feat_X_tr_clus = feat_vectorzr.transform(feat_gatr_eve['locationbin'].values.reshape(-1,1))\n",
        "feat_X_te_clus = feat_vectorzr.transform(feat_gate_eve['locationbin'].values.reshape(-1,1))\n",
        "\n",
        "print(\"Train Event locationbin Shape: \",feat_X_tr_clus.shape)\n",
        "print(\"Test Event locationbin Shape: \",feat_X_te_clus.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEQVTCdqM0Er"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('clustered_features','wb') as fp:\n",
        "    pickle.dump(feat_vectorzr,fp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJ-d_0NOM0Er"
      },
      "source": [
        "# TFIDF FEATURE FOR APP IS_ACTIVE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d34jHUZGM0Er",
        "outputId": "3f95484e-4497-4f41-ef1a-537f890537c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Apps Active TF-IDF Shape:  (23309, 2)\n",
            "Test Apps Active TF-IDF Shape:  (35194, 2)\n"
          ]
        }
      ],
      "source": [
        "#Mapping The Values the values to train and test dataframes\n",
        "feat_gatr_eve['apps_active']=feat_gatr_eve.index.map(active_apps_events)\n",
        "feat_gate_eve['apps_active']=feat_gate_eve.index.map(active_apps_events)\n",
        "\n",
        "feat_vectorzr=TfidfVectorizer()\n",
        "feat_vectorzr.fit(feat_gatr_eve['apps_active'].values)\n",
        "\n",
        "feat_X_tr_activ = feat_vectorzr.transform(feat_gatr_eve['apps_active'].values)\n",
        "feat_X_te_activ = feat_vectorzr.transform(feat_gate_eve['apps_active'].values)\n",
        "\n",
        "print(\"Train Apps Active TF-IDF Shape: \",feat_X_tr_activ.shape)\n",
        "print(\"Test Apps Active TF-IDF Shape: \",feat_X_te_activ.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQDcfHIaM0Es"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('isactive_tfidf','wb') as fp:\n",
        "    pickle.dump(feat_vectorzr,fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frSPkwRBM0Es",
        "outputId": "9c6fb7e6-c2d2-4e76-ca78-0cf24cc8ef0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(23309, 21576)\n",
            "(35194, 21576)\n"
          ]
        }
      ],
      "source": [
        "#creating final data matrix\n",
        "feat_Xtr_eve=hstack((feat_Xtr_eve_br,feat_Xtr_eve_mod,feat_Xtr_eve_lab,feat_Xtr_horjoin_tfidf,feat_X_tr_hrbinjoin_onehot,feat_X_tr_daysjoin_tfidf,feat_Xtr_eve_lat,feat_Xtr_eve_lon,feat_Xtr_eve_app,feat_X_tr_activ,feat_X_tr_clus),format='csr')\n",
        "\n",
        "feat_Xte_eve =hstack((feat_Xte_eve_br,feat_Xte_eve_mod,feat_Xte_eve_lab,feat_Xte_horjoin_tfidf,feat_X_te_hrbinjoin_onehot,feat_X_te_daysjoin_tfidf,feat_Xte_eve_lat,feat_Xte_eve_lon,feat_Xte_eve_app,feat_X_te_activ,feat_X_te_clus),format='csr')\n",
        "\n",
        "print(feat_Xtr_eve.shape)\n",
        "print(feat_Xte_eve.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Zq1z3bnM0Es"
      },
      "outputs": [],
      "source": [
        "#label encoding target variable\n",
        "feat_targt_encod = LabelEncoder().fit(feat_gatr_eve.group)\n",
        "y = feat_targt_encod.transform(feat_gatr_eve.group)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRWChI-LM0Es",
        "outputId": "3c9b99f5-2b65-4d79-d7e6-c9b2ddc64630"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "xtrain shape: (23309, 21576)\n",
            "ytrain shape: (23309,)\n",
            "xtest shape: (35194, 21576)\n"
          ]
        }
      ],
      "source": [
        "print(\"xtrain shape:\",feat_Xtr_eve.shape)\n",
        "print(\"ytrain shape:\",feat_y.shape)\n",
        "\n",
        "print(\"xtest shape:\",feat_Xte_eve.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6VtHB8mM0Es"
      },
      "outputs": [],
      "source": [
        "xtr, xcv, ytr, ycv = train_test_split(feat_Xtr_eve, y,stratify=feat_y,test_size=0.2,random_state=9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GECljwwRM0Et"
      },
      "outputs": [],
      "source": [
        "#one hot encoding target variable\n",
        "ytr=np_utils.to_categorical(ytr)\n",
        "ycv=np_utils.to_categorical(ycv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTHIzrJCM0Et"
      },
      "source": [
        "# NEURAL NETWORK 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPleRhgmM0Et"
      },
      "outputs": [],
      "source": [
        "def feat_eve_nn_mod1(input_dim,output_dim):\n",
        "    model = Sequential()\n",
        "    model.add(Dropout(0.15, input_shape=(input_dim,)))\n",
        "    model.add(Dense(240, init='uniform'))\n",
        "    model.add(PReLU(init='zero'))\n",
        "    model.add(Dropout(0.8))\n",
        "    model.add(Dense(240, init='uniform'))\n",
        "    model.add(PReLU(init='zero', weights=None))\n",
        "    model.add(Dropout(0.35))\n",
        "    model.add(Dense(260, init='uniform'))\n",
        "    model.add(PReLU(init='zero', weights=None))\n",
        "    model.add(Dropout(0.40))\n",
        "    model.add(Dense(output_dim, init='uniform'))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    opt = Adagrad(lr=0.008, epsilon=1e-08)\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=opt,\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_NJTl-mM0Et",
        "outputId": "d5f6c039-7fdc-473c-857d-5c59590c0527"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dropout_19 (Dropout)         (None, 21576)             0         \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 240)               5178480   \n",
            "_________________________________________________________________\n",
            "p_re_lu_19 (PReLU)           (None, 240)               240       \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 240)               0         \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 240)               57840     \n",
            "_________________________________________________________________\n",
            "p_re_lu_20 (PReLU)           (None, 240)               240       \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 240)               0         \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 260)               62660     \n",
            "_________________________________________________________________\n",
            "p_re_lu_21 (PReLU)           (None, 260)               260       \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 260)               0         \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 12)                3132      \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 12)                0         \n",
            "=================================================================\n",
            "Total params: 5,302,852\n",
            "Trainable params: 5,302,852\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_sum=feat_eve_nn_mod1(xtr.shape[1],12)\n",
        "model_sum.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVIheZQaM0Eu"
      },
      "outputs": [],
      "source": [
        "early_stop=EarlyStopping(monitor='val_loss',patience=5,restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hOctZmSM0Eu"
      },
      "outputs": [],
      "source": [
        "def feat_eve_avg_nn_1(state):\n",
        "    \"\"\"\n",
        "    Takes a list of Random Seeds, splits the data into Train and CV based on Seed, trains model and takes average of \n",
        "    predictions while testing  \n",
        "    \"\"\"\n",
        "    feat_mod_list=[]\n",
        "    feat_los_list=[]\n",
        "    feat_avg_cv_los=0\n",
        "    for i in range((state)):\n",
        "        model=feat_eve_nn_mod1(xtr.shape[1],12)\n",
        "        model.fit(xtr, ytr, batch_size=149, epochs=20, verbose=1, validation_data=(xcv, ycv),callbacks=[early_stop])\n",
        "        model.save('saved_models/events/nn1'+str(i+1))\n",
        "        eat_pred=model.predict_proba(xcv)\n",
        "        feat_cv_los=log_loss(ycv, eat_pred)\n",
        "        print(\"Validation Log Loss of  Model in Current Run: \",feat_cv_los)\n",
        "        feat_mod_list.append(model)\n",
        "        feat_los_list.append(feat_cv_los)\n",
        "    feat_avg_cv_los=mean(feat_los_list)\n",
        "    print(\"Average CV Loss of \"+str((state))+\" Runs :\",feat_avg_cv_los)\n",
        "    return(feat_mod_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INGm10fIM0Eu",
        "outputId": "c4065edf-95b9-47ca-9707-b562884a1319"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 18647 samples, validate on 4662 samples\n",
            "Epoch 1/20\n",
            "18647/18647 [==============================] - 16s 854us/step - loss: 2.2832 - acc: 0.1883 - val_loss: 2.1078 - val_acc: 0.2602\n",
            "Epoch 2/20\n",
            "18647/18647 [==============================] - 15s 821us/step - loss: 2.1294 - acc: 0.2401 - val_loss: 2.0377 - val_acc: 0.2969\n",
            "Epoch 3/20\n",
            "18647/18647 [==============================] - 15s 804us/step - loss: 2.0580 - acc: 0.2699 - val_loss: 2.0073 - val_acc: 0.3012\n",
            "Epoch 4/20\n",
            "18647/18647 [==============================] - 15s 787us/step - loss: 2.0219 - acc: 0.2880 - val_loss: 1.9709 - val_acc: 0.3215\n",
            "Epoch 5/20\n",
            "18647/18647 [==============================] - 15s 792us/step - loss: 1.9912 - acc: 0.2924 - val_loss: 1.9530 - val_acc: 0.3220\n",
            "Epoch 6/20\n",
            "18647/18647 [==============================] - 15s 805us/step - loss: 1.9563 - acc: 0.3013 - val_loss: 1.9505 - val_acc: 0.3168\n",
            "Epoch 7/20\n",
            "18647/18647 [==============================] - 15s 791us/step - loss: 1.9350 - acc: 0.3127 - val_loss: 1.9464 - val_acc: 0.3220\n",
            "Epoch 8/20\n",
            "18647/18647 [==============================] - 15s 798us/step - loss: 1.9187 - acc: 0.3130 - val_loss: 1.9306 - val_acc: 0.3271\n",
            "Epoch 9/20\n",
            "18647/18647 [==============================] - 15s 785us/step - loss: 1.8983 - acc: 0.3241 - val_loss: 1.9241 - val_acc: 0.3265\n",
            "Epoch 10/20\n",
            "18647/18647 [==============================] - 14s 763us/step - loss: 1.8741 - acc: 0.3339 - val_loss: 1.9207 - val_acc: 0.3275\n",
            "Epoch 11/20\n",
            "18647/18647 [==============================] - 14s 767us/step - loss: 1.8543 - acc: 0.3383 - val_loss: 1.9211 - val_acc: 0.3235\n",
            "Epoch 12/20\n",
            "18647/18647 [==============================] - 15s 778us/step - loss: 1.8433 - acc: 0.3423 - val_loss: 1.9186 - val_acc: 0.3241\n",
            "Epoch 13/20\n",
            "18647/18647 [==============================] - 14s 767us/step - loss: 1.8259 - acc: 0.3439 - val_loss: 1.9126 - val_acc: 0.3263\n",
            "Epoch 14/20\n",
            "18647/18647 [==============================] - 14s 765us/step - loss: 1.8118 - acc: 0.3502 - val_loss: 1.9149 - val_acc: 0.3271\n",
            "Epoch 15/20\n",
            "18647/18647 [==============================] - 14s 764us/step - loss: 1.7944 - acc: 0.3559 - val_loss: 1.9189 - val_acc: 0.3239\n",
            "Epoch 16/20\n",
            "18647/18647 [==============================] - 14s 774us/step - loss: 1.7882 - acc: 0.3608 - val_loss: 1.9151 - val_acc: 0.3275\n",
            "Epoch 17/20\n",
            "18647/18647 [==============================] - 14s 769us/step - loss: 1.7690 - acc: 0.3661 - val_loss: 1.9180 - val_acc: 0.3265\n",
            "Epoch 18/20\n",
            "18647/18647 [==============================] - 15s 778us/step - loss: 1.7641 - acc: 0.3677 - val_loss: 1.9137 - val_acc: 0.3299\n",
            "Validation Log Loss of  Model in Current Run:  1.9136059269573138\n",
            "Train on 18647 samples, validate on 4662 samples\n",
            "Epoch 1/20\n",
            "18647/18647 [==============================] - 16s 876us/step - loss: 2.3051 - acc: 0.1749 - val_loss: 2.1252 - val_acc: 0.2578\n",
            "Epoch 2/20\n",
            "18647/18647 [==============================] - 15s 778us/step - loss: 2.1361 - acc: 0.2389 - val_loss: 2.0454 - val_acc: 0.2898\n",
            "Epoch 3/20\n",
            "18647/18647 [==============================] - 14s 772us/step - loss: 2.0704 - acc: 0.2671 - val_loss: 2.0079 - val_acc: 0.2997\n",
            "Epoch 4/20\n",
            "18647/18647 [==============================] - 14s 776us/step - loss: 2.0264 - acc: 0.2822 - val_loss: 1.9727 - val_acc: 0.3104\n",
            "Epoch 5/20\n",
            "18647/18647 [==============================] - 14s 770us/step - loss: 1.9958 - acc: 0.2914 - val_loss: 1.9737 - val_acc: 0.2992\n",
            "Epoch 6/20\n",
            "18647/18647 [==============================] - 14s 771us/step - loss: 1.9618 - acc: 0.3011 - val_loss: 1.9551 - val_acc: 0.3142\n",
            "Epoch 7/20\n",
            "18647/18647 [==============================] - 15s 787us/step - loss: 1.9387 - acc: 0.3040 - val_loss: 1.9462 - val_acc: 0.3187\n",
            "Epoch 8/20\n",
            "18647/18647 [==============================] - 15s 784us/step - loss: 1.9280 - acc: 0.3159 - val_loss: 1.9417 - val_acc: 0.3142\n",
            "Epoch 9/20\n",
            "18647/18647 [==============================] - 14s 760us/step - loss: 1.9011 - acc: 0.3202 - val_loss: 1.9305 - val_acc: 0.3263\n",
            "Epoch 10/20\n",
            "18647/18647 [==============================] - 14s 774us/step - loss: 1.8765 - acc: 0.3278 - val_loss: 1.9242 - val_acc: 0.3230\n",
            "Epoch 11/20\n",
            "18647/18647 [==============================] - 14s 778us/step - loss: 1.8635 - acc: 0.3388 - val_loss: 1.9216 - val_acc: 0.3213\n",
            "Epoch 12/20\n",
            "18647/18647 [==============================] - 14s 764us/step - loss: 1.8497 - acc: 0.3354 - val_loss: 1.9225 - val_acc: 0.3230\n",
            "Epoch 13/20\n",
            "18647/18647 [==============================] - 14s 767us/step - loss: 1.8411 - acc: 0.3428 - val_loss: 1.9212 - val_acc: 0.3248\n",
            "Epoch 14/20\n",
            "18647/18647 [==============================] - 15s 781us/step - loss: 1.8222 - acc: 0.3436 - val_loss: 1.9160 - val_acc: 0.3237\n",
            "Epoch 15/20\n",
            "18647/18647 [==============================] - 14s 772us/step - loss: 1.8042 - acc: 0.3552 - val_loss: 1.9194 - val_acc: 0.3256\n",
            "Epoch 16/20\n",
            "18647/18647 [==============================] - 14s 763us/step - loss: 1.7896 - acc: 0.3569 - val_loss: 1.9148 - val_acc: 0.3267\n",
            "Epoch 17/20\n",
            "18647/18647 [==============================] - 16s 861us/step - loss: 1.7753 - acc: 0.3638 - val_loss: 1.9220 - val_acc: 0.3263\n",
            "Epoch 18/20\n",
            "18647/18647 [==============================] - 14s 773us/step - loss: 1.7692 - acc: 0.3698 - val_loss: 1.9197 - val_acc: 0.3245\n",
            "Epoch 19/20\n",
            "18647/18647 [==============================] - 14s 769us/step - loss: 1.7475 - acc: 0.3698 - val_loss: 1.9213 - val_acc: 0.3280\n",
            "Epoch 20/20\n",
            "18647/18647 [==============================] - 15s 810us/step - loss: 1.7461 - acc: 0.3712 - val_loss: 1.9354 - val_acc: 0.3170\n",
            "Validation Log Loss of  Model in Current Run:  1.9367125339164373\n",
            "Train on 18647 samples, validate on 4662 samples\n",
            "Epoch 1/20\n",
            "18647/18647 [==============================] - 18s 945us/step - loss: 2.2979 - acc: 0.1819 - val_loss: 2.1559 - val_acc: 0.2606\n",
            "Epoch 2/20\n",
            "18647/18647 [==============================] - 16s 863us/step - loss: 2.1412 - acc: 0.2369 - val_loss: 2.0460 - val_acc: 0.2821\n",
            "Epoch 3/20\n",
            "18647/18647 [==============================] - 16s 834us/step - loss: 2.0747 - acc: 0.2664 - val_loss: 2.0131 - val_acc: 0.3039\n",
            "Epoch 4/20\n",
            "18647/18647 [==============================] - 16s 832us/step - loss: 2.0286 - acc: 0.2797 - val_loss: 1.9821 - val_acc: 0.3091\n",
            "Epoch 5/20\n",
            "18647/18647 [==============================] - 15s 816us/step - loss: 1.9968 - acc: 0.2885 - val_loss: 1.9650 - val_acc: 0.3183\n",
            "Epoch 6/20\n",
            "18647/18647 [==============================] - 15s 828us/step - loss: 1.9620 - acc: 0.3041 - val_loss: 1.9557 - val_acc: 0.3117\n",
            "Epoch 7/20\n",
            "18647/18647 [==============================] - 15s 826us/step - loss: 1.9425 - acc: 0.3070 - val_loss: 1.9472 - val_acc: 0.3164\n",
            "Epoch 8/20\n",
            "18647/18647 [==============================] - 16s 837us/step - loss: 1.9183 - acc: 0.3133 - val_loss: 1.9398 - val_acc: 0.3179\n",
            "Epoch 9/20\n",
            "18647/18647 [==============================] - 15s 819us/step - loss: 1.8951 - acc: 0.3286 - val_loss: 1.9343 - val_acc: 0.3196\n",
            "Epoch 10/20\n",
            "18647/18647 [==============================] - 15s 820us/step - loss: 1.8788 - acc: 0.3281 - val_loss: 1.9219 - val_acc: 0.3237\n",
            "Epoch 11/20\n",
            "18647/18647 [==============================] - 15s 818us/step - loss: 1.8619 - acc: 0.3326 - val_loss: 1.9303 - val_acc: 0.3224\n",
            "Epoch 12/20\n",
            "18647/18647 [==============================] - 15s 820us/step - loss: 1.8488 - acc: 0.3402 - val_loss: 1.9159 - val_acc: 0.3252\n",
            "Epoch 13/20\n",
            "18647/18647 [==============================] - 16s 833us/step - loss: 1.8431 - acc: 0.3404 - val_loss: 1.9160 - val_acc: 0.3256\n",
            "Epoch 14/20\n",
            "18647/18647 [==============================] - 15s 817us/step - loss: 1.8144 - acc: 0.3530 - val_loss: 1.9152 - val_acc: 0.3228\n",
            "Epoch 15/20\n",
            "18647/18647 [==============================] - 15s 799us/step - loss: 1.8013 - acc: 0.3559 - val_loss: 1.9149 - val_acc: 0.3252\n",
            "Epoch 16/20\n",
            "18647/18647 [==============================] - 15s 783us/step - loss: 1.7890 - acc: 0.3582 - val_loss: 1.9145 - val_acc: 0.3280\n",
            "Epoch 17/20\n",
            "18647/18647 [==============================] - 15s 792us/step - loss: 1.7784 - acc: 0.3673 - val_loss: 1.9227 - val_acc: 0.3207\n",
            "Epoch 18/20\n",
            "18647/18647 [==============================] - 15s 812us/step - loss: 1.7676 - acc: 0.3645 - val_loss: 1.9206 - val_acc: 0.3248\n",
            "Epoch 19/20\n",
            "18647/18647 [==============================] - 15s 816us/step - loss: 1.7520 - acc: 0.3730 - val_loss: 1.9182 - val_acc: 0.3256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20/20\n",
            "18647/18647 [==============================] - 15s 817us/step - loss: 1.7487 - acc: 0.3700 - val_loss: 1.9221 - val_acc: 0.3241\n",
            "Validation Log Loss of  Model in Current Run:  1.9237789996264\n",
            "Train on 18647 samples, validate on 4662 samples\n",
            "Epoch 1/20\n",
            "18647/18647 [==============================] - 16s 877us/step - loss: 2.2848 - acc: 0.1854 - val_loss: 2.1432 - val_acc: 0.2492\n",
            "Epoch 2/20\n",
            "18647/18647 [==============================] - 15s 817us/step - loss: 2.1296 - acc: 0.2450 - val_loss: 2.0251 - val_acc: 0.2846\n",
            "Epoch 3/20\n",
            "18647/18647 [==============================] - 15s 818us/step - loss: 2.0554 - acc: 0.2733 - val_loss: 1.9900 - val_acc: 0.3140\n",
            "Epoch 4/20\n",
            "18647/18647 [==============================] - 15s 824us/step - loss: 2.0230 - acc: 0.2837 - val_loss: 1.9835 - val_acc: 0.3050\n",
            "Epoch 5/20\n",
            "18647/18647 [==============================] - 15s 812us/step - loss: 1.9856 - acc: 0.2962 - val_loss: 1.9566 - val_acc: 0.3097\n",
            "Epoch 6/20\n",
            "18647/18647 [==============================] - 14s 759us/step - loss: 1.9666 - acc: 0.3058 - val_loss: 1.9504 - val_acc: 0.3164\n",
            "Epoch 7/20\n",
            "18647/18647 [==============================] - 14s 770us/step - loss: 1.9340 - acc: 0.3111 - val_loss: 1.9408 - val_acc: 0.3218\n",
            "Epoch 8/20\n",
            "18647/18647 [==============================] - 14s 764us/step - loss: 1.9148 - acc: 0.3185 - val_loss: 1.9395 - val_acc: 0.3170\n",
            "Epoch 9/20\n",
            "18647/18647 [==============================] - 14s 772us/step - loss: 1.8887 - acc: 0.3255 - val_loss: 1.9258 - val_acc: 0.3263\n",
            "Epoch 10/20\n",
            "18647/18647 [==============================] - 14s 752us/step - loss: 1.8752 - acc: 0.3336 - val_loss: 1.9244 - val_acc: 0.3215\n",
            "Epoch 11/20\n",
            "18647/18647 [==============================] - 15s 792us/step - loss: 1.8615 - acc: 0.3321 - val_loss: 1.9246 - val_acc: 0.3260\n",
            "Epoch 12/20\n",
            "18647/18647 [==============================] - 15s 799us/step - loss: 1.8423 - acc: 0.3433 - val_loss: 1.9187 - val_acc: 0.3271\n",
            "Epoch 13/20\n",
            "18647/18647 [==============================] - 15s 778us/step - loss: 1.8385 - acc: 0.3447 - val_loss: 1.9206 - val_acc: 0.3297\n",
            "Epoch 14/20\n",
            "18647/18647 [==============================] - 14s 775us/step - loss: 1.8177 - acc: 0.3446 - val_loss: 1.9190 - val_acc: 0.3303\n",
            "Epoch 15/20\n",
            "18647/18647 [==============================] - 16s 834us/step - loss: 1.8023 - acc: 0.3534 - val_loss: 1.9267 - val_acc: 0.3286\n",
            "Epoch 16/20\n",
            "18647/18647 [==============================] - 15s 807us/step - loss: 1.7851 - acc: 0.3625 - val_loss: 1.9182 - val_acc: 0.3286\n",
            "Epoch 17/20\n",
            "18647/18647 [==============================] - 15s 828us/step - loss: 1.7784 - acc: 0.3649 - val_loss: 1.9229 - val_acc: 0.3265\n",
            "Epoch 18/20\n",
            "18647/18647 [==============================] - 16s 859us/step - loss: 1.7729 - acc: 0.3613 - val_loss: 1.9256 - val_acc: 0.3280\n",
            "Epoch 19/20\n",
            "18647/18647 [==============================] - 16s 839us/step - loss: 1.7505 - acc: 0.3694 - val_loss: 1.9255 - val_acc: 0.3269\n",
            "Epoch 20/20\n",
            "18647/18647 [==============================] - 16s 840us/step - loss: 1.7471 - acc: 0.3700 - val_loss: 1.9282 - val_acc: 0.3290\n",
            "Validation Log Loss of  Model in Current Run:  1.9296700733280108\n",
            "Train on 18647 samples, validate on 4662 samples\n",
            "Epoch 1/20\n",
            "18647/18647 [==============================] - 17s 894us/step - loss: 2.2951 - acc: 0.1793 - val_loss: 2.1393 - val_acc: 0.2435\n",
            "Epoch 2/20\n",
            "18647/18647 [==============================] - 15s 805us/step - loss: 2.1336 - acc: 0.2361 - val_loss: 2.0347 - val_acc: 0.2958\n",
            "Epoch 3/20\n",
            "18647/18647 [==============================] - 15s 808us/step - loss: 2.0728 - acc: 0.2644 - val_loss: 2.0083 - val_acc: 0.3014\n",
            "Epoch 4/20\n",
            "18647/18647 [==============================] - 15s 808us/step - loss: 2.0254 - acc: 0.2768 - val_loss: 1.9843 - val_acc: 0.3093\n",
            "Epoch 5/20\n",
            "18647/18647 [==============================] - 15s 812us/step - loss: 1.9930 - acc: 0.2908 - val_loss: 1.9700 - val_acc: 0.3054\n",
            "Epoch 6/20\n",
            "18647/18647 [==============================] - 15s 817us/step - loss: 1.9691 - acc: 0.3003 - val_loss: 1.9472 - val_acc: 0.3220\n",
            "Epoch 7/20\n",
            "18647/18647 [==============================] - 15s 814us/step - loss: 1.9395 - acc: 0.3113 - val_loss: 1.9389 - val_acc: 0.3220\n",
            "Epoch 8/20\n",
            "18647/18647 [==============================] - 15s 815us/step - loss: 1.9196 - acc: 0.3163 - val_loss: 1.9315 - val_acc: 0.3185\n",
            "Epoch 9/20\n",
            "18647/18647 [==============================] - 15s 814us/step - loss: 1.9017 - acc: 0.3158 - val_loss: 1.9310 - val_acc: 0.3200\n",
            "Epoch 10/20\n",
            "18647/18647 [==============================] - 15s 821us/step - loss: 1.8796 - acc: 0.3274 - val_loss: 1.9207 - val_acc: 0.3284\n",
            "Epoch 11/20\n",
            "18647/18647 [==============================] - 16s 846us/step - loss: 1.8728 - acc: 0.3352 - val_loss: 1.9191 - val_acc: 0.3239\n",
            "Epoch 12/20\n",
            "18647/18647 [==============================] - 15s 814us/step - loss: 1.8577 - acc: 0.3363 - val_loss: 1.9195 - val_acc: 0.3245\n",
            "Epoch 13/20\n",
            "18647/18647 [==============================] - 16s 836us/step - loss: 1.8376 - acc: 0.3419 - val_loss: 1.9163 - val_acc: 0.3220\n",
            "Epoch 14/20\n",
            "18647/18647 [==============================] - 15s 817us/step - loss: 1.8172 - acc: 0.3492 - val_loss: 1.9152 - val_acc: 0.3256\n",
            "Epoch 15/20\n",
            "18647/18647 [==============================] - 15s 789us/step - loss: 1.8079 - acc: 0.3524 - val_loss: 1.9180 - val_acc: 0.3245\n",
            "Epoch 16/20\n",
            "18647/18647 [==============================] - 15s 797us/step - loss: 1.7937 - acc: 0.3543 - val_loss: 1.9127 - val_acc: 0.3252\n",
            "Epoch 17/20\n",
            "18647/18647 [==============================] - 15s 808us/step - loss: 1.7825 - acc: 0.3616 - val_loss: 1.9160 - val_acc: 0.3198\n",
            "Epoch 18/20\n",
            "18647/18647 [==============================] - 15s 819us/step - loss: 1.7666 - acc: 0.3665 - val_loss: 1.9178 - val_acc: 0.3224\n",
            "Epoch 19/20\n",
            "18647/18647 [==============================] - 15s 827us/step - loss: 1.7566 - acc: 0.3685 - val_loss: 1.9203 - val_acc: 0.3237\n",
            "Epoch 20/20\n",
            "18647/18647 [==============================] - 15s 804us/step - loss: 1.7386 - acc: 0.3699 - val_loss: 1.9194 - val_acc: 0.3181\n",
            "Validation Log Loss of  Model in Current Run:  1.9203065615975894\n",
            "Train on 18647 samples, validate on 4662 samples\n",
            "Epoch 1/20\n",
            "18647/18647 [==============================] - 17s 891us/step - loss: 2.2866 - acc: 0.1833 - val_loss: 2.1179 - val_acc: 0.2531\n",
            "Epoch 2/20\n",
            "18647/18647 [==============================] - 14s 759us/step - loss: 2.1303 - acc: 0.2436 - val_loss: 2.0570 - val_acc: 0.2999\n",
            "Epoch 3/20\n",
            "18647/18647 [==============================] - 14s 757us/step - loss: 2.0682 - acc: 0.2684 - val_loss: 2.0122 - val_acc: 0.2956\n",
            "Epoch 4/20\n",
            "18647/18647 [==============================] - 15s 788us/step - loss: 2.0270 - acc: 0.2828 - val_loss: 1.9793 - val_acc: 0.3085\n",
            "Epoch 5/20\n",
            "18647/18647 [==============================] - 14s 768us/step - loss: 1.9897 - acc: 0.2916 - val_loss: 1.9699 - val_acc: 0.3074\n",
            "Epoch 6/20\n",
            "18647/18647 [==============================] - 15s 791us/step - loss: 1.9645 - acc: 0.3028 - val_loss: 1.9496 - val_acc: 0.3175\n",
            "Epoch 7/20\n",
            "18647/18647 [==============================] - 15s 804us/step - loss: 1.9400 - acc: 0.3117 - val_loss: 1.9357 - val_acc: 0.3226\n",
            "Epoch 8/20\n",
            "18647/18647 [==============================] - 15s 809us/step - loss: 1.9176 - acc: 0.3162 - val_loss: 1.9444 - val_acc: 0.3202\n",
            "Epoch 9/20\n",
            "18647/18647 [==============================] - 16s 839us/step - loss: 1.8963 - acc: 0.3256 - val_loss: 1.9258 - val_acc: 0.3220\n",
            "Epoch 10/20\n",
            "18647/18647 [==============================] - 16s 849us/step - loss: 1.8884 - acc: 0.3282 - val_loss: 1.9217 - val_acc: 0.3260\n",
            "Epoch 11/20\n",
            "18647/18647 [==============================] - 16s 842us/step - loss: 1.8682 - acc: 0.3336 - val_loss: 1.9173 - val_acc: 0.3220\n",
            "Epoch 12/20\n",
            "18647/18647 [==============================] - 16s 856us/step - loss: 1.8451 - acc: 0.3406 - val_loss: 1.9168 - val_acc: 0.3260\n",
            "Epoch 13/20\n",
            "18647/18647 [==============================] - 16s 836us/step - loss: 1.8263 - acc: 0.3428 - val_loss: 1.9159 - val_acc: 0.3299\n",
            "Epoch 14/20\n",
            "18647/18647 [==============================] - 16s 842us/step - loss: 1.8232 - acc: 0.3477 - val_loss: 1.9157 - val_acc: 0.3310\n",
            "Epoch 15/20\n",
            "18647/18647 [==============================] - 16s 877us/step - loss: 1.8113 - acc: 0.3492 - val_loss: 1.9182 - val_acc: 0.3248\n",
            "Epoch 16/20\n",
            "18647/18647 [==============================] - 16s 841us/step - loss: 1.7985 - acc: 0.3532 - val_loss: 1.9158 - val_acc: 0.3299\n",
            "Epoch 17/20\n",
            "18647/18647 [==============================] - 16s 835us/step - loss: 1.7862 - acc: 0.3604 - val_loss: 1.9173 - val_acc: 0.3252\n",
            "Epoch 18/20\n",
            "18647/18647 [==============================] - 16s 839us/step - loss: 1.7741 - acc: 0.3606 - val_loss: 1.9219 - val_acc: 0.3318\n",
            "Epoch 19/20\n",
            "18647/18647 [==============================] - 15s 820us/step - loss: 1.7576 - acc: 0.3723 - val_loss: 1.9194 - val_acc: 0.3312\n",
            "Validation Log Loss of  Model in Current Run:  1.9162446622131852\n",
            "Train on 18647 samples, validate on 4662 samples\n",
            "Epoch 1/20\n",
            "18647/18647 [==============================] - 17s 905us/step - loss: 2.2878 - acc: 0.1842 - val_loss: 2.1195 - val_acc: 0.2492\n",
            "Epoch 2/20\n",
            "18647/18647 [==============================] - 15s 813us/step - loss: 2.1343 - acc: 0.2474 - val_loss: 2.0474 - val_acc: 0.2846\n",
            "Epoch 3/20\n",
            "18647/18647 [==============================] - 15s 826us/step - loss: 2.0727 - acc: 0.2675 - val_loss: 2.0180 - val_acc: 0.3050\n",
            "Epoch 4/20\n",
            "18647/18647 [==============================] - 15s 805us/step - loss: 2.0303 - acc: 0.2795 - val_loss: 1.9816 - val_acc: 0.3093\n",
            "Epoch 5/20\n",
            "18647/18647 [==============================] - 15s 806us/step - loss: 1.9940 - acc: 0.2919 - val_loss: 1.9607 - val_acc: 0.3181\n",
            "Epoch 6/20\n",
            "18647/18647 [==============================] - 15s 824us/step - loss: 1.9651 - acc: 0.3009 - val_loss: 1.9576 - val_acc: 0.3160\n",
            "Epoch 7/20\n",
            "18647/18647 [==============================] - 15s 817us/step - loss: 1.9469 - acc: 0.3098 - val_loss: 1.9380 - val_acc: 0.3183\n",
            "Epoch 8/20\n",
            "18647/18647 [==============================] - 15s 827us/step - loss: 1.9204 - acc: 0.3166 - val_loss: 1.9344 - val_acc: 0.3177\n",
            "Epoch 9/20\n",
            "18647/18647 [==============================] - 15s 821us/step - loss: 1.9028 - acc: 0.3209 - val_loss: 1.9388 - val_acc: 0.3196\n",
            "Epoch 10/20\n",
            "18647/18647 [==============================] - 15s 818us/step - loss: 1.8788 - acc: 0.3278 - val_loss: 1.9261 - val_acc: 0.3226\n",
            "Epoch 11/20\n",
            "18647/18647 [==============================] - 15s 798us/step - loss: 1.8763 - acc: 0.3238 - val_loss: 1.9327 - val_acc: 0.3192\n",
            "Epoch 12/20\n",
            "18647/18647 [==============================] - 15s 798us/step - loss: 1.8506 - acc: 0.3381 - val_loss: 1.9199 - val_acc: 0.3198\n",
            "Epoch 13/20\n",
            "18647/18647 [==============================] - 16s 859us/step - loss: 1.8400 - acc: 0.3446 - val_loss: 1.9195 - val_acc: 0.3278\n",
            "Epoch 14/20\n",
            "18647/18647 [==============================] - 15s 799us/step - loss: 1.8241 - acc: 0.3457 - val_loss: 1.9163 - val_acc: 0.3258\n",
            "Epoch 15/20\n",
            "18647/18647 [==============================] - 15s 807us/step - loss: 1.8058 - acc: 0.3570 - val_loss: 1.9186 - val_acc: 0.3190\n",
            "Epoch 16/20\n",
            "18647/18647 [==============================] - 15s 822us/step - loss: 1.8049 - acc: 0.3513 - val_loss: 1.9140 - val_acc: 0.3258\n",
            "Epoch 17/20\n",
            "18647/18647 [==============================] - 15s 793us/step - loss: 1.7871 - acc: 0.3599 - val_loss: 1.9201 - val_acc: 0.3280\n",
            "Epoch 18/20\n",
            "18647/18647 [==============================] - 15s 807us/step - loss: 1.7747 - acc: 0.3600 - val_loss: 1.9189 - val_acc: 0.3280\n",
            "Epoch 19/20\n",
            "18647/18647 [==============================] - 15s 794us/step - loss: 1.7660 - acc: 0.3639 - val_loss: 1.9219 - val_acc: 0.3241\n",
            "Epoch 20/20\n",
            "18647/18647 [==============================] - 15s 798us/step - loss: 1.7468 - acc: 0.3744 - val_loss: 1.9277 - val_acc: 0.3288\n",
            "Validation Log Loss of  Model in Current Run:  1.9291087886768443\n",
            "Train on 18647 samples, validate on 4662 samples\n",
            "Epoch 1/20\n",
            "18647/18647 [==============================] - 16s 867us/step - loss: 2.2869 - acc: 0.1868 - val_loss: 2.1600 - val_acc: 0.2544\n",
            "Epoch 2/20\n",
            "18647/18647 [==============================] - 15s 806us/step - loss: 2.1389 - acc: 0.2411 - val_loss: 2.0484 - val_acc: 0.2924\n",
            "Epoch 3/20\n",
            "18647/18647 [==============================] - 15s 801us/step - loss: 2.0696 - acc: 0.2671 - val_loss: 2.0009 - val_acc: 0.3012\n",
            "Epoch 4/20\n",
            "18647/18647 [==============================] - 15s 808us/step - loss: 2.0255 - acc: 0.2752 - val_loss: 1.9805 - val_acc: 0.3130\n",
            "Epoch 5/20\n",
            "18647/18647 [==============================] - 15s 808us/step - loss: 1.9912 - acc: 0.2919 - val_loss: 1.9656 - val_acc: 0.3142\n",
            "Epoch 6/20\n",
            "18647/18647 [==============================] - 15s 806us/step - loss: 1.9720 - acc: 0.2947 - val_loss: 1.9542 - val_acc: 0.3138\n",
            "Epoch 7/20\n",
            "18647/18647 [==============================] - 15s 791us/step - loss: 1.9457 - acc: 0.3078 - val_loss: 1.9513 - val_acc: 0.3172\n",
            "Epoch 8/20\n",
            "18647/18647 [==============================] - 15s 804us/step - loss: 1.9199 - acc: 0.3176 - val_loss: 1.9395 - val_acc: 0.3179\n",
            "Epoch 9/20\n",
            "18647/18647 [==============================] - 15s 808us/step - loss: 1.9046 - acc: 0.3221 - val_loss: 1.9298 - val_acc: 0.3237\n",
            "Epoch 10/20\n",
            "18647/18647 [==============================] - 15s 809us/step - loss: 1.8891 - acc: 0.3229 - val_loss: 1.9223 - val_acc: 0.3263\n",
            "Epoch 11/20\n",
            "18647/18647 [==============================] - 15s 820us/step - loss: 1.8708 - acc: 0.3328 - val_loss: 1.9291 - val_acc: 0.3205\n",
            "Epoch 12/20\n",
            "18647/18647 [==============================] - 16s 839us/step - loss: 1.8489 - acc: 0.3430 - val_loss: 1.9208 - val_acc: 0.3252\n",
            "Epoch 13/20\n",
            "18647/18647 [==============================] - 15s 817us/step - loss: 1.8441 - acc: 0.3397 - val_loss: 1.9176 - val_acc: 0.3241\n",
            "Epoch 14/20\n",
            "18647/18647 [==============================] - 15s 818us/step - loss: 1.8205 - acc: 0.3475 - val_loss: 1.9153 - val_acc: 0.3273\n",
            "Epoch 15/20\n",
            "18647/18647 [==============================] - 17s 885us/step - loss: 1.8067 - acc: 0.3520 - val_loss: 1.9165 - val_acc: 0.3275\n",
            "Epoch 16/20\n",
            "18647/18647 [==============================] - 15s 789us/step - loss: 1.7972 - acc: 0.3559 - val_loss: 1.9136 - val_acc: 0.3258\n",
            "Epoch 17/20\n",
            "18647/18647 [==============================] - 15s 792us/step - loss: 1.7898 - acc: 0.3539 - val_loss: 1.9172 - val_acc: 0.3273\n",
            "Epoch 18/20\n",
            "18647/18647 [==============================] - 16s 839us/step - loss: 1.7747 - acc: 0.3601 - val_loss: 1.9187 - val_acc: 0.3288\n",
            "Epoch 19/20\n",
            "18647/18647 [==============================] - 15s 819us/step - loss: 1.7580 - acc: 0.3718 - val_loss: 1.9194 - val_acc: 0.3243\n",
            "Epoch 20/20\n",
            "18647/18647 [==============================] - 15s 818us/step - loss: 1.7521 - acc: 0.3698 - val_loss: 1.9172 - val_acc: 0.3254\n",
            "Validation Log Loss of  Model in Current Run:  1.9185632223832525\n",
            "Train on 18647 samples, validate on 4662 samples\n",
            "Epoch 1/20\n",
            "18647/18647 [==============================] - 17s 919us/step - loss: 2.2961 - acc: 0.1805 - val_loss: 2.1186 - val_acc: 0.2585\n",
            "Epoch 2/20\n",
            "18647/18647 [==============================] - 16s 855us/step - loss: 2.1372 - acc: 0.2459 - val_loss: 2.0371 - val_acc: 0.2932\n",
            "Epoch 3/20\n",
            "18647/18647 [==============================] - 16s 846us/step - loss: 2.0676 - acc: 0.2646 - val_loss: 2.0051 - val_acc: 0.3042\n",
            "Epoch 4/20\n",
            "18647/18647 [==============================] - 15s 809us/step - loss: 2.0292 - acc: 0.2790 - val_loss: 1.9902 - val_acc: 0.3003\n",
            "Epoch 5/20\n",
            "18647/18647 [==============================] - 15s 805us/step - loss: 1.9961 - acc: 0.2886 - val_loss: 1.9915 - val_acc: 0.3093\n",
            "Epoch 6/20\n",
            "18647/18647 [==============================] - 15s 808us/step - loss: 1.9647 - acc: 0.2961 - val_loss: 1.9557 - val_acc: 0.3119\n",
            "Epoch 7/20\n",
            "18647/18647 [==============================] - 16s 834us/step - loss: 1.9419 - acc: 0.3049 - val_loss: 1.9508 - val_acc: 0.3117\n",
            "Epoch 8/20\n",
            "18647/18647 [==============================] - 15s 809us/step - loss: 1.9206 - acc: 0.3195 - val_loss: 1.9425 - val_acc: 0.3179\n",
            "Epoch 9/20\n",
            "18647/18647 [==============================] - 15s 829us/step - loss: 1.9037 - acc: 0.3202 - val_loss: 1.9295 - val_acc: 0.3245\n",
            "Epoch 10/20\n",
            "18647/18647 [==============================] - 16s 843us/step - loss: 1.8851 - acc: 0.3247 - val_loss: 1.9276 - val_acc: 0.3233\n",
            "Epoch 11/20\n",
            "18647/18647 [==============================] - 15s 828us/step - loss: 1.8686 - acc: 0.3282 - val_loss: 1.9285 - val_acc: 0.3202\n",
            "Epoch 12/20\n",
            "18647/18647 [==============================] - 16s 871us/step - loss: 1.8613 - acc: 0.3369 - val_loss: 1.9211 - val_acc: 0.3235\n",
            "Epoch 13/20\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "18647/18647 [==============================] - 16s 858us/step - loss: 1.8450 - acc: 0.3390 - val_loss: 1.9177 - val_acc: 0.3325\n",
            "Epoch 14/20\n",
            "18647/18647 [==============================] - 16s 852us/step - loss: 1.8212 - acc: 0.3487 - val_loss: 1.9146 - val_acc: 0.3293\n",
            "Epoch 15/20\n",
            "18647/18647 [==============================] - 15s 825us/step - loss: 1.8110 - acc: 0.3525 - val_loss: 1.9188 - val_acc: 0.3228\n",
            "Epoch 16/20\n",
            "18647/18647 [==============================] - 15s 822us/step - loss: 1.7998 - acc: 0.3501 - val_loss: 1.9145 - val_acc: 0.3327\n",
            "Epoch 17/20\n",
            "18647/18647 [==============================] - 15s 827us/step - loss: 1.7845 - acc: 0.3560 - val_loss: 1.9213 - val_acc: 0.3218\n",
            "Epoch 18/20\n",
            "18647/18647 [==============================] - 16s 840us/step - loss: 1.7684 - acc: 0.3637 - val_loss: 1.9174 - val_acc: 0.3312\n",
            "Epoch 19/20\n",
            "18647/18647 [==============================] - 15s 830us/step - loss: 1.7573 - acc: 0.3664 - val_loss: 1.9251 - val_acc: 0.3267\n",
            "Epoch 20/20\n",
            "18647/18647 [==============================] - 15s 791us/step - loss: 1.7377 - acc: 0.3765 - val_loss: 1.9242 - val_acc: 0.3250\n",
            "Validation Log Loss of  Model in Current Run:  1.9258740875150422\n",
            "Train on 18647 samples, validate on 4662 samples\n",
            "Epoch 1/20\n",
            "18647/18647 [==============================] - 17s 901us/step - loss: 2.2759 - acc: 0.1882 - val_loss: 2.1619 - val_acc: 0.2218\n",
            "Epoch 2/20\n",
            "18647/18647 [==============================] - 15s 810us/step - loss: 2.1346 - acc: 0.2425 - val_loss: 2.0396 - val_acc: 0.2928\n",
            "Epoch 3/20\n",
            "18647/18647 [==============================] - 15s 818us/step - loss: 2.0685 - acc: 0.2666 - val_loss: 2.0111 - val_acc: 0.2939\n",
            "Epoch 4/20\n",
            "18647/18647 [==============================] - 15s 821us/step - loss: 2.0228 - acc: 0.2806 - val_loss: 1.9822 - val_acc: 0.3035\n",
            "Epoch 5/20\n",
            "18647/18647 [==============================] - 15s 817us/step - loss: 1.9909 - acc: 0.2895 - val_loss: 1.9584 - val_acc: 0.3140\n",
            "Epoch 6/20\n",
            "18647/18647 [==============================] - 15s 815us/step - loss: 1.9623 - acc: 0.3015 - val_loss: 1.9478 - val_acc: 0.3218\n",
            "Epoch 7/20\n",
            "18647/18647 [==============================] - 16s 842us/step - loss: 1.9396 - acc: 0.3083 - val_loss: 1.9474 - val_acc: 0.3172\n",
            "Epoch 8/20\n",
            "18647/18647 [==============================] - 15s 817us/step - loss: 1.9139 - acc: 0.3167 - val_loss: 1.9349 - val_acc: 0.3168\n",
            "Epoch 9/20\n",
            "18647/18647 [==============================] - 15s 814us/step - loss: 1.8933 - acc: 0.3262 - val_loss: 1.9282 - val_acc: 0.3230\n",
            "Epoch 10/20\n",
            "18647/18647 [==============================] - 15s 827us/step - loss: 1.8764 - acc: 0.3325 - val_loss: 1.9207 - val_acc: 0.3245\n",
            "Epoch 11/20\n",
            "18647/18647 [==============================] - 15s 813us/step - loss: 1.8670 - acc: 0.3251 - val_loss: 1.9225 - val_acc: 0.3280\n",
            "Epoch 12/20\n",
            "18647/18647 [==============================] - 15s 814us/step - loss: 1.8539 - acc: 0.3355 - val_loss: 1.9233 - val_acc: 0.3194\n",
            "Epoch 13/20\n",
            "18647/18647 [==============================] - 15s 811us/step - loss: 1.8352 - acc: 0.3401 - val_loss: 1.9188 - val_acc: 0.3230\n",
            "Epoch 14/20\n",
            "18647/18647 [==============================] - 15s 792us/step - loss: 1.8162 - acc: 0.3439 - val_loss: 1.9197 - val_acc: 0.3256\n",
            "Epoch 15/20\n",
            "18647/18647 [==============================] - 15s 806us/step - loss: 1.8127 - acc: 0.3522 - val_loss: 1.9379 - val_acc: 0.3220\n",
            "Epoch 16/20\n",
            "18647/18647 [==============================] - 15s 830us/step - loss: 1.7812 - acc: 0.3601 - val_loss: 1.9163 - val_acc: 0.3237\n",
            "Epoch 17/20\n",
            "18647/18647 [==============================] - 15s 801us/step - loss: 1.7845 - acc: 0.3550 - val_loss: 1.9128 - val_acc: 0.3218\n",
            "Epoch 18/20\n",
            "18647/18647 [==============================] - 15s 788us/step - loss: 1.7699 - acc: 0.3607 - val_loss: 1.9208 - val_acc: 0.3192\n",
            "Epoch 19/20\n",
            "18647/18647 [==============================] - 15s 815us/step - loss: 1.7546 - acc: 0.3693 - val_loss: 1.9202 - val_acc: 0.3209\n",
            "Epoch 20/20\n",
            "18647/18647 [==============================] - 15s 819us/step - loss: 1.7456 - acc: 0.3757 - val_loss: 1.9192 - val_acc: 0.3228\n",
            "Validation Log Loss of  Model in Current Run:  1.9209416287566417\n",
            "Average CV Loss of 10 Runs : 1.9234806484970717\n"
          ]
        }
      ],
      "source": [
        "model_list_2=feat_eve_avg_nn_1(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WwHvx6oM0Eu",
        "outputId": "d22bb9ed-d37d-4c2f-81f1-a5539105c341"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Average Log-Loss:  1.5406584936512548\n"
          ]
        }
      ],
      "source": [
        "feat_avg_pred=np.zeros((xtr.shape[0],12))\n",
        "for i in range(len(model_list_2)):\n",
        "    feat_tr_pred=model_list_2[i].predict_proba(xtr)\n",
        "    feat_avg_pred+=feat_tr_pred\n",
        "feat_avg_pred/=len(model_list_2)\n",
        "print(\"Train Average Log-Loss: \",log_loss(ytr, feat_avg_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ndub8zHPM0Eu",
        "outputId": "130ceccd-7e1f-4771-a091-6ab05a65c352"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Average Log-Loss:  1.9074406784271256\n"
          ]
        }
      ],
      "source": [
        "feat_avg_pred=np.zeros((xcv.shape[0],12))\n",
        "for i in range(len(model_list_2)):\n",
        "    feat_cv_pred=model_list_2[i].predict_proba(xcv)\n",
        "    feat_avg_pred+=feat_cv_pred\n",
        "feat_avg_pred/=len(model_list_2)\n",
        "print(\"Validation Average Log-Loss: \",log_loss(ycv, feat_avg_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bDs_zDbM0Eu"
      },
      "outputs": [],
      "source": [
        "feat_avg_pred=np.zeros((X_test_events.shape[0],12))\n",
        "for i in range(len(model_list_2)):\n",
        "    feat_te_pred=model_list_2[i].predict_proba(X_test_events)\n",
        "    feat_avg_pred+=feat_te_pred\n",
        "feat_avg_pred/=len(model_list_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "480-EAzxM0Ev"
      },
      "outputs": [],
      "source": [
        "np.save('nn1_events_1',feat_avg_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GA8Q6QAQM0Ev"
      },
      "source": [
        "OBSERVATIONS:\n",
        "1.THE TRAIN AND VALIDATION LOSSES ARE 1.5406 AND 1.9074 RESPECTIVELY.\n",
        "2. BOTH TRAIN AND VALIDATIONN LOSSES DECREASED AS WE ADDED MORE FEATURES.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKRkwnOkM0Ev"
      },
      "source": [
        "# NEURAL NETWORK 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gK5IAVjSM0Ev"
      },
      "outputs": [],
      "source": [
        "def feat_eve_nn_mod_2(input_dim,output_dim):\n",
        "    model = Sequential()\n",
        "    model.add(Dropout(0.4, input_shape=(input_dim,)))\n",
        "    model.add(Dense(75))\n",
        "    model.add(PReLU())\n",
        "    model.add(Dropout(0.30))\n",
        "    model.add(Dense(50, init='normal', activation='tanh'))\n",
        "    model.add(PReLU())\n",
        "    model.add(Dropout(0.20))\n",
        "    model.add(Dense(output_dim, init='normal', activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Byhy_obvM0Ev",
        "outputId": "0217aa59-6678-4d53-e7ef-be3c6ef3ef4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dropout_63 (Dropout)         (None, 21576)             0         \n",
            "_________________________________________________________________\n",
            "dense_75 (Dense)             (None, 75)                1618275   \n",
            "_________________________________________________________________\n",
            "p_re_lu_52 (PReLU)           (None, 75)                75        \n",
            "_________________________________________________________________\n",
            "dropout_64 (Dropout)         (None, 75)                0         \n",
            "_________________________________________________________________\n",
            "dense_76 (Dense)             (None, 50)                3800      \n",
            "_________________________________________________________________\n",
            "p_re_lu_53 (PReLU)           (None, 50)                50        \n",
            "_________________________________________________________________\n",
            "dropout_65 (Dropout)         (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_77 (Dense)             (None, 12)                612       \n",
            "=================================================================\n",
            "Total params: 1,622,812\n",
            "Trainable params: 1,622,812\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_sum=feat_eve_nn_mod_2(xtr.shape[1],12)\n",
        "model_sum.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0uFhfEyM0Ev"
      },
      "outputs": [],
      "source": [
        "def feat_eve_avg_nn_2(state):\n",
        "\n",
        "    model_list=[]\n",
        "    loss_list=[]\n",
        "    feat_avg_cv_los=0\n",
        "    for i in range((state)):\n",
        "        model=events_nn_model2(xtr.shape[1],12)\n",
        "        model.fit(xtr, ytr, batch_size=149, epochs=20, verbose=1, validation_data=(xcv, ycv),callbacks=[early_stop])\n",
        "        model.save('saved_models/events/nn2'+str(i+1))\n",
        "        feat_pred=model.predict_proba(xcv)\n",
        "        feat_cv_los=log_loss(ycv, feat_pred)\n",
        "        print(\"Validation Log Loss of  Model in Current Run: \",feat_cv_los)\n",
        "        feat_mod_list.append(model)\n",
        "        feat_los_list.append(feat_cv_los)\n",
        "    feat_avg_cv_los=mean(feat_los_list)\n",
        "    print(\"Average CV Loss of \"+str((state))+\" Runs :\",feat_avg_cv_los)\n",
        "    return(feat_mod_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNfjVv4eM0Ew",
        "outputId": "e6c77574-c674-4084-c52a-4e57ee2ff35e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 18647 samples, validate on 4662 samples\n",
            "Epoch 1/20\n",
            "18647/18647 [==============================] - 13s 706us/step - loss: 2.3350 - acc: 0.1686 - val_loss: 2.1600 - val_acc: 0.2454\n",
            "Epoch 2/20\n",
            "18647/18647 [==============================] - 12s 641us/step - loss: 2.1608 - acc: 0.2397 - val_loss: 2.0982 - val_acc: 0.2683\n",
            "Epoch 3/20\n",
            "18647/18647 [==============================] - 13s 689us/step - loss: 2.0919 - acc: 0.2597 - val_loss: 2.0512 - val_acc: 0.2861\n",
            "Epoch 4/20\n",
            "18647/18647 [==============================] - 13s 685us/step - loss: 2.0469 - acc: 0.2799 - val_loss: 1.9799 - val_acc: 0.3166\n",
            "Epoch 5/20\n",
            "18647/18647 [==============================] - 12s 632us/step - loss: 2.0245 - acc: 0.2851 - val_loss: 1.9927 - val_acc: 0.3027\n",
            "Epoch 6/20\n",
            "18647/18647 [==============================] - 12s 635us/step - loss: 1.9889 - acc: 0.2986 - val_loss: 1.9650 - val_acc: 0.3162\n",
            "Epoch 7/20\n",
            "18647/18647 [==============================] - 12s 650us/step - loss: 1.9787 - acc: 0.3034 - val_loss: 1.9700 - val_acc: 0.3142\n",
            "Epoch 8/20\n",
            "18647/18647 [==============================] - 13s 712us/step - loss: 1.9568 - acc: 0.3110 - val_loss: 1.9337 - val_acc: 0.3233\n",
            "Epoch 9/20\n",
            "18647/18647 [==============================] - 12s 657us/step - loss: 1.9395 - acc: 0.3102 - val_loss: 1.9785 - val_acc: 0.3140\n",
            "Epoch 10/20\n",
            "18647/18647 [==============================] - 12s 658us/step - loss: 1.9292 - acc: 0.3182 - val_loss: 1.9467 - val_acc: 0.3164\n",
            "Epoch 11/20\n",
            "18647/18647 [==============================] - 12s 634us/step - loss: 1.9116 - acc: 0.3227 - val_loss: 1.9328 - val_acc: 0.3187\n",
            "Epoch 12/20\n",
            "18647/18647 [==============================] - 12s 623us/step - loss: 1.8988 - acc: 0.3324 - val_loss: 1.9169 - val_acc: 0.3278\n",
            "Epoch 13/20\n",
            "18647/18647 [==============================] - 12s 636us/step - loss: 1.8862 - acc: 0.3372 - val_loss: 1.9572 - val_acc: 0.3102\n",
            "Epoch 14/20\n",
            "18647/18647 [==============================] - 12s 622us/step - loss: 1.8677 - acc: 0.3404 - val_loss: 1.9572 - val_acc: 0.3190\n",
            "Epoch 15/20\n",
            "18647/18647 [==============================] - 12s 626us/step - loss: 1.8570 - acc: 0.3413 - val_loss: 1.9490 - val_acc: 0.3181\n",
            "Epoch 16/20\n",
            "18647/18647 [==============================] - 12s 627us/step - loss: 1.8447 - acc: 0.3522 - val_loss: 1.9303 - val_acc: 0.3301\n",
            "Epoch 17/20\n",
            "18647/18647 [==============================] - 12s 637us/step - loss: 1.8272 - acc: 0.3567 - val_loss: 1.9427 - val_acc: 0.3260\n",
            "Validation Log Loss of  Model in Current Run:  1.9168982927262757\n",
            "Train on 18647 samples, validate on 4662 samples\n",
            "Epoch 1/20\n",
            "18647/18647 [==============================] - 13s 707us/step - loss: 2.3279 - acc: 0.1774 - val_loss: 2.1513 - val_acc: 0.2424\n",
            "Epoch 2/20\n",
            "18647/18647 [==============================] - 12s 617us/step - loss: 2.1482 - acc: 0.2451 - val_loss: 2.1517 - val_acc: 0.2480\n",
            "Epoch 3/20\n",
            "18647/18647 [==============================] - 11s 612us/step - loss: 2.0857 - acc: 0.2651 - val_loss: 2.0919 - val_acc: 0.2662\n",
            "Epoch 4/20\n",
            "18647/18647 [==============================] - 12s 618us/step - loss: 2.0402 - acc: 0.2813 - val_loss: 2.0846 - val_acc: 0.2656\n",
            "Epoch 5/20\n",
            "18647/18647 [==============================] - 12s 620us/step - loss: 2.0140 - acc: 0.2892 - val_loss: 1.9836 - val_acc: 0.2969\n",
            "Epoch 6/20\n",
            "18647/18647 [==============================] - 11s 616us/step - loss: 1.9926 - acc: 0.2990 - val_loss: 1.9386 - val_acc: 0.3202\n",
            "Epoch 7/20\n",
            "18647/18647 [==============================] - 12s 621us/step - loss: 1.9673 - acc: 0.3070 - val_loss: 1.9354 - val_acc: 0.3256\n",
            "Epoch 8/20\n",
            "18647/18647 [==============================] - 11s 616us/step - loss: 1.9498 - acc: 0.3137 - val_loss: 1.9509 - val_acc: 0.3149\n",
            "Epoch 9/20\n",
            "18647/18647 [==============================] - 12s 618us/step - loss: 1.9301 - acc: 0.3227 - val_loss: 1.9435 - val_acc: 0.3267\n",
            "Epoch 10/20\n",
            "18647/18647 [==============================] - 11s 611us/step - loss: 1.9183 - acc: 0.3233 - val_loss: 1.9459 - val_acc: 0.3164\n",
            "Epoch 11/20\n",
            "18647/18647 [==============================] - 11s 603us/step - loss: 1.9008 - acc: 0.3277 - val_loss: 1.9223 - val_acc: 0.3271\n",
            "Epoch 12/20\n",
            "18647/18647 [==============================] - 11s 610us/step - loss: 1.8960 - acc: 0.3343 - val_loss: 1.9331 - val_acc: 0.3237\n",
            "Epoch 13/20\n",
            "18647/18647 [==============================] - 12s 645us/step - loss: 1.8700 - acc: 0.3377 - val_loss: 1.9246 - val_acc: 0.3256\n",
            "Epoch 14/20\n",
            "18647/18647 [==============================] - 11s 604us/step - loss: 1.8607 - acc: 0.3458 - val_loss: 1.9147 - val_acc: 0.3194\n",
            "Epoch 15/20\n",
            "18647/18647 [==============================] - 11s 603us/step - loss: 1.8494 - acc: 0.3460 - val_loss: 1.9315 - val_acc: 0.3239\n",
            "Epoch 16/20\n",
            "18647/18647 [==============================] - 11s 611us/step - loss: 1.8367 - acc: 0.3515 - val_loss: 1.9360 - val_acc: 0.3166\n",
            "Epoch 17/20\n",
            "18647/18647 [==============================] - 12s 617us/step - loss: 1.8187 - acc: 0.3571 - val_loss: 1.9337 - val_acc: 0.3175\n",
            "Epoch 18/20\n",
            "18647/18647 [==============================] - 12s 620us/step - loss: 1.8112 - acc: 0.3591 - val_loss: 1.9263 - val_acc: 0.3192\n",
            "Epoch 19/20\n",
            "18647/18647 [==============================] - 12s 624us/step - loss: 1.7877 - acc: 0.3687 - val_loss: 1.9415 - val_acc: 0.3243\n",
            "Validation Log Loss of  Model in Current Run:  1.9146637250839105\n",
            "Train on 18647 samples, validate on 4662 samples\n",
            "Epoch 1/20\n",
            "18647/18647 [==============================] - 13s 715us/step - loss: 2.3170 - acc: 0.1779 - val_loss: 2.1846 - val_acc: 0.2179\n",
            "Epoch 2/20\n",
            "18647/18647 [==============================] - 11s 591us/step - loss: 2.1505 - acc: 0.2411 - val_loss: 2.1458 - val_acc: 0.2432\n",
            "Epoch 3/20\n",
            "18647/18647 [==============================] - 11s 593us/step - loss: 2.0837 - acc: 0.2660 - val_loss: 2.0299 - val_acc: 0.2906\n",
            "Epoch 4/20\n",
            "18647/18647 [==============================] - 11s 588us/step - loss: 2.0430 - acc: 0.2783 - val_loss: 1.9921 - val_acc: 0.3048\n",
            "Epoch 5/20\n",
            "18647/18647 [==============================] - 11s 575us/step - loss: 2.0140 - acc: 0.2928 - val_loss: 1.9691 - val_acc: 0.3190\n",
            "Epoch 6/20\n",
            "18647/18647 [==============================] - 12s 626us/step - loss: 1.9916 - acc: 0.2929 - val_loss: 1.9847 - val_acc: 0.3085\n",
            "Epoch 7/20\n",
            "18647/18647 [==============================] - 11s 604us/step - loss: 1.9701 - acc: 0.3035 - val_loss: 1.9432 - val_acc: 0.3269\n",
            "Epoch 8/20\n",
            "18647/18647 [==============================] - 12s 627us/step - loss: 1.9516 - acc: 0.3111 - val_loss: 1.9360 - val_acc: 0.3243\n",
            "Epoch 9/20\n",
            "18647/18647 [==============================] - 12s 621us/step - loss: 1.9357 - acc: 0.3190 - val_loss: 1.9513 - val_acc: 0.3166\n",
            "Epoch 10/20\n",
            "18647/18647 [==============================] - 11s 613us/step - loss: 1.9228 - acc: 0.3220 - val_loss: 1.9388 - val_acc: 0.3318\n",
            "Epoch 11/20\n",
            "18647/18647 [==============================] - 12s 630us/step - loss: 1.9185 - acc: 0.3197 - val_loss: 1.9370 - val_acc: 0.3190\n",
            "Epoch 12/20\n",
            "18647/18647 [==============================] - 12s 649us/step - loss: 1.8954 - acc: 0.3329 - val_loss: 1.9213 - val_acc: 0.3260\n",
            "Epoch 13/20\n",
            "18647/18647 [==============================] - 12s 632us/step - loss: 1.8787 - acc: 0.3355 - val_loss: 1.9198 - val_acc: 0.3284\n",
            "Epoch 14/20\n",
            "18647/18647 [==============================] - 12s 656us/step - loss: 1.8706 - acc: 0.3384 - val_loss: 1.9149 - val_acc: 0.3282\n",
            "Epoch 15/20\n",
            "18647/18647 [==============================] - 12s 634us/step - loss: 1.8602 - acc: 0.3399 - val_loss: 2.0072 - val_acc: 0.3027\n",
            "Epoch 16/20\n",
            "18647/18647 [==============================] - 12s 631us/step - loss: 1.8425 - acc: 0.3463 - val_loss: 1.9377 - val_acc: 0.3213\n",
            "Epoch 17/20\n",
            "18647/18647 [==============================] - 12s 618us/step - loss: 1.8324 - acc: 0.3504 - val_loss: 1.9421 - val_acc: 0.3185\n",
            "Epoch 18/20\n",
            "18647/18647 [==============================] - 11s 614us/step - loss: 1.8147 - acc: 0.3583 - val_loss: 1.9414 - val_acc: 0.3183\n",
            "Epoch 19/20\n",
            "18647/18647 [==============================] - 11s 616us/step - loss: 1.8030 - acc: 0.3615 - val_loss: 1.9322 - val_acc: 0.3248\n",
            "Validation Log Loss of  Model in Current Run:  1.9148988088457843\n",
            "Train on 18647 samples, validate on 4662 samples\n",
            "Epoch 1/20\n",
            "18647/18647 [==============================] - 14s 727us/step - loss: 2.3361 - acc: 0.1656 - val_loss: 2.2334 - val_acc: 0.2186\n",
            "Epoch 2/20\n",
            "18647/18647 [==============================] - 11s 616us/step - loss: 2.1667 - acc: 0.2360 - val_loss: 2.0562 - val_acc: 0.2891\n",
            "Epoch 3/20\n",
            "18647/18647 [==============================] - 11s 617us/step - loss: 2.0897 - acc: 0.2592 - val_loss: 2.0043 - val_acc: 0.3052\n",
            "Epoch 4/20\n",
            "18647/18647 [==============================] - 12s 620us/step - loss: 2.0462 - acc: 0.2803 - val_loss: 2.0205 - val_acc: 0.2855\n",
            "Epoch 5/20\n",
            "18647/18647 [==============================] - 12s 661us/step - loss: 2.0215 - acc: 0.2885 - val_loss: 1.9720 - val_acc: 0.3106\n",
            "Epoch 6/20\n",
            "18647/18647 [==============================] - 12s 642us/step - loss: 1.9983 - acc: 0.2969 - val_loss: 1.9922 - val_acc: 0.3087\n",
            "Epoch 7/20\n",
            "18647/18647 [==============================] - 12s 650us/step - loss: 1.9755 - acc: 0.3036 - val_loss: 1.9450 - val_acc: 0.3222\n",
            "Epoch 8/20\n",
            "18647/18647 [==============================] - 12s 627us/step - loss: 1.9554 - acc: 0.3114 - val_loss: 1.9403 - val_acc: 0.3260\n",
            "Epoch 9/20\n",
            "18647/18647 [==============================] - 12s 620us/step - loss: 1.9409 - acc: 0.3160 - val_loss: 1.9493 - val_acc: 0.3192\n",
            "Epoch 10/20\n",
            "18647/18647 [==============================] - 11s 609us/step - loss: 1.9268 - acc: 0.3214 - val_loss: 1.9250 - val_acc: 0.3254\n",
            "Epoch 11/20\n",
            "18647/18647 [==============================] - 11s 610us/step - loss: 1.9093 - acc: 0.3275 - val_loss: 1.9665 - val_acc: 0.3119\n",
            "Epoch 12/20\n",
            "18647/18647 [==============================] - 11s 605us/step - loss: 1.9063 - acc: 0.3238 - val_loss: 1.9375 - val_acc: 0.3222\n",
            "Epoch 13/20\n",
            "18647/18647 [==============================] - 11s 610us/step - loss: 1.8821 - acc: 0.3334 - val_loss: 1.9965 - val_acc: 0.3033\n",
            "Epoch 14/20\n",
            "18647/18647 [==============================] - 11s 606us/step - loss: 1.8725 - acc: 0.3372 - val_loss: 1.9428 - val_acc: 0.3198\n",
            "Epoch 15/20\n",
            "18647/18647 [==============================] - 11s 613us/step - loss: 1.8524 - acc: 0.3452 - val_loss: 1.9319 - val_acc: 0.3250\n",
            "Validation Log Loss of  Model in Current Run:  1.924992392238362\n",
            "Train on 18647 samples, validate on 4662 samples\n",
            "Epoch 1/20\n",
            "18647/18647 [==============================] - 13s 717us/step - loss: 2.3289 - acc: 0.1720 - val_loss: 2.2337 - val_acc: 0.2199\n",
            "Epoch 2/20\n",
            "18647/18647 [==============================] - 11s 615us/step - loss: 2.1578 - acc: 0.2379 - val_loss: 2.0511 - val_acc: 0.2840\n",
            "Epoch 3/20\n",
            "18647/18647 [==============================] - 11s 614us/step - loss: 2.0906 - acc: 0.2662 - val_loss: 2.0087 - val_acc: 0.3014\n",
            "Epoch 4/20\n",
            "18647/18647 [==============================] - 11s 607us/step - loss: 2.0399 - acc: 0.2805 - val_loss: 1.9674 - val_acc: 0.3134\n",
            "Epoch 5/20\n",
            "18647/18647 [==============================] - 11s 605us/step - loss: 2.0149 - acc: 0.2923 - val_loss: 1.9848 - val_acc: 0.3054\n",
            "Epoch 6/20\n",
            "18647/18647 [==============================] - 11s 602us/step - loss: 1.9946 - acc: 0.2985 - val_loss: 1.9581 - val_acc: 0.3119\n",
            "Epoch 7/20\n",
            "18647/18647 [==============================] - 12s 622us/step - loss: 1.9732 - acc: 0.3022 - val_loss: 1.9736 - val_acc: 0.3072\n",
            "Epoch 8/20\n",
            "18647/18647 [==============================] - 12s 625us/step - loss: 1.9574 - acc: 0.3069 - val_loss: 1.9595 - val_acc: 0.3106\n",
            "Epoch 9/20\n",
            "18647/18647 [==============================] - 12s 662us/step - loss: 1.9385 - acc: 0.3132 - val_loss: 1.9356 - val_acc: 0.3220\n",
            "Epoch 10/20\n",
            "18647/18647 [==============================] - 14s 754us/step - loss: 1.9191 - acc: 0.3230 - val_loss: 1.9294 - val_acc: 0.3263\n",
            "Epoch 11/20\n",
            "18647/18647 [==============================] - 12s 666us/step - loss: 1.9104 - acc: 0.3273 - val_loss: 1.9277 - val_acc: 0.3245\n",
            "Epoch 12/20\n",
            "18647/18647 [==============================] - 11s 603us/step - loss: 1.8938 - acc: 0.3307 - val_loss: 1.9205 - val_acc: 0.3256\n",
            "Epoch 13/20\n",
            "18647/18647 [==============================] - 11s 609us/step - loss: 1.8837 - acc: 0.3382 - val_loss: 1.9471 - val_acc: 0.3097\n",
            "Epoch 14/20\n",
            "18647/18647 [==============================] - 11s 611us/step - loss: 1.8668 - acc: 0.3381 - val_loss: 1.9324 - val_acc: 0.3220\n",
            "Epoch 15/20\n",
            "18647/18647 [==============================] - 11s 592us/step - loss: 1.8502 - acc: 0.3446 - val_loss: 1.9301 - val_acc: 0.3200\n",
            "Epoch 16/20\n",
            "18647/18647 [==============================] - 11s 593us/step - loss: 1.8359 - acc: 0.3487 - val_loss: 1.9358 - val_acc: 0.3215\n",
            "Epoch 17/20\n",
            "18647/18647 [==============================] - 11s 603us/step - loss: 1.8271 - acc: 0.3550 - val_loss: 1.9568 - val_acc: 0.3192\n",
            "Validation Log Loss of  Model in Current Run:  1.9205034403254269\n",
            "Train on 18647 samples, validate on 4662 samples\n",
            "Epoch 1/20\n",
            "18647/18647 [==============================] - 16s 845us/step - loss: 2.3284 - acc: 0.1669 - val_loss: 2.2163 - val_acc: 0.2059\n",
            "Epoch 2/20\n",
            "18647/18647 [==============================] - 14s 726us/step - loss: 2.1591 - acc: 0.2406 - val_loss: 2.0946 - val_acc: 0.2604\n",
            "Epoch 3/20\n",
            "18647/18647 [==============================] - 14s 727us/step - loss: 2.0845 - acc: 0.2653 - val_loss: 2.0344 - val_acc: 0.2962\n",
            "Epoch 4/20\n",
            "18647/18647 [==============================] - 13s 712us/step - loss: 2.0455 - acc: 0.2804 - val_loss: 2.0642 - val_acc: 0.2786\n",
            "Epoch 5/20\n",
            "18647/18647 [==============================] - 13s 717us/step - loss: 2.0113 - acc: 0.2901 - val_loss: 1.9781 - val_acc: 0.3115\n",
            "Epoch 6/20\n",
            "18647/18647 [==============================] - 13s 708us/step - loss: 1.9870 - acc: 0.2989 - val_loss: 1.9830 - val_acc: 0.2973\n",
            "Epoch 7/20\n",
            "18647/18647 [==============================] - 12s 637us/step - loss: 1.9720 - acc: 0.3011 - val_loss: 1.9472 - val_acc: 0.3218\n",
            "Epoch 8/20\n",
            "18647/18647 [==============================] - 11s 597us/step - loss: 1.9535 - acc: 0.3077 - val_loss: 1.9288 - val_acc: 0.3301\n",
            "Epoch 9/20\n",
            "18647/18647 [==============================] - 11s 607us/step - loss: 1.9335 - acc: 0.3180 - val_loss: 1.9576 - val_acc: 0.3222\n",
            "Epoch 10/20\n",
            "18647/18647 [==============================] - 12s 668us/step - loss: 1.9179 - acc: 0.3243 - val_loss: 1.9331 - val_acc: 0.3220\n",
            "Epoch 11/20\n",
            "18647/18647 [==============================] - 12s 658us/step - loss: 1.9006 - acc: 0.3272 - val_loss: 1.9319 - val_acc: 0.3260\n",
            "Epoch 12/20\n",
            "18647/18647 [==============================] - 12s 661us/step - loss: 1.8932 - acc: 0.3313 - val_loss: 1.9712 - val_acc: 0.2984\n",
            "Epoch 13/20\n",
            "18647/18647 [==============================] - 12s 659us/step - loss: 1.8769 - acc: 0.3369 - val_loss: 1.9516 - val_acc: 0.3106\n",
            "Validation Log Loss of  Model in Current Run:  1.928770428193403\n",
            "Train on 18647 samples, validate on 4662 samples\n",
            "Epoch 1/20\n",
            "18647/18647 [==============================] - 14s 767us/step - loss: 2.3246 - acc: 0.1728 - val_loss: 2.1944 - val_acc: 0.2411\n",
            "Epoch 2/20\n",
            "18647/18647 [==============================] - 11s 576us/step - loss: 2.1514 - acc: 0.2447 - val_loss: 2.1698 - val_acc: 0.2282\n",
            "Epoch 3/20\n",
            "18647/18647 [==============================] - 11s 595us/step - loss: 2.0869 - acc: 0.2667 - val_loss: 2.0212 - val_acc: 0.2979\n",
            "Epoch 4/20\n",
            "18647/18647 [==============================] - 12s 638us/step - loss: 2.0465 - acc: 0.2830 - val_loss: 1.9823 - val_acc: 0.3140\n",
            "Epoch 5/20\n",
            "18647/18647 [==============================] - 13s 703us/step - loss: 2.0152 - acc: 0.2899 - val_loss: 1.9797 - val_acc: 0.3052\n",
            "Epoch 6/20\n",
            "18647/18647 [==============================] - 12s 662us/step - loss: 1.9951 - acc: 0.2960 - val_loss: 1.9542 - val_acc: 0.3196\n",
            "Epoch 7/20\n",
            "18647/18647 [==============================] - 12s 670us/step - loss: 1.9707 - acc: 0.3051 - val_loss: 1.9474 - val_acc: 0.3125\n",
            "Epoch 8/20\n",
            "18647/18647 [==============================] - 11s 601us/step - loss: 1.9533 - acc: 0.3098 - val_loss: 1.9606 - val_acc: 0.3082\n",
            "Epoch 9/20\n",
            "18647/18647 [==============================] - 11s 581us/step - loss: 1.9370 - acc: 0.3130 - val_loss: 1.9435 - val_acc: 0.3241\n",
            "Epoch 10/20\n",
            "18647/18647 [==============================] - 11s 578us/step - loss: 1.9249 - acc: 0.3176 - val_loss: 1.9461 - val_acc: 0.3175\n",
            "Epoch 11/20\n",
            "18647/18647 [==============================] - 11s 580us/step - loss: 1.9060 - acc: 0.3251 - val_loss: 2.0473 - val_acc: 0.2718\n",
            "Epoch 12/20\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "18647/18647 [==============================] - 11s 571us/step - loss: 1.8954 - acc: 0.3305 - val_loss: 1.9139 - val_acc: 0.3303\n",
            "Epoch 13/20\n",
            "18647/18647 [==============================] - 11s 579us/step - loss: 1.8790 - acc: 0.3320 - val_loss: 1.9116 - val_acc: 0.3260\n",
            "Epoch 14/20\n",
            "18647/18647 [==============================] - 11s 577us/step - loss: 1.8626 - acc: 0.3397 - val_loss: 1.9259 - val_acc: 0.3192\n",
            "Epoch 15/20\n",
            "18647/18647 [==============================] - 11s 576us/step - loss: 1.8457 - acc: 0.3463 - val_loss: 1.9211 - val_acc: 0.3230\n",
            "Epoch 16/20\n",
            "18647/18647 [==============================] - 11s 583us/step - loss: 1.8344 - acc: 0.3506 - val_loss: 1.9176 - val_acc: 0.3237\n",
            "Epoch 17/20\n",
            "18647/18647 [==============================] - 11s 580us/step - loss: 1.8264 - acc: 0.3564 - val_loss: 1.9421 - val_acc: 0.3164\n",
            "Epoch 18/20\n",
            "18647/18647 [==============================] - 11s 576us/step - loss: 1.8152 - acc: 0.3565 - val_loss: 1.9458 - val_acc: 0.3149\n",
            "Validation Log Loss of  Model in Current Run:  1.9115930246656696\n",
            "Train on 18647 samples, validate on 4662 samples\n",
            "Epoch 1/20\n",
            "18647/18647 [==============================] - 13s 687us/step - loss: 2.3201 - acc: 0.1744 - val_loss: 2.1997 - val_acc: 0.2201\n",
            "Epoch 2/20\n",
            "18647/18647 [==============================] - 11s 600us/step - loss: 2.1535 - acc: 0.2438 - val_loss: 2.1573 - val_acc: 0.2544\n",
            "Epoch 3/20\n",
            "18647/18647 [==============================] - 11s 577us/step - loss: 2.0855 - acc: 0.2650 - val_loss: 2.0144 - val_acc: 0.2883\n",
            "Epoch 4/20\n",
            "18647/18647 [==============================] - 11s 576us/step - loss: 2.0416 - acc: 0.2830 - val_loss: 1.9886 - val_acc: 0.3097\n",
            "Epoch 5/20\n",
            "18647/18647 [==============================] - 11s 580us/step - loss: 2.0178 - acc: 0.2884 - val_loss: 1.9824 - val_acc: 0.3127\n",
            "Epoch 6/20\n",
            "18647/18647 [==============================] - 11s 581us/step - loss: 1.9873 - acc: 0.3021 - val_loss: 1.9594 - val_acc: 0.3164\n",
            "Epoch 7/20\n",
            "18647/18647 [==============================] - 11s 577us/step - loss: 1.9680 - acc: 0.3092 - val_loss: 1.9480 - val_acc: 0.3228\n",
            "Epoch 8/20\n",
            "18647/18647 [==============================] - 11s 576us/step - loss: 1.9524 - acc: 0.3129 - val_loss: 1.9532 - val_acc: 0.3125\n",
            "Epoch 9/20\n",
            "18647/18647 [==============================] - 11s 580us/step - loss: 1.9372 - acc: 0.3221 - val_loss: 1.9327 - val_acc: 0.3218\n",
            "Epoch 10/20\n",
            "18647/18647 [==============================] - 11s 580us/step - loss: 1.9251 - acc: 0.3187 - val_loss: 1.9317 - val_acc: 0.3196\n",
            "Epoch 11/20\n",
            "18647/18647 [==============================] - 11s 575us/step - loss: 1.9032 - acc: 0.3277 - val_loss: 1.9359 - val_acc: 0.3196\n",
            "Epoch 12/20\n",
            "18647/18647 [==============================] - 11s 577us/step - loss: 1.8931 - acc: 0.3313 - val_loss: 1.9373 - val_acc: 0.3183\n",
            "Epoch 13/20\n",
            "18647/18647 [==============================] - 11s 579us/step - loss: 1.8835 - acc: 0.3375 - val_loss: 1.9235 - val_acc: 0.3235\n",
            "Epoch 14/20\n",
            "18647/18647 [==============================] - 11s 580us/step - loss: 1.8695 - acc: 0.3381 - val_loss: 1.9196 - val_acc: 0.3284\n",
            "Epoch 15/20\n",
            "18647/18647 [==============================] - 11s 583us/step - loss: 1.8513 - acc: 0.3430 - val_loss: 1.9149 - val_acc: 0.3263\n",
            "Epoch 16/20\n",
            "18647/18647 [==============================] - 11s 584us/step - loss: 1.8350 - acc: 0.3504 - val_loss: 1.9246 - val_acc: 0.3226\n",
            "Epoch 17/20\n",
            "18647/18647 [==============================] - 11s 587us/step - loss: 1.8234 - acc: 0.3532 - val_loss: 1.9464 - val_acc: 0.3157\n",
            "Epoch 18/20\n",
            "18647/18647 [==============================] - 11s 581us/step - loss: 1.8142 - acc: 0.3595 - val_loss: 1.9433 - val_acc: 0.3121\n",
            "Epoch 19/20\n",
            "18647/18647 [==============================] - 11s 583us/step - loss: 1.7976 - acc: 0.3649 - val_loss: 1.9347 - val_acc: 0.3207\n",
            "Epoch 20/20\n",
            "18647/18647 [==============================] - 11s 583us/step - loss: 1.7913 - acc: 0.3654 - val_loss: 1.9322 - val_acc: 0.3220\n",
            "Validation Log Loss of  Model in Current Run:  1.9148608428341785\n",
            "Train on 18647 samples, validate on 4662 samples\n",
            "Epoch 1/20\n",
            "18647/18647 [==============================] - 13s 690us/step - loss: 2.3379 - acc: 0.1681 - val_loss: 2.1805 - val_acc: 0.2250\n",
            "Epoch 2/20\n",
            "18647/18647 [==============================] - 11s 616us/step - loss: 2.1597 - acc: 0.2419 - val_loss: 2.0904 - val_acc: 0.2692\n",
            "Epoch 3/20\n",
            "18647/18647 [==============================] - 11s 585us/step - loss: 2.0887 - acc: 0.2621 - val_loss: 2.0280 - val_acc: 0.2932\n",
            "Epoch 4/20\n",
            "18647/18647 [==============================] - 11s 572us/step - loss: 2.0379 - acc: 0.2840 - val_loss: 1.9859 - val_acc: 0.3121\n",
            "Epoch 5/20\n",
            "18647/18647 [==============================] - 11s 612us/step - loss: 2.0161 - acc: 0.2846 - val_loss: 2.1284 - val_acc: 0.2486\n",
            "Epoch 6/20\n",
            "18647/18647 [==============================] - 11s 573us/step - loss: 1.9886 - acc: 0.2977 - val_loss: 1.9518 - val_acc: 0.3093\n",
            "Epoch 7/20\n",
            "18647/18647 [==============================] - 11s 604us/step - loss: 1.9681 - acc: 0.3061 - val_loss: 1.9466 - val_acc: 0.3213\n",
            "Epoch 8/20\n",
            "18647/18647 [==============================] - 11s 580us/step - loss: 1.9488 - acc: 0.3130 - val_loss: 1.9381 - val_acc: 0.3205\n",
            "Epoch 9/20\n",
            "18647/18647 [==============================] - 11s 613us/step - loss: 1.9387 - acc: 0.3175 - val_loss: 1.9406 - val_acc: 0.3226\n",
            "Epoch 10/20\n",
            "18647/18647 [==============================] - 11s 586us/step - loss: 1.9150 - acc: 0.3276 - val_loss: 1.9258 - val_acc: 0.3239\n",
            "Epoch 11/20\n",
            "18647/18647 [==============================] - 11s 590us/step - loss: 1.9101 - acc: 0.3251 - val_loss: 1.9281 - val_acc: 0.3338\n",
            "Epoch 12/20\n",
            "18647/18647 [==============================] - 12s 652us/step - loss: 1.8939 - acc: 0.3299 - val_loss: 1.9254 - val_acc: 0.3267\n",
            "Epoch 13/20\n",
            "18647/18647 [==============================] - 11s 596us/step - loss: 1.8781 - acc: 0.3359 - val_loss: 1.9725 - val_acc: 0.3157\n",
            "Epoch 14/20\n",
            "18647/18647 [==============================] - 12s 656us/step - loss: 1.8598 - acc: 0.3433 - val_loss: 1.9183 - val_acc: 0.3269\n",
            "Epoch 15/20\n",
            "18647/18647 [==============================] - 11s 615us/step - loss: 1.8502 - acc: 0.3471 - val_loss: 1.9429 - val_acc: 0.3102\n",
            "Epoch 16/20\n",
            "18647/18647 [==============================] - 11s 595us/step - loss: 1.8336 - acc: 0.3536 - val_loss: 1.9477 - val_acc: 0.3119\n",
            "Epoch 17/20\n",
            "18647/18647 [==============================] - 10s 561us/step - loss: 1.8240 - acc: 0.3521 - val_loss: 2.0130 - val_acc: 0.2992\n",
            "Epoch 18/20\n",
            "18647/18647 [==============================] - 11s 592us/step - loss: 1.8125 - acc: 0.3610 - val_loss: 1.9446 - val_acc: 0.3170\n",
            "Epoch 19/20\n",
            "18647/18647 [==============================] - 12s 619us/step - loss: 1.7925 - acc: 0.3641 - val_loss: 1.9429 - val_acc: 0.3200\n",
            "Validation Log Loss of  Model in Current Run:  1.918339006581988\n",
            "Train on 18647 samples, validate on 4662 samples\n",
            "Epoch 1/20\n",
            "18647/18647 [==============================] - 13s 696us/step - loss: 2.3280 - acc: 0.1693 - val_loss: 2.2421 - val_acc: 0.1918\n",
            "Epoch 2/20\n",
            "18647/18647 [==============================] - 11s 585us/step - loss: 2.1578 - acc: 0.2400 - val_loss: 2.1214 - val_acc: 0.2576\n",
            "Epoch 3/20\n",
            "18647/18647 [==============================] - 11s 576us/step - loss: 2.0890 - acc: 0.2640 - val_loss: 1.9978 - val_acc: 0.3016\n",
            "Epoch 4/20\n",
            "18647/18647 [==============================] - 11s 576us/step - loss: 2.0478 - acc: 0.2780 - val_loss: 1.9853 - val_acc: 0.3115\n",
            "Epoch 5/20\n",
            "18647/18647 [==============================] - 11s 577us/step - loss: 2.0227 - acc: 0.2827 - val_loss: 1.9697 - val_acc: 0.3177\n",
            "Epoch 6/20\n",
            "18647/18647 [==============================] - 11s 569us/step - loss: 1.9916 - acc: 0.2980 - val_loss: 1.9509 - val_acc: 0.3198\n",
            "Epoch 7/20\n",
            "18647/18647 [==============================] - 11s 566us/step - loss: 1.9759 - acc: 0.3025 - val_loss: 1.9436 - val_acc: 0.3226\n",
            "Epoch 8/20\n",
            "18647/18647 [==============================] - 11s 566us/step - loss: 1.9566 - acc: 0.3095 - val_loss: 1.9513 - val_acc: 0.3123\n",
            "Epoch 9/20\n",
            "18647/18647 [==============================] - 11s 575us/step - loss: 1.9447 - acc: 0.3139 - val_loss: 1.9394 - val_acc: 0.3263\n",
            "Epoch 10/20\n",
            "18647/18647 [==============================] - 11s 585us/step - loss: 1.9347 - acc: 0.3160 - val_loss: 1.9418 - val_acc: 0.3215\n",
            "Epoch 11/20\n",
            "18647/18647 [==============================] - 11s 602us/step - loss: 1.9052 - acc: 0.3258 - val_loss: 1.9427 - val_acc: 0.3138\n",
            "Epoch 12/20\n",
            "18647/18647 [==============================] - 11s 578us/step - loss: 1.8930 - acc: 0.3323 - val_loss: 1.9222 - val_acc: 0.3297\n",
            "Epoch 13/20\n",
            "18647/18647 [==============================] - 11s 575us/step - loss: 1.8862 - acc: 0.3368 - val_loss: 1.9412 - val_acc: 0.3198\n",
            "Epoch 14/20\n",
            "18647/18647 [==============================] - 11s 593us/step - loss: 1.8644 - acc: 0.3409 - val_loss: 1.9385 - val_acc: 0.3175\n",
            "Epoch 15/20\n",
            "18647/18647 [==============================] - 11s 571us/step - loss: 1.8588 - acc: 0.3436 - val_loss: 1.9255 - val_acc: 0.3271\n",
            "Epoch 16/20\n",
            "18647/18647 [==============================] - 11s 573us/step - loss: 1.8497 - acc: 0.3465 - val_loss: 1.9400 - val_acc: 0.3226\n",
            "Epoch 17/20\n",
            "18647/18647 [==============================] - 11s 592us/step - loss: 1.8285 - acc: 0.3562 - val_loss: 1.9394 - val_acc: 0.3275\n",
            "Validation Log Loss of  Model in Current Run:  1.9222252802920925\n",
            "Average CV Loss of 10 Runs : 1.918774524178709\n"
          ]
        }
      ],
      "source": [
        "model_list_2=feat_eve_avg_nn_2(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uki2tM7NM0Ew",
        "outputId": "b10422e9-d9bf-4cb9-9f1f-6a044963e38f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Average Log-Loss:  1.7068032853037864\n"
          ]
        }
      ],
      "source": [
        "feat_avg_pred=np.zeros((xtr.shape[0],12))\n",
        "for i in range(len(model_list_2)):\n",
        "    feat_tr_pred=model_list_2[i].predict_proba(xtr)\n",
        "    feat_avg_pred+=feat_tr_pred\n",
        "feat_avg_pred/=len(model_list_2)\n",
        "print(\"Train Average Log-Loss: \",log_loss(ytr, feat_avg_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spKeIXICM0Ew",
        "outputId": "bc3720f8-17cb-465b-92c0-c4ae3799231d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Average Log-Loss:  1.9012935504651483\n"
          ]
        }
      ],
      "source": [
        "feat_avg_pred=np.zeros((xcv.shape[0],12))\n",
        "for i in range(len(model_list_2)):\n",
        "    feat_cv_pred=model_list_2[i].predict_proba(xcv)\n",
        "    feat_avg_pred+=feat_cv_pred\n",
        "feat_avg_pred/=len(model_list_2)\n",
        "print(\"Validation Average Log-Loss: \",log_loss(ycv, feat_avg_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_OYiOhGM0Ew"
      },
      "outputs": [],
      "source": [
        "feat_avg_pred=np.zeros((X_test_events.shape[0],12))\n",
        "for i in range(len(model_list_2)):\n",
        "    feat_te_pred=model_list_2[i].predict_proba(feat_Xte_eve)\n",
        "    feat_avg_pred+=feat_te_pred\n",
        "feat_avg_pred/=len(model_list_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wYdsQgzM0Ew"
      },
      "outputs": [],
      "source": [
        "np.save('nn2_events_1',feat_avg_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_y55hYqM0Ew"
      },
      "source": [
        "OBSERVATIONS:\n",
        "1. THE TRAIN AND VALIDATION LOSSES ARE 1.7068 AND 1.9012 RESPECTIVELY."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sldSK2uoM0Ew"
      },
      "source": [
        "# XGBOOST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOrffZmvM0Ex",
        "outputId": "fa421b30-cb3d-4293-cf33-c6a174fd9891"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(18647, 12)"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ytr.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edqv0ZaUM0Ex"
      },
      "outputs": [],
      "source": [
        "xtr, xcv, ytr, ycv = train_test_split(feat_Xtr_eve, y,stratify=feat_y,test_size=0.2,random_state=9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7IGXdMnM0Ex",
        "outputId": "601d8935-ccf0-4281-ae51-c7672144cc3f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(18647,)"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ytr.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bm_XDujzM0Ex",
        "outputId": "bf7347a8-3c9f-4fdf-cd11-7ba91658ca5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Log Loss : 1.2839666002195145\n",
            "Validation Log Loss : 2.057339870807861\n"
          ]
        }
      ],
      "source": [
        "feat_xgb = XGBClassifier(n_estimators=350, n_jobs=-1,learning_rate=0.05, colsample_bytree=0.7, max_depth=5,subsample=0.7,objective='multi:softprob',num_class=12,eval_metric='mlogloss')\n",
        "feat_xgb.fit(xtr, ytr)\n",
        "#Using Model Calibration\n",
        "feat_clf = CalibratedClassifierCV(feat_xgb, method=\"sigmoid\")\n",
        "feat_clf.fit(xtr, ytr)\n",
        "\n",
        "feat_pred_y=feat_clf.predict_proba(xtr)\n",
        "print(\"Train Log Loss :\",log_loss(ytr, feat_pred_y))\n",
        "\n",
        "\n",
        "feat_pred_y=feat_clf.predict_proba(xcv)\n",
        "print(\"Validation Log Loss :\",log_loss(ycv, feat_pred_y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Gc0AGhxM0Ex"
      },
      "outputs": [],
      "source": [
        "feat_eve_pred_xgb=clf.predict_proba(feat_Xte_eve)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdSAteZhM0Ex"
      },
      "outputs": [],
      "source": [
        "np.save('xgb_events_1.npy',feat_eve_pred_xgb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "469z_euqM0Ey"
      },
      "source": [
        "OBSERVATIONS:\n",
        " THE TRAIN AND  VALIDATION LOSSES ARE 1.2839 AND 2.0573 RESPECTIVELY."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGaFBP9DM0Ey"
      },
      "source": [
        "# LOGISTIC REGRESSION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsO5BWDOM0Ey",
        "outputId": "d94c6161-a983-4de2-8b4c-3487e0834490"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For values of C =  0.001 The validation log loss is: 2.0982561817893224\n",
            "For values of C =  0.01 The validation log loss is: 2.019844834880824\n",
            "For values of C =  0.02 The validation log loss is: 2.0160115578199274\n",
            "For values of C =  0.1 The validation log loss is: 2.043084585773688\n",
            "For values of C =  0.15 The validation log loss is: 2.055436921152977\n",
            "For values of C =  1 The validation log loss is: 2.1074612177933965\n",
            "For values of C =  10 The validation log loss is: 2.13818998200252\n"
          ]
        }
      ],
      "source": [
        "# Train a Logistic regression+Calibration model using text features whicha re on-hot encoded\n",
        "feat_alph = [0.001,0.01,0.02,0.1,0.15,1,10]\n",
        "\n",
        "\n",
        "for i in feat_alph:\n",
        "    feat_clf = LogisticRegression(C=i, class_weight='balanced', multi_class='multinomial',solver='lbfgs')\n",
        "    feat_clf.fit(xtr, ytr)\n",
        "    #Using Model Calibration\n",
        "    feat_sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
        "    feat_sig_clf.fit(xtr, ytr)\n",
        "    predict_y = feat_sig_clf.predict_proba(xcv)\n",
        "    print('For values of C = ', i, \"The validation log loss is:\",log_loss(ycv, feat_pred_y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaqJgT3eM0Ey"
      },
      "source": [
        "WE CHOSE OUR BEST C TO BE 0.02"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHR7LrY0M0Ey",
        "outputId": "9ebe4c5a-1fd9-47e9-c4c9-57c615c7ee7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The train log loss for best C is: 1.840631737548809\n",
            "The validation log loss for best C is: 2.0160115578199274\n"
          ]
        }
      ],
      "source": [
        "feat_clf = LogisticRegression(C=0.02, class_weight='balanced', multi_class='multinomial', solver='lbfgs')\n",
        "feat_clf.fit(xtr, ytr)\n",
        "feat_sig_clf = CalibratedClassifierCV(feat_clf, method=\"sigmoid\")\n",
        "feat_sig_clf.fit(xtr, ytr)\n",
        "\n",
        "feat_pred_y = feat_sig_clf.predict_proba(xtr)\n",
        "feat_loss=log_loss(ytr, feat_pred_y)\n",
        "print(\"The train log loss for best C is:\",feat_loss)\n",
        "feat_pred_y = feat_sig_clf.predict_proba(xcv)\n",
        "feat_loss=log_loss(ycv, feat_pred_y)\n",
        "print(\"The validation log loss for best C is:\",feat_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfLI-T0CM0Ey"
      },
      "outputs": [],
      "source": [
        "feat_eve_pred_lr=clf.predict_proba(feat_Xte_eve)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUuMkr-tM0Ez"
      },
      "outputs": [],
      "source": [
        "#saving the model\n",
        "np.save('lr_events_1.npy',feat_eve_pred_lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8lnwyiTM0Ez"
      },
      "source": [
        "OBSERVATIONS:\n",
        "  WE GOT TRAIN AND VALIDATION LOSS AS 1.84 AND 2.0160 RESPECTIVELY."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlAUqeAgM0Ez"
      },
      "source": [
        "# MODEL ENSEMBLING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFK0A2_uM0Ez"
      },
      "source": [
        "# MACHINE LEARNING MODELS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sc-0W_dxM0Ez"
      },
      "source": [
        "WE USE LOGISTIC REGRESSION  AND XGBOOST WITH EVENTS AND WITHOUTS DATA AND WE CONCATENATE THE RESULTS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvcxMtjdM0Ez"
      },
      "outputs": [],
      "source": [
        "feat_lr1=np.load(\"lr_noevents.npy\")\n",
        "feat_lr2=np.load(\"lr_events_1.npy\")\n",
        "\n",
        "feat_xgb1=np.load(\"xgb_noevents_1.npy\")\n",
        "feat_xgb2=np.load(\"xgb_events_1.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMQ7ADfwM0E0"
      },
      "outputs": [],
      "source": [
        "w1=0.5\n",
        "w2=0.5\n",
        "w3=0.3\n",
        "w4=0.5\n",
        "\n",
        "feat_test1=(w1*lr1)+(w2*xgb1)\n",
        "\n",
        "feat_test2=(w3*lr2)+(w4*xgb2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QGC58eRM0E0"
      },
      "outputs": [],
      "source": [
        "feat_gat_tr=pd.read_csv('gender_age_train.csv',index_col = 'device_id')\n",
        "feat_targt_encod = LabelEncoder().fit(feat_gat_tr.group)\n",
        "feat_y = feat_targt_encod.transform(feat_gat_tr.group)\n",
        "nclasses = len(feat_targt_encod.classes_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2b-P42tDM0E0",
        "outputId": "02b6cc3d-b3c9-4d4c-8b8f-0e689ac9d41c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(112071, 12)"
            ]
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feat_pred1 = pd.DataFrame(feat_test1, index = feat_gate_noeve.index, columns=feat_targt_encod.classes_)\n",
        "feat_pred2 = pd.DataFrame(feat_test2, index = feat_gate_noeve.index, columns=feat_targt_encod.classes_)\n",
        "feat_fin_pred=pd.concat([feat_pred1,feat_pred2], axis=0)\n",
        "feat_fin_pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJD7i9QwM0E0"
      },
      "outputs": [],
      "source": [
        "feat_fin_pred.to_csv('ml_final.csv',index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2kF4ynrM0E0"
      },
      "source": [
        "#  ENSEMBLING NEURAL NETS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8EEQw_YM0E0"
      },
      "outputs": [],
      "source": [
        "\n",
        "feat_noeve_nn_1=np.load(\"nn1_noevents_1.npy\")\n",
        "feat_noeve_nn_2=np.load(\"nn2_noevents_1.npy\")\n",
        "\n",
        "feat_eve_nn_1=np.load(\"nn1_events_1.npy\")\n",
        "feat_eve_nn_2=np.load(\"nn2_events_1.npy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOQVe6rhM0E0"
      },
      "source": [
        "WE ARE TAKING ONLY NEURAL NETWORK 1 FOR DEVICES WITHOUT EVENTS AND FOR DEVICES WITH EVENTS WE ARE TAKING AVERAGE OF BOTH NETWORKS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SicTRwmlM0E1"
      },
      "outputs": [],
      "source": [
        "w1=0.5\n",
        "w2=0.5\n",
        "\n",
        "feat_test1=(1*feat_noeve_nn_1)\n",
        "\n",
        "feat_test1=(0.5*feat_eve_nn_1)+(0.5*feat_eve_nn_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2FQPQXgM0E1"
      },
      "outputs": [],
      "source": [
        "feat_gat_tr=pd.read_csv('gender_age_train.csv',index_col = 'device_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpEMudcZM0E1"
      },
      "outputs": [],
      "source": [
        "feat_targt_encod = LabelEncoder().fit(feat_gat_tr.group)\n",
        "feat_y = feat_targt_encod.transform(feat_gat_tr.group)\n",
        "nclasses = len(feat_targt_encod.classes_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oGN111PM0E1",
        "outputId": "be281df9-038d-4f3f-b3ce-1619dc3e4d94"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(112071, 12)"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feat_pred1 = pd.DataFrame(test1, index = gatest_noevents.index, columns=targetencoder.classes_)\n",
        "feat_pred2 = pd.DataFrame(test2, index = gatest_events.index, columns=targetencoder.classes_)\n",
        "feat_fin_pred1=pd.concat([feat_pred1,feat_pred2], axis=0)\n",
        "feat_fin_pred1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJQE5EZSM0E1"
      },
      "outputs": [],
      "source": [
        "feat_fin_pred1.to_csv('dl_sub_1.csv',index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9S5e2G7M0E1"
      },
      "source": [
        "# RESULT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPa4r7JmM0E1",
        "outputId": "c050d5b5-db55-4a08-d4fd-a33b436f1822"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------------------+----------------+------------+------------------+\n",
            "|        Model         |      Data      | TRAIN LOSS |  Validation loss |\n",
            "+----------------------+----------------+------------+------------------+\n",
            "| Logistic Regression  | without events |   2.3628   |      2.3891      |\n",
            "|       XGboost        | without events |   2.3718   |      2.3929      |\n",
            "| Avg Neural Network-1 | without events |   2.3528   |      2.3577      |\n",
            "| Avg Neural Network-2 | without events |   2.377    |      2.3788      |\n",
            "| Logistic Regression  |  WITH events   |   1.8406   |      2.016       |\n",
            "|       XGboost        |  WITH events   |   1.2839   |      2.0573      |\n",
            "| Avg Neural Network-1 |  WITH events   |   1.5406   |      1.9074      |\n",
            "| Avg Neural Network-2 |  WITH events   |   1.7068   |      1.9012      |\n",
            "| LOGISTIC REGRESSION  |   FULL DATA    |   2.4145   |      2.354       |\n",
            "+----------------------+----------------+------------+------------------+\n"
          ]
        }
      ],
      "source": [
        "from prettytable import PrettyTable\n",
        "\n",
        "feat_res = PrettyTable()\n",
        "feat_res.field_names = [\"Model\", \"Data\", \"TRAIN LOSS\",\" Validation loss\"]\n",
        "feat_res.add_row([\"Logistic Regression\", \"without events\",  2.3628,2.3891])\n",
        "feat_res.add_row([\"XGboost\", \"without events\",  2.3718,2.3929])\n",
        "feat_res.add_row([\"Avg Neural Network-1\", \"without events\",  2.3528,2.3577])\n",
        "feat_res.add_row([\"Avg Neural Network-2\", \"without events\",  2.3770,2.3788])\n",
        "\n",
        "feat_res.add_row([\"Logistic Regression\", \"WITH events\",  1.8406,2.0160])\n",
        "feat_res.add_row([\"XGboost\", \"WITH events\", 1.2839,2.0573])\n",
        "feat_res.add_row([\"Avg Neural Network-1\", \"WITH events\",  1.5406,1.9074])\n",
        "feat_res.add_row([\"Avg Neural Network-2\", \"WITH events\",  1.7068,1.9012])\n",
        "feat_res.add_row(['LOGISTIC REGRESSION','FULL DATA',2.4145,2.3540])\n",
        "\n",
        "print(feat_res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7CUeyjbM0E2"
      },
      "source": [
        "# REFERENCES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3le_3NQM0E2"
      },
      "source": [
        "1.https://www.kaggle.com/dvasyukova/a-linear-model-on-apps-and-labels\n",
        "2.https://www.kaggle.com/c/talkingdata-mobile-user-demographics/discussion/23424"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xzFppSAM0E2"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JN0in1F9M0E2"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "final model.ipynb.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Wlz6ZiheM0EW",
        "o3ih6OE3M0Em",
        "DlAUqeAgM0Ez"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}